{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"e37cb69cb73a49c2ad07cf670e073cb7","deepnote_cell_height":156.390625,"deepnote_cell_type":"markdown","id":"XUZ1dFPHzAHl"},"source":["<h1><center>Laboratorio 4: Spark y EDA</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos - Primavera 2024</strong></center>"]},{"cell_type":"markdown","metadata":{"id":"PkEUN6c8S-E_"},"source":["### Cuerpo Docente:\n","\n","- Profesores: Ignacio Meza, Sebasti치n Tinoco\n","- Auxiliar: Eduardo Moya\n","- Ayudantes: Nicol치s Ojeda, Melanie Pe침a, Valentina Rojas"]},{"cell_type":"markdown","metadata":{"cell_id":"8ebcb0f2f70c43319279fdd28c13fe89","deepnote_cell_height":171.796875,"deepnote_cell_type":"markdown","id":"tXflExjqzAHr"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n","\n","- Nombre de alumno 1: Luis Pic칩n.\n","- Nombre de alumno 2: Israel Astudillo M.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"290822720f3e4484b09e762655bcdb76","deepnote_cell_height":62,"deepnote_cell_type":"markdown","id":"AD-V0bbZzAHr"},"source":["### **Link de repositorio de GitHub:** [Repositorio](https://github.com/IsraPKMNPAP/Laboratorio-de-Herramientas)"]},{"cell_type":"markdown","metadata":{"cell_id":"60255b81ff0349ad9b18f598a8d71386","deepnote_cell_height":216,"deepnote_cell_type":"markdown","id":"hnYD2hBMAwXf","tags":[]},"source":["## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Fecha de entrega: 6 d칤as de plazo con descuento de 1 punto por d칤a. Entregas Jueves a las 23:59.\n","- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria.\n","- <u>Prohibidas las copias</u>. Cualquier intento de copia ser치 debidamente penalizado con el reglamento de la escuela.\n","- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est칠n en u-cursos no ser치n revisados. Recuerden que el repositorio tambi칠n tiene nota.\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n","- Pueden usar cualquier material del curso que estimen conveniente."]},{"cell_type":"markdown","metadata":{"cell_id":"5bf6f5f66dcd4da9a6926774cec108ab","deepnote_cell_height":114.390625,"deepnote_cell_type":"markdown","id":"xzz695obAwXg","tags":[]},"source":["### Temas a tratar\n","\n","- Introducci칩n al manejo y an치lisis de grandes vol칰menes de datos por medio de la libreria `pyspark`."]},{"cell_type":"markdown","metadata":{"cell_id":"50ec30f08f2548a29bc979ed1741f5a0","deepnote_cell_height":243.390625,"deepnote_cell_type":"markdown","id":"6uBLPj1PzAHs"},"source":["### Objetivos principales del laboratorio\n","\n","- Entender, aplicar y aprovechar las ventajas que nos ofrece la libreria `pyspark` para manejar datos tabulares de gran vol칰men.\n","- Crear gr치ficos para el desarrollo de An치lisis de Datos Exploratorios (EDA)."]},{"cell_type":"markdown","metadata":{"id":"f7hHEyTgm12s"},"source":["### Datos del Lab\n","\n","- Base de datos: https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/datos_lab_spark.parquet\n","- Objeto serializado: https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/object.pkl"]},{"cell_type":"markdown","metadata":{"id":"6CrDdk5NRAKe"},"source":["## 1. Preguntas Te칩ricas [12 puntos]\n","(2 por pregunta)"]},{"cell_type":"markdown","metadata":{"id":"EmDMGUTxLp7M"},"source":["<center>\n","<img src=\"https://img.buzzfeed.com/buzzfeed-static/static/2018-08/1/17/enhanced/buzzfeed-prod-web-05/anigif_enhanced-9173-1533160033-1.gif\" width=350 />\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pGZZcxMWRdIa"},"source":["Responda en  m치ximo 5 l칤neas las siguientes preguntas:\n","1. 쯈u칠 es Apache Spark y cu치les son sus principales ventajas sobre Pandas?\n","2. 쯈u칠 es un RDD en Spark? Describe una de sus principales caracter칤sticas. 쯈u칠 tienen que ver con los dataframes?.\n","3. Diferencia entre transformaciones y acciones en Spark. Proporciona ejemplos de cada una. 쯈u칠 ocurre internamente cuando se ejecuta una acci칩n?\n","4. Explica la importancia del particionamiento en Spark y c칩mo afecta el rendimiento del procesamiento de datos.\n","5. 쮺u치les son las funciones de Spark Driver y Spark Executor?\n","6. 쯈u칠 es el Catalyst Optimizer en Apache Spark y cu치l es su funci칩n principal en la optimizaci칩n de consultas SQL?\n"]},{"cell_type":"markdown","metadata":{"id":"1elJgE8JRn2O"},"source":["**Respuestas**\n","\n","> 1. Apache Spark es un motor de procesamiento de datos masivos unificado, orientado al an치lisis de datos y la eficiencia procesando grandes cantidades de datos. Este motor se puede acceder en Python a trav칠s de PySpark, que es una librer칤a que compatibiliza el lenguaje con el motor. Tiene la ventaja principal de ser eficiente y r치pido trabajando grandes cantidades de datos, as칤 como facilitar el stream de datos entre distintos procesos. \n","> 2. Un RDD en Spark es una estructura de datos que se caracteriza por estar distribuida en distintas m치quinas y es la base de las operaciones que Spark permite realizar. Su principal caracter칤stica es la distribuci칩n de sus partes en distintas m치quinas que le da la propiedad de paralelismo de operaciones y aumento en general de la velocidad de procesamiento. Se relacionan con los DataFrames en que sirven de estructura fundamental para estos y funcionan como abstracci칩n de mas alto nivel de los RDD optimizadas para consultas.\n","> 3. Una transformaci칩n es una especie de operaci칩n que transforma un datafrme en otro nuevo (sin modificar el original) que Spark guarda internamente para ejecutar luego en las acciones de Spark (perezosas), las cuales desencadenan las transformaciones en cola. Un ejemplo de transformaci칩n es filter() funci칩n de filtrado de dataframes y uno de acci칩n es save() que guarda un dataframe en alg칰n tipo de almacenamiento externo. Cuando se ejecuta una acci칩n se desencadena la operaci칩n de toda la cola de transformaciones, organizadas en una secuencia optimizada que mejora finalmente la eficiencia en ejecuci칩n y tiempo de procesamiento.\n","> 4. El particionamiento de datos permite a Spark distribuir el procesamiento de distintas tareas en varias m치quinas de manera de acelerar el procesamiento de datos a trav칠s de operaciones en paralelo en las distintas m치quinas distribuidas. Esto tiene finalmente efecto sobre el rendimiento para grandes cantidades de datos, donde las operaciones mismas a realizar son las que m치s demandan en t칠rminos computacionales por sobre reagrupar la data separada.\n","> 5. El driver es el gestor que instancia la sesi칩n que se encarga de administrar y solicitar los recursos necesarios para la ejecuci칩n de las tareas, que a su vez tambi칠n transforma a grafos ac칤clicos. El executor opera en cada nodo de trabajo dentro del cl칰ster llevando a cabo las tareas asignadas por el conductor o cluster manager.\n","> 6. Catalyst Optimizer es el optimizador detr치s del motor de SQL que ofrece Spark para ejecutar consultas SQL. Su funci칩n principal es de optimizaci칩n de consultas a trav칠s de una secuencia de pasos que mejor utiliza los recursos de Spark para ejecutar las consultas.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"00002-bf13ea5a-d8bf-4cee-879e-ba1c7035e657","deepnote_cell_type":"markdown","id":"b020ce37"},"source":["## Parte Pr치ctica\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k0DaDvtgEYTV"},"source":["<center>\n","<img src=\"https://pbs.twimg.com/ad_img/1285681293590749189/kDckYy6Z?format=png&name=900x900\" width=350 />"]},{"cell_type":"markdown","metadata":{"id":"uW1dg_5_WR8S"},"source":["Juan Carlos Bodoque, el famoso periodista y empresario, decidi칩 diversificar su portafolio de negocios y crear su propia plataforma de e-commerce. Despu칠s de varios a침os de investigar y analizar el mercado financiero, finalmente logr칩 fundar Bodoque E-Shop con el objetivo de ofrecer a sus clientes una experiencia personalizada y confiable en sus transacciones.\n","\n","Sin embargo, con la llegada de los aliens al planeta Tierra, aparecen nuevos desaf칤os para el negocio. Por ello, Bodoque decide invertir en un equipo de expertos en tecnolog칤a y comercio interplanetario, para que Bodoque Shop implemente las 칰ltimas innovaciones en servicio al cliente para garantizar la satisfacci칩n y fidelizaci칩n de sus nuevos clientes.\n","\n","El primer objetivo de Bodoque E-Shop ser치 la hacer un an치lisis exploratorio para entender mejor el comportamiento de los usuarios en la plataforma. Para ello Bodoque les hace entrega de un extenso dataset en el que se registran las actividades que han realizado sus clientes durante los 칰ltimos meses. A continuaci칩n se presenta un diccionario de variables que levanto el equipo de consultores interplanetarios de Bodoque:\n","\n","1. `Transaction ID`: A unique identifier for each transaction.\n","2. `Customer ID`: A unique identifier for each customer.\n","3. `Transaction Amount`: The total amount of money exchanged in the transaction in USD.\n","4. `Transaction Date`: The date and time when the transaction took place.\n","5. `Payment Method`: The method used to complete the transaction (e.g., credit card, PayPal, etc.).\n","6. `Product Category`: The category of the product involved in the transaction.\n","7. `Quantity`: The number of products involved in the transaction.\n","8. `Customer Age`: The age of the customer making the transaction.\n","9. `Customer Location`: The geographical location of the customer.\n","10. `Device Used`: The type of device used to make the transaction (e.g., mobile, desktop).\n","11. `IP Address`: The IP address of the device used for the transaction.\n","Shipping Address: The address where the product was shipped.\n","12. `Billing Address`: The address associated with the payment method.\n","13. `Is An Alien`: A binary indicator of whether customer is an alien.\n","14. `Account Age Days`: The age of the customer's account in days at the time of the transaction.\n","15. `Transaction Hour`: The hour of the day when the transaction occurred.\n"]},{"cell_type":"markdown","metadata":{"cell_id":"1769820f70244385ab5ac51f7509b6de","deepnote_cell_height":61.133331298828125,"deepnote_cell_type":"markdown","id":"MhISwri4zAHy"},"source":["### Importamos librerias utiles y cargamos los datos游땾"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"xHoq7VBlJoS3"},"outputs":[],"source":["import os\n","os.environ[\"JAVA_HOME\"] = r\"C:/Program Files/Java/jdk-22/\""]},{"cell_type":"code","execution_count":2,"metadata":{"id":"M6MKzLmPSHzY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting plotly\n","  Downloading plotly-5.24.0-py3-none-any.whl.metadata (7.3 kB)\n","Collecting tenacity>=6.2.0 (from plotly)\n","  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: packaging in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from plotly) (24.1)\n","Downloading plotly-5.24.0-py3-none-any.whl (19.0 MB)\n","   ---------------------------------------- 0.0/19.0 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/19.0 MB ? eta -:--:--\n","    --------------------------------------- 0.3/19.0 MB ? eta -:--:--\n","   --- ------------------------------------ 1.6/19.0 MB 5.6 MB/s eta 0:00:04\n","   ------ --------------------------------- 2.9/19.0 MB 5.6 MB/s eta 0:00:03\n","   -------- ------------------------------- 4.2/19.0 MB 5.9 MB/s eta 0:00:03\n","   ---------- ----------------------------- 5.0/19.0 MB 5.8 MB/s eta 0:00:03\n","   ------------- -------------------------- 6.3/19.0 MB 5.7 MB/s eta 0:00:03\n","   --------------- ------------------------ 7.3/19.0 MB 5.7 MB/s eta 0:00:03\n","   ---------------- ----------------------- 7.9/19.0 MB 5.4 MB/s eta 0:00:03\n","   ------------------ --------------------- 8.7/19.0 MB 4.8 MB/s eta 0:00:03\n","   -------------------- ------------------- 9.7/19.0 MB 4.8 MB/s eta 0:00:02\n","   ---------------------- ----------------- 10.7/19.0 MB 4.8 MB/s eta 0:00:02\n","   ------------------------ --------------- 11.8/19.0 MB 4.8 MB/s eta 0:00:02\n","   -------------------------- ------------- 12.6/19.0 MB 4.8 MB/s eta 0:00:02\n","   ---------------------------- ----------- 13.6/19.0 MB 4.8 MB/s eta 0:00:02\n","   ------------------------------ --------- 14.4/19.0 MB 4.7 MB/s eta 0:00:01\n","   -------------------------------- ------- 15.5/19.0 MB 4.7 MB/s eta 0:00:01\n","   ---------------------------------- ----- 16.3/19.0 MB 4.7 MB/s eta 0:00:01\n","   ------------------------------------ --- 17.3/19.0 MB 4.7 MB/s eta 0:00:01\n","   -------------------------------------- - 18.4/19.0 MB 4.7 MB/s eta 0:00:01\n","   ---------------------------------------  18.9/19.0 MB 4.7 MB/s eta 0:00:01\n","   ---------------------------------------- 19.0/19.0 MB 4.4 MB/s eta 0:00:00\n","Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n","Installing collected packages: tenacity, plotly\n","Successfully installed plotly-5.24.0 tenacity-9.0.0\n","Collecting missingno\n","  Downloading missingno-0.5.2-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: numpy in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from missingno) (1.26.4)\n","Requirement already satisfied: matplotlib in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from missingno) (3.9.2)\n","Requirement already satisfied: scipy in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from missingno) (1.13.1)\n","Requirement already satisfied: seaborn in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from missingno) (0.13.2)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (24.1)\n","Requirement already satisfied: pillow>=8 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from matplotlib->missingno) (2.9.0.post0)\n","Requirement already satisfied: pandas>=1.2 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from seaborn->missingno) (2.2.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from pandas>=1.2->seaborn->missingno) (2023.3)\n","Requirement already satisfied: six>=1.5 in c:\\users\\alumno\\miniconda3\\envs\\pyspark_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n","Downloading missingno-0.5.2-py3-none-any.whl (8.7 kB)\n","Installing collected packages: missingno\n","Successfully installed missingno-0.5.2\n"]}],"source":["# Libreria Core del lab.\n","import pyspark\n","from pyspark import SparkConf, SparkContext\n","from pyspark.sql import SparkSession\n","import pandas as pd\n","from pyspark.sql.types import StringType, IntegerType, FloatType\n","\n","\n","#Libreria para plotear\n","!pip install --upgrade plotly\n","!pip install missingno\n","import matplotlib.pyplot as plt\n","import plotly.express as px"]},{"cell_type":"markdown","metadata":{"id":"9vJWSlEXYBqq"},"source":["Cargue los datos usando **pyspark**\n","\n","> Nota: Puede ser util el siguiente [enlace](https://www.oracle.com/cl/java/technologies/downloads/#jdk22-windows)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"i9Uf-BTZXqXe"},"outputs":[],"source":["# Creamos sesi칩n\n","sparksession = SparkSession.builder.master(\"local\").appName(\"Dataframes\").getOrCreate()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Leemos el DF\n","df = (\n","    sparksession.read\n","    .format(\"parquet\")\n","    .load(\"../temp/datos_lab_spark.parquet\")\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","|      Transaction ID|         Customer ID|Transaction Amount|   Transaction Date|Payment Method|Product Category|Quantity|Customer Age|Customer Location|Device Used|     IP Address|    Shipping Address|     Billing Address|Is An Alien|Account Age Days|Transaction Hour|\n","+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","|4b4a5fe1-ec4d-4f9...|d1b87f62-51b2-493...|             58.09|2022-03-24 00:00:00| bank transfer|     electronics|     1.0|        17.0|    Amandaborough|       NULL| 212.195.49.198|Unit 8934 Box 005...|Unit 8934 Box 005...|        0.0|            NULL|             5.0|\n","|bacd9392-73ce-481...|37de64d5-e901-4a5...|            389.96|2023-01-17 00:00:00|    debit card|     electronics|     2.0|        40.0|     East Timothy|    desktop|208.106.249.121|634 May Keys\\nPor...|634 May Keys\\nPor...|        0.0|            72.0|             8.0|\n","|d936a024-3a1d-40d...|1bac88d6-4b22-409...|            134.19|2023-06-01 00:00:00|        PayPal|   home & garden|     2.0|        22.0|       Davismouth|     tablet|   76.63.88.212|                NULL|16282 Dana Falls ...|        0.0|            63.0|            NULL|\n","|a30aaab5-4042-4b8...|2357c76e-9253-4ce...|            226.17|2019-07-02 00:00:00| bank transfer|        clothing|     5.0|        31.0|         Lynnberg|    desktop| 207.208.171.73|828 Strong Loaf A...|828 Strong Loaf A...|        0.0|           124.0|            20.0|\n","|b0634f43-d07d-4ca...|45071bc5-9588-43e...|            121.53|2020-10-26 00:00:00| bank transfer|        clothing|     2.0|        51.0|             NULL|       NULL| 190.172.14.169|29799 Jason Hills...|29799 Jason Hills...|        0.0|           158.0|            NULL|\n","|8c4711b8-7477-421...|29616b04-2d5c-472...|            166.41|2019-06-10 00:00:00| bank transfer|    toys & games|    NULL|        34.0|     Herreramouth|     tablet|           NULL|5699 Brittany Vil...|120 Kristi Dale\\n...|       NULL|            38.0|            10.0|\n","|fd0342fe-6b16-4a3...|fe21ae29-ba4c-424...|             92.88|2020-10-09 00:00:00|        PayPal|    toys & games|     2.0|        14.0|        Ramosfort|     tablet|   13.45.27.192|                NULL|727 Gibson Island...|        0.0|           119.0|            19.0|\n","|2d7299de-355b-479...|024257c3-5671-4de...|            318.14|2021-10-09 00:00:00|   credit card| health & beauty|     4.0|        42.0|             NULL|    desktop|131.141.230.185|3914 Davis Union\\...|                NULL|        0.0|           251.0|            NULL|\n","|de51c9df-ab52-43a...|                NULL|              NULL|2019-03-22 00:00:00| bank transfer|   home & garden|    NULL|        38.0|       Carneyfurt|       NULL|           NULL|47893 Maldonado S...|                NULL|        0.0|           190.0|            19.0|\n","|                NULL|aab93e75-582f-445...|            121.78|2022-02-28 00:00:00| bank transfer| health & beauty|     4.0|        39.0|       Brockburgh|     mobile| 174.32.252.238|2334 Briana Cente...|2334 Briana Cente...|        0.0|           343.0|            NULL|\n","|f445a4e3-77cc-4d8...|6a2e1397-e24a-414...|            633.39|               NULL|          NULL|            NULL|     5.0|        20.0|        Craneport|     tablet|201.188.209.214|Unit 7360 Box 518...|55423 Henry Haven...|        0.0|           285.0|            22.0|\n","|a93649c4-0d70-49d...|a30a5030-1c23-475...|             56.31|2024-02-15 00:00:00|        PayPal|            NULL|     3.0|        35.0|     West Michael|     tablet|           NULL|3684 Morris Inlet...|3684 Morris Inlet...|       NULL|            NULL|            NULL|\n","|f5f4d967-c8c5-4b5...|                NULL|            275.87|2021-04-28 00:00:00|   credit card|   home & garden|     5.0|        NULL|      Melindafurt|     mobile| 105.173.82.111|4197 Lewis Way\\nM...|075 Monroe Court\\...|        0.0|           307.0|            11.0|\n","|                NULL|                NULL|            178.94|2020-05-15 00:00:00|    debit card|        clothing|     4.0|        27.0|             NULL|     mobile| 211.46.251.245|298 Taylor Canyon...|                NULL|        0.0|           200.0|            NULL|\n","|f1b10958-67af-48c...|bffedad1-43c1-4ef...|            374.04|               NULL| bank transfer|   home & garden|     5.0|        51.0|      Danielmouth|       NULL|   25.126.229.2|32232 Omar Glens\\...|32232 Omar Glens\\...|        0.0|            22.0|            NULL|\n","|                NULL|4c80f103-ce9c-4e4...|            169.04|2022-11-16 00:00:00|    debit card|   home & garden|     1.0|        54.0|         Lamburgh|       NULL|  1.199.155.117|Unit 4478 Box 382...|Unit 4478 Box 382...|        0.0|            60.0|            NULL|\n","|                NULL|                NULL|            254.48|2018-11-07 00:00:00| bank transfer|     electronics|    NULL|        NULL|West Melissashire|    desktop|   52.160.5.136|1117 Braun Courts...|1117 Braun Courts...|        0.0|           238.0|             8.0|\n","|0a0ec219-172f-47a...|                NULL|              NULL|2021-05-26 00:00:00|          NULL|            NULL|     1.0|        41.0|     Port Rebecca|       NULL|   194.26.237.2|1228 Torres Squar...|1228 Torres Squar...|        0.0|            NULL|            14.0|\n","|                NULL|e852cd05-3ee9-45a...|            263.28|2020-11-10 00:00:00|    debit card|            NULL|     3.0|        30.0|             NULL|     tablet|166.131.101.195|12872 Kevin Creek...|                NULL|        0.0|           159.0|            NULL|\n","|                NULL|339683a0-3028-449...|            475.76|2023-09-04 00:00:00|        PayPal|            NULL|     2.0|        29.0|      Muellerstad|     mobile|  196.101.90.48|3496 Jason Ports\\...|3496 Jason Ports\\...|       NULL|           143.0|            10.0|\n","+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Mostramos\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"z6l6GNynYnh4"},"source":["### 2. Limpieza con pyspark [8 puntos]\n","(1 punto por pregunta)"]},{"cell_type":"markdown","metadata":{"id":"8DVdjYyOGRom"},"source":["<center>\n","<img src=\"https://miro.medium.com/v2/resize:fit:600/1*A6PpTrehGLxCJWNcUsDTNg.jpeg\" width=350 />\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sPGV40BjZekP"},"source":["Para comenzar con el an치lisis exploratorio usted decide empezar limpiando la base de datos con **pyspark** dado el alto volumen de datos que genera diariamente Bodoque E-Shop.\n","\n","**Nota: NO SE PERMITE EL USO DE PANDAS EN ESTA SECCI칍N**\n","\n","\n","\n","1.   Utilice `.printSchema()` para revisar la estructura de los datos\n","2.   Muestre las primeras 10 filas del dataset. Hint: utilice `.show()`\n","3.   Imprima un muestreo aleatorio con el 5% de los datos diponibles. . Hint: utilice `.sample()`\n","4. Revise los tipos de datos de cada columna con `.dtypes()` y responda la siguiente pregunta: 쮺u치l/es columna/s tiene/n un tipo de dato que no es el adecuado y por qu칠?\n","5. Cree una funci칩n **cast_columns** que permita cambiar el tipo de datos de las columnas problem치ticas. Luego utilice esta funci칩n respecto a lo respondido en la pregunta anterior.\n","6. Cuente la cantidad de datos nulos por variable. Recuerde que Spark no posee un m칠todo que le permita calcular directamente los nulos.\n","7. Elimine datos nulos.\n","8. Elimine datos duplicados.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nw95Jvr-DtwS"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Transaction ID: string (nullable = true)\n"," |-- Customer ID: string (nullable = true)\n"," |-- Transaction Amount: double (nullable = true)\n"," |-- Transaction Date: timestamp_ntz (nullable = true)\n"," |-- Payment Method: string (nullable = true)\n"," |-- Product Category: string (nullable = true)\n"," |-- Quantity: double (nullable = true)\n"," |-- Customer Age: double (nullable = true)\n"," |-- Customer Location: string (nullable = true)\n"," |-- Device Used: string (nullable = true)\n"," |-- IP Address: string (nullable = true)\n"," |-- Shipping Address: string (nullable = true)\n"," |-- Billing Address: string (nullable = true)\n"," |-- Is An Alien: double (nullable = true)\n"," |-- Account Age Days: double (nullable = true)\n"," |-- Transaction Hour: double (nullable = true)\n","\n"]}],"source":["# Escriba su respuesta aqu칤\n","df.printSchema()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","|      Transaction ID|         Customer ID|Transaction Amount|   Transaction Date|Payment Method|Product Category|Quantity|Customer Age|Customer Location|Device Used|     IP Address|    Shipping Address|     Billing Address|Is An Alien|Account Age Days|Transaction Hour|\n","+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","|4b4a5fe1-ec4d-4f9...|d1b87f62-51b2-493...|             58.09|2022-03-24 00:00:00| bank transfer|     electronics|     1.0|        17.0|    Amandaborough|       NULL| 212.195.49.198|Unit 8934 Box 005...|Unit 8934 Box 005...|        0.0|            NULL|             5.0|\n","|bacd9392-73ce-481...|37de64d5-e901-4a5...|            389.96|2023-01-17 00:00:00|    debit card|     electronics|     2.0|        40.0|     East Timothy|    desktop|208.106.249.121|634 May Keys\\nPor...|634 May Keys\\nPor...|        0.0|            72.0|             8.0|\n","|d936a024-3a1d-40d...|1bac88d6-4b22-409...|            134.19|2023-06-01 00:00:00|        PayPal|   home & garden|     2.0|        22.0|       Davismouth|     tablet|   76.63.88.212|                NULL|16282 Dana Falls ...|        0.0|            63.0|            NULL|\n","|a30aaab5-4042-4b8...|2357c76e-9253-4ce...|            226.17|2019-07-02 00:00:00| bank transfer|        clothing|     5.0|        31.0|         Lynnberg|    desktop| 207.208.171.73|828 Strong Loaf A...|828 Strong Loaf A...|        0.0|           124.0|            20.0|\n","|b0634f43-d07d-4ca...|45071bc5-9588-43e...|            121.53|2020-10-26 00:00:00| bank transfer|        clothing|     2.0|        51.0|             NULL|       NULL| 190.172.14.169|29799 Jason Hills...|29799 Jason Hills...|        0.0|           158.0|            NULL|\n","|8c4711b8-7477-421...|29616b04-2d5c-472...|            166.41|2019-06-10 00:00:00| bank transfer|    toys & games|    NULL|        34.0|     Herreramouth|     tablet|           NULL|5699 Brittany Vil...|120 Kristi Dale\\n...|       NULL|            38.0|            10.0|\n","|fd0342fe-6b16-4a3...|fe21ae29-ba4c-424...|             92.88|2020-10-09 00:00:00|        PayPal|    toys & games|     2.0|        14.0|        Ramosfort|     tablet|   13.45.27.192|                NULL|727 Gibson Island...|        0.0|           119.0|            19.0|\n","|2d7299de-355b-479...|024257c3-5671-4de...|            318.14|2021-10-09 00:00:00|   credit card| health & beauty|     4.0|        42.0|             NULL|    desktop|131.141.230.185|3914 Davis Union\\...|                NULL|        0.0|           251.0|            NULL|\n","|de51c9df-ab52-43a...|                NULL|              NULL|2019-03-22 00:00:00| bank transfer|   home & garden|    NULL|        38.0|       Carneyfurt|       NULL|           NULL|47893 Maldonado S...|                NULL|        0.0|           190.0|            19.0|\n","|                NULL|aab93e75-582f-445...|            121.78|2022-02-28 00:00:00| bank transfer| health & beauty|     4.0|        39.0|       Brockburgh|     mobile| 174.32.252.238|2334 Briana Cente...|2334 Briana Cente...|        0.0|           343.0|            NULL|\n","+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Mostramos las primeras 10 filas\n","df.show(10)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","|      Transaction ID|         Customer ID|Transaction Amount|   Transaction Date|Payment Method|Product Category|Quantity|Customer Age|Customer Location|Device Used|     IP Address|    Shipping Address|     Billing Address|Is An Alien|Account Age Days|Transaction Hour|\n","+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","|                NULL|339683a0-3028-449...|            475.76|2023-09-04 00:00:00|        PayPal|            NULL|     2.0|        29.0|      Muellerstad|     mobile|  196.101.90.48|3496 Jason Ports\\...|3496 Jason Ports\\...|       NULL|           143.0|            10.0|\n","|f9f98c9c-e9fd-406...|80624244-ceb2-4bb...|              NULL|2024-07-23 00:00:00|   credit card|    toys & games|     5.0|        16.0|      East Ashley|     tablet|           NULL|0283 Booker Row S...|0283 Booker Row S...|        0.0|           132.0|            NULL|\n","|c289aff5-e5e1-49e...|                NULL|             56.83|2023-05-05 00:00:00|    debit card|    toys & games|     3.0|        21.0|   Port Adamhaven|     tablet|134.165.126.136|571 Michael Knoll...|                NULL|        0.0|           321.0|            15.0|\n","|8e6a140f-f125-488...|                NULL|              NULL|2022-10-09 00:00:00|          NULL|    toys & games|     5.0|        23.0|        New Jacob|    desktop|  117.189.96.77|4884 Regina Summi...|4884 Regina Summi...|       NULL|           260.0|            NULL|\n","|56d6ab78-4e3b-428...|                NULL|            216.17|2019-06-07 00:00:00|   credit card|   home & garden|     1.0|        41.0|        Scottport|     tablet|  145.63.154.89|Unit 3223 Box 846...|Unit 3223 Box 846...|        0.0|            NULL|            11.0|\n","|                NULL|                NULL|             77.83|2021-04-20 00:00:00|        PayPal|    toys & games|    NULL|        63.0|       Manuelland|    desktop|  53.52.247.199|309 James Cliff\\n...|                NULL|       NULL|           315.0|            22.0|\n","|377ce7ed-0f0b-49c...|765e8076-ab50-457...|            186.28|2020-11-14 00:00:00|   credit card| health & beauty|     4.0|        39.0|             NULL|     tablet|  190.83.210.73|79356 Robbins Vie...|79356 Robbins Vie...|       NULL|           354.0|            NULL|\n","|e7543c93-a0fe-42b...|1f53277f-af43-4c6...|            265.95|2020-07-31 00:00:00| bank transfer|    toys & games|     2.0|        23.0|        Lopezfort|     tablet|           NULL|                NULL|1359 Palmer Hill\\...|        0.0|            41.0|            21.0|\n","|8b6ab7ef-b8b5-41e...|                NULL|              NULL|               NULL|    debit card|     electronics|     3.0|        36.0|             NULL|       NULL| 196.199.123.24|Unit 8016 Box 041...|USNS Johnston\\nFP...|        0.0|           286.0|            14.0|\n","|7b10eb02-349d-424...|dbf53e49-73dc-46c...|            172.08|2023-10-30 00:00:00|        PayPal|            NULL|     4.0|        39.0|     Richardstown|    desktop| 201.168.192.41|                NULL|66511 Mendoza Way...|       NULL|           345.0|            10.0|\n","|                NULL|63ecbac0-797d-4c4...|            208.15|               NULL| bank transfer| health & beauty|     2.0|        55.0| West Joshuaburgh|       NULL|   48.203.41.20|448 Thomas Prairi...|448 Thomas Prairi...|        0.0|            NULL|            22.0|\n","|078ee844-7bd7-454...|eae2bba5-653a-4b7...|            141.12|2023-06-18 00:00:00|    debit card| health & beauty|     2.0|        36.0|      Port Cheryl|     mobile|   23.86.127.29|                NULL|96644 Zachary Pas...|        0.0|            70.0|            16.0|\n","|84d41a9d-396a-46c...|163a8d07-febd-443...|             22.18|2021-12-22 00:00:00| bank transfer|            NULL|     3.0|        NULL|             NULL|    desktop|  155.24.186.83|523 David Dale\\nY...|523 David Dale\\nY...|        0.0|            52.0|            NULL|\n","|e8ac0b3c-09aa-44e...|656f8b98-a35d-4c3...|              NULL|2021-06-27 00:00:00|          NULL|        clothing|     1.0|        28.0|      Port Melody|     mobile|  177.128.68.85|2395 Kim Loop Apt...|2395 Kim Loop Apt...|        0.0|           299.0|            23.0|\n","|                NULL|7db4de39-f5fa-440...|             89.37|2021-11-29 00:00:00|        PayPal|    toys & games|    NULL|        33.0|             NULL|       NULL| 195.255.11.110|336 Edward Rest S...|                NULL|        0.0|           119.0|             7.0|\n","|                NULL|                NULL|            2392.0|2024-05-17 00:00:00| bank transfer|   home & garden|     3.0|        30.0|Lake Jonathantown|     mobile|108.128.142.186|445 Jeremy Union\\...|445 Jeremy Union\\...|        1.0|             4.0|             2.0|\n","|bee5da12-9ef8-466...|2ab50c9e-5c74-410...|            405.74|2022-10-02 00:00:00|          NULL|            NULL|     5.0|        NULL| East Hannahshire|     tablet|           NULL|5039 Thomas Spur ...|5039 Thomas Spur ...|        0.0|            41.0|            18.0|\n","|ec53c129-fc9b-41f...|                NULL|            865.94|2021-11-29 00:00:00|    debit card|        clothing|     1.0|        36.0|  West Danielside|     mobile|           NULL|829 Dennis Glens\\...|                NULL|        0.0|           265.0|            10.0|\n","|                NULL|a2ac0ae3-b892-48f...|             37.13|2023-09-13 00:00:00|   credit card|    toys & games|     3.0|        NULL|     Lake Brandon|     tablet|           NULL|USNV Ellis\\nFPO A...|                NULL|        0.0|           327.0|            18.0|\n","|                NULL|7d14d714-18a8-47a...|            304.21|2021-09-10 00:00:00|   credit card|     electronics|    NULL|        37.0|        Parksport|       NULL|  177.21.28.195|62575 Martinez Fr...|62575 Martinez Fr...|        0.0|           210.0|            NULL|\n","+--------------------+--------------------+------------------+-------------------+--------------+----------------+--------+------------+-----------------+-----------+---------------+--------------------+--------------------+-----------+----------------+----------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Sampleo de 5% de los datos y lo mostramos\n","df.sample(fraction=0.05,seed=30).show()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["[('Transaction ID', 'string'),\n"," ('Customer ID', 'string'),\n"," ('Transaction Amount', 'double'),\n"," ('Transaction Date', 'timestamp_ntz'),\n"," ('Payment Method', 'string'),\n"," ('Product Category', 'string'),\n"," ('Quantity', 'double'),\n"," ('Customer Age', 'double'),\n"," ('Customer Location', 'string'),\n"," ('Device Used', 'string'),\n"," ('IP Address', 'string'),\n"," ('Shipping Address', 'string'),\n"," ('Billing Address', 'string'),\n"," ('Is An Alien', 'double'),\n"," ('Account Age Days', 'double'),\n"," ('Transaction Hour', 'double')]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Mostramos los tipos de datos de las columnas\n","df.dtypes"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Diccionario de tipos de variables a cambiar\n","dic = {}\n","# Funci칩n de cambio de tipos de variables\n","def cast_columns(df, cols_types):\n","    \"\"\"\n","    Cambia el tipo de m칰ltiples columnas en un DataFrame de Spark.\n","\n","    Par치metros:\n","    - df: DataFrame de Spark.\n","    - cols_types: Diccionario con nombres de columnas como claves y tipos de datos de Spark como valores.\n","\n","    Retorna:\n","    - DataFrame de Spark con tipos de columnas modificados.\n","    \"\"\"\n","    for col_name, new_type in cols_types.items():\n","        df = df.withColumn(col_name, df[col_name].cast(new_type))\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Utilizamos la funci칩n\n","cast_columns(df,dic)\n","# Verificamos que funcione\n","df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Contamos cantidad de nulos por columna\n","\n","# Importamos las funciones de consulta SQL\n","\n","from pyspark.sql.functions import when, col, sum\n","\n","exprs = [sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns]\n","\n","df.agg(*exprs).show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sparksession.stop()"]},{"cell_type":"markdown","metadata":{"id":"MjxI2Xd6cRu1"},"source":["### 3. Transformaciones con pyspark [6 puntos]\n","(1 punto por pregunta)"]},{"cell_type":"markdown","metadata":{"id":"bPfhWPZeHXUH"},"source":["<center>\n","<img src=\"https://live.staticflickr.com/13/91801406_0e71d7f019_b.jpg\" width=350 />\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lbIDKn44cWhI"},"source":["**Nota: NO SE PERMITE EL USO DE PANDAS EN ESTA SECCI칍N**\n","\n","Para continuar con el an치lisis, los especistas de Bodoque les gustar칤a tener nuevas variables disponibles. Tras las notas de la reuni칩n usted llega a la conclusi칩n de que tiene que realizar las siguientes tareas (con el dataset preprocesado de la seccion anterior):\n","\n","\n","1.   Agregar una columna llamada \"Transaction bp\" con el **monto total** de la transacci칩n en bodoque pesos. Se considera que $x$ d칩lares equivalen a $log(48+|x^{36}|)$ bodoque pesos.\n","2.   Crear una columna llamada \"Transaction Month\" con el mes en que se realiza una transacci칩n.\n","3.   Crear la variable *Type of purchase* seg칰n la catidad de unidades vendidas de acuerdo a las siguientes categor칤as.\n","  * Compra minorista: 4 productos o menos.\n","  * Compra mayorista: 5 produtos o m치s.\n","4. Imprima los registros de compras hechas por alien칤genas en el comecio mayorista.  Utilice `.filter()`.\n","5. Cuente la cantidad de compras realizadas por humanos y la cantidad de compras realizadas por alien칤genas. Utilice `.groupby()`.\n","6. Muestre una tabla con la recaudaci칩n promedio por transacci칩n para cada m칠todo de pago, tanto para humanos como alien칤genas. Utilice `pivot()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbtFJi3mHnkK"},"outputs":[],"source":["# Escriba su respuesta aqu칤"]},{"cell_type":"markdown","metadata":{"id":"17Muj6u2jOLq"},"source":["### 4. EDA [20 puntos]\n","(1 punto por gr치fico y 1 punto por su interpretaci칩n)"]},{"cell_type":"markdown","metadata":{"id":"7F3yo66wFQ0z"},"source":["<center>\n","<img src=\"https://i.pinimg.com/originals/41/7e/7b/417e7b9089bcc20c4909df8954c6e742.gif\" width=400 />\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ayN5LYRamE7-"},"source":["Esta secci칩n tiene como objetivo evaluar su habilidad para generar reportes y conclusiones a partir de los patrones identificados en los datos proporcionados por Bodoque. Espec칤ficamente, se enfoca en **caracterizar las transacciones** y **explorar las diferencias y similitudes en el comportamiento de humanos y aliens**. Utilice el dataset que ya incluye las transformaciones necesarias.\n","\n","Por favor, aseg칰rese de que **todas** las visualizaciones que realice cumplan con los siguientes criterios:\n","- Deben ser relevantes y f치ciles de interpretar.\n","- Cada gr치fico debe incluir un t칤tulo claro, nombres en los ejes y leyendas adecuadas.\n","- Adjunte una breve descripci칩n interpretativa junto a cada gr치fico para explicar los resultados visualizados.\n","\n","Para llevar a cabo esta tarea, siga los siguientes pasos utilizando la librer칤a de visualizaci칩n de su elecci칩n (matplotlib, seaborn, plotly, etc):\n","\n","1. **Conversi칩n del DataFrame a formato pandas** (2 puntos): Pase el DataFrame procesado a formato pandas. Evite realizar transformaciones adicionales con pandas.\n","2. **Visualizaci칩n de Variables Categ칩ricas** (2 puntos por visualizaci칩n):\n","   - Genere **tres gr치ficos de barras** que diferencien entre humanos y aliens. Analice y comente cualquier diferencia o similitud observada entre estos dos grupos.\n","3. **Visualizaci칩n de Variables Num칠ricas** (2 puntos por visualizaci칩n):\n","   - Elabore **tres distplots** para examinar las distribuciones de variables num칠ricas, diferenciando entre humanos y aliens. Comente las diferencias o similitudes notables.\n","4. **An치lisis de Patrones en Transacciones** (2 puntos por visualizaci칩n):\n","   - Cree **tres gr치ficos avanzados** que ayuden a identificar patrones en las transacciones. Estos gr치ficos deben incorporar al menos dos dimensiones y diferir de los anteriores. Algunos ejemplos podr칤an ser un lineplot que muestre la cantidad de transacciones mensuales por canal de venta, o un barplot que exhiba los tres productos m치s vendidos por canal.\n","\n","Estos pasos le permitir치n no solo visualizar datos complejos de manera efectiva, sino tambi칠n interpretar estos datos para extraer insights valiosos acerca del comportamiento de los consumidores en el contexto de Bodoque."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGw5y36IxRk3"},"outputs":[],"source":["# Escriba su respuesta aqu칤"]},{"cell_type":"markdown","metadata":{"id":"97zN2_g4vgY6"},"source":["### 5. Particiones y consultas en SQL [2 puntos]"]},{"cell_type":"markdown","metadata":{"id":"viNvNuE_odgc"},"source":["<center>\n","<img src=\"https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/1696330143457.gif\" width=400 />"]},{"cell_type":"markdown","metadata":{"id":"SCdHwyGBwVx8"},"source":["El equipo de Bodoque e-shop ha solicitado que los datos est칠n disponibles en una tabla SQL consultable. Adem치s, est치n interesados en aprovechar las funciones de ventana en SQL para an치lisis avanzados. Las funciones de ventana permiten realizar c치lculos sobre un conjunto de filas que est치n relacionadas con la fila actual. Por ejemplo, UNBOUNDED PRECEDING se usa para indicar que el rango de la funci칩n de ventana comienza desde la primera fila de la partici칩n o del conjunto de resultados, lo cual es 칰til para calcular sumas acumulativas hasta la fila actual. Las variaciones comunes de este uso incluyen:\n","\n","- `UNBOUNDED PRECEDING` to `CURRENT ROW`: Calcula desde el inicio de la partici칩n hasta la fila actual.\n","- `UNBOUNDED PRECEDING` to `UNBOUNDED FOLLOWING`: Cubre todas las filas dentro de la partici칩n.\n","- `VALUE PRECEDING` to `VALUE FOLLOWING`: Establece un rango espec칤fico basado en valores antes y despu칠s de la fila actual."]},{"cell_type":"markdown","metadata":{"id":"VntjejKLleIa"},"source":["<center>\n","<img src=\"https://learnsql.com/blog/sql-window-functions-rows-clause/1.png\" width=500 />"]},{"cell_type":"markdown","metadata":{"id":"D8XJ7NrPllKG"},"source":["Ejemplo de uso en SQL:\n","\n","```sql\n","STAT(COL1_NAME) OVER (PARTITION BY COL2_NAME ORDER BY COL3_NAME ROWS BETWEEN X PRECEDING AND CURRENT ROW)\n","```\n","\n","\n","Responda y realice los siguientes puntos:\n","\n","1. **Creaci칩n de Tabla con PySpark** (2 puntos):\n","   - Desarrolle un script utilizando PySpark para crear una tabla a partir de un DataFrame previamente transformado. Seleccione y utilice una variable espec칤fica para la partici칩n de la tabla. Justifique su elecci칩n de esta variable considerando factores como el tama침o del DataFrame, la distribuci칩n de los datos y el impacto potencial en el rendimiento de futuras consultas.\n","\n","2. **Consulta SQL para Principales Clientes** (Bonus: 2 punto):\n","   - Ejecute una consulta SQL para identificar los 10 clientes que m치s productos han comprado. La consulta debe retornar el ID del cliente junto con el total de productos comprados, ordenados en forma descendente.\n","\n","3. **Implementaci칩n de Funci칩n de Ventana en SQL y Equivalente en Spark** (Bonus: 2 punto):\n","   - Implemente una funci칩n de ventana en SQL para calcular la compra m치s alta realizada por cada usuario en los 칰ltimos tres meses. Adem치s, describa c칩mo se podr칤a realizar una funci칩n equivalente en Spark, considerando las capacidades espec칤ficas de PySpark para manejar este tipo de consultas.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xe_JQ3npiM6_"},"outputs":[],"source":["# C칩digo Aqu칤"]},{"cell_type":"markdown","metadata":{"id":"AKQs-augfZBv"},"source":["### 6. UDF [12 puntos]"]},{"cell_type":"markdown","metadata":{"id":"ovDBGi-uhhdD"},"source":["<center>\n","<img src=\"https://64.media.tumblr.com/ba8c705edd2bed0a28d9458811155d69/tumblr_pap19zg4ae1w3zg6go1_400.gifv\" width=400 />"]},{"cell_type":"markdown","metadata":{"id":"TJUUnpi8qKHD"},"source":["\n","\n","Un experto en predicciones y programaci칩n le ha proporcionado un objeto serializado (`pickle`) dise침ado para calcular las probabilidades de que un cliente cometa o no un fraude. Este experto sugiere que, para maximizar las capacidades de procesamiento distribuido de Spark, deber칤a implementar `Scalar User Defined Functions` (udf). Esto le permitir치 aplicar el objeto serializado en un entorno distribuido a lo largo de toda la poblaci칩n de datos. Un aspecto clave de la funci칩n desarrollada por el experto es que se enfoca exclusivamente en las siguientes columnas para realizar las predicciones: `['Transaction Amount', 'Quantity', 'Customer Age', 'Transaction Hour']`.\n","\n","Aparte, el experto le proporciona las siguientes instrucciones para usar las UDF en Spark:\n","\n","```python\n","from pyspark.sql.functions import udf\n","from pyspark.sql.types import FloatType\n","\n","def custom_function(col1, col2, col3, col4):\n","    pass\n","\n","udf_function = udf(custom_function, FloatType())\n","```\n","\n","Bas치ndose en la estructura proporcionada, debe desarrollar una funci칩n que ejecute un c칩digo espec칤fico. Tenga en cuenta que esta funci칩n solo puede recibir columnas de Spark y debe retornar el valor deseado. Posteriormente, deber치 utilizar esta funci칩n UDF indicando la funci칩n personalizada y el formato de salida.\n","\n","Siga los siguientes pasos para implementar la soluci칩n y responda las preguntas:\n","\n","1. **Cargar el objeto serializado**: Revise el tipo de objeto y deduzca su funci칩n. (1 punto)\n","2. **Explorar el objeto**: Utilice las funciones `dir` y `help` para identificar qu칠 m칠todo del objeto predice la probabilidad. (1 punto)\n","3. **Crear una funci칩n personalizada**: Elabore una funci칩n que prediga la probabilidad de fraude utilizando el 칰ltimo valor de la lista generada por el objeto serializado. Puede modificar el nombre de la funci칩n para reflejar su prop칩sito. (6 puntos)\n","4. **Definir la funci칩n UDF**: Establezca la funci칩n UDF con la funci칩n personalizada que ha creado. (2 punto)\n","5. **Generar una nueva columna**: A침ada una nueva columna `prediction` a su DataFrame en Spark utilizando la funci칩n UDF y muestre un ejemplo de c칩mo se aplica. 쯈u칠 beneficios podr칤a generar utilizar udf? (2 puntos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPJVs2OBezN_"},"outputs":[],"source":["# C칩digo Aqu칤"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
