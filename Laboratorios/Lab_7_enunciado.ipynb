{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 7: Clasificaci√≥n ü§ó\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Luis Pic√≥n\n",
        "- Nombre de alumno 2: Israel Astudillo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/IsraPKMNPAP/Laboratorio-de-Herramientas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificaci√≥n en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo trabajar con problemas de clasificaci√≥n con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Te√≥rica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cu√°l es la diferencia entre los datos de entrenamiento y validaci√≥n. [1 punto]\n",
        "\n",
        "2. Explique cu√°l es el principal desaf√≠o al trabajar problemas de clasificaci√≥n con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qu√© es la matriz de confusi√≥n y para qu√© se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la f√≥rmula de las siguientes m√©tricas y explique con **sus palabras** c√≥mo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qu√© m√©trica recomendar√≠a para los siguientes contextos de clasificaci√≥n. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detecci√≥n de enfermedades altamente contagiosas.\n",
        "  * Aprobaci√≥n de cr√©ditos de alto riesgo.\n",
        "  * Detecci√≥n de cr√≠menes.\n",
        "\n",
        "6. Explique qu√© es la calibraci√≥n de modelos y para qu√© se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "1. Los datos de entrenamiento son el conjunto de datos disponibles que son utilizados por alg√∫n modelo de aprendizaje para extraer relaciones o patrones que describan alguna variable dependiente de inter√©s. El modelo se basa en los datos de entrenamiento para generar predicciones de la variable de inter√©s utilizando los patrones que encontr√≥ en los datos de entrenamiento. Por otro lado, los datos de validaci√≥n son los utilizados para ajustar el modelo entrenado, sus hiperpar√°metros y revisar si cumple los est√°ndares m√≠nimos en primera instancia sobre un conjunto reducido de datos. El conjunto de testeo es un conjunto de datos sobre el cual el modelo ya entrenado y validado realiza predicciones de la variable dependiente, de forma de compararla luego con el valor real de esta variable y concluir sobre el desempe√±o general del modelo para predecir esta variable en base a m√©tricas. Cabe destacar que estos conjuntos deben ser disjuntos entre s√≠ para evitar sesgos dados por data leakage, es decir no queremos darle al modelo informaci√≥n de entrenamiento que se incluya en su testeo de forma de conocer el verdadero desempe√±o del modelo y caracterizar su capacidad de generalizaci√≥n.\n",
        "2. El principal desaf√≠o al trabajar con problemas de clasificaci√≥n con datos no supervisados es que al buscar agrupar datos por similaridad en sus caracter√≠sticas, los grupos encontrados pueden no ser diferenciables, identificables o interpretables y por sobre todo no se sabe a priori cu√°ntos grupos de datos existen realmente en la data, es decir se desconoce la cantidad de clases que caracterizan a la data y es este precisamente el problema que la clasificaci√≥n no supervisada busca resolver.\n",
        "3. La matriz de confusi√≥n es una forma de organizar y ordenar las predicciones correctas e incorrectas que realiza un modelo. Muestra la cantidad de aciertos y desaciertos por clase, permitiendo visualizar posibles problemas tempranamente como desbalance de clases y permite caracterizar el comportamiento predicitivo del modelo en base a las predicciones que realiza. Se usa como base para construir las distintas m√©tricas de evaluaci√≥n de modelos que representan razones entre predicciones correctas o incorrectas por sobre las totales para cierta clase o en general, dependiendo de la m√©trica.\n",
        "4. Se considerar√° la f√≥rmula para el caso de clasificaci√≥n binaria por simplicidad, donde TP son los verdaderos positivos, TN los verdaderos negativos, FP los falsos positivos y FN los falsos negativos. El Accuracy que viene dado por: \n",
        "$$\\text{Accuracy}=\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
        "Representa el porcentaje de aciertos que el modelo tuvo respecto al total de predicciones que realiz√≥.\n",
        "\n",
        "El Precision viene dado por:\n",
        "$$\\text{Precision}=\\frac{TP}{TP+FP}$$\n",
        "Representa el porcentaje de aciertos positivos que el modelo realiz√≥, es decir del total de positivos que predijo cuantos realmente eran positivos.\n",
        "\n",
        "El Recall viene dado por:\n",
        "$$\\text{Recall}=\\frac{TP}{TP+FN}$$\n",
        "Representa el porcentaje de clasificaciones positivas correctas del total de elementos con clase positiva. Es decir, de todos los elementos de clases positiva, cuantos identific√≥ correctamente el modelo.\n",
        "\n",
        "El F1-Score viene dado por:\n",
        "$$\\text{F1-Score}=2\\cdot\\frac{\\text{Precision}\\cdot\\text{Recall}}{\\text{Precision}+\\text{Recall}}$$\n",
        "Representa una media arm√≥nica entre el Precision y Recall, de forma que enterega un equilibrio entre el desempe√±o del modelo para ambas de estas m√©tricas.\n",
        "5. La m√©tricas recomendadas para los casos mostrados son:\n",
        "- Considerando que el matenimiento predictivo de fallas en la maquinaria busca reducir el tiempo de inactividad operacional por fallas y suponiendo que prepararse para una falla y que no haya falla implica un menor costo que remendar la falla una vez ocurre, preferimos que hayan falsos positivos sobre falsos negativos. Es decir, preferimos que nuestro modelo sobre prediga fallas de forma que tienda a reportar m√°s fallas de las que ocurren, de forma de minimizar las fallas imprevistas que son muy costosas. En este sentido la m√©trica recomendada es el recall que mide exactamente esto y penaliza por falsos negativos, es decir cuando el modelo dice que no hay falla pero realmente si hay.\n",
        "- Para la detecci√≥n de enfermedades altamente contagiosas preferimos siempre estar lo m√°s conscientes posibles de la cantidad de enfermos. Es decir, nos gustar√≠a que nuestro modelo prediga m√°s personas enfermas que no enfermas. As√≠ es necesario exigir al modelo tener pocos falsos negativos, es decir pocos casos que el modelo dice que no est√°n enfermos pero en realidad si lo estaban. Nuevamente la m√©trica que penaliza por falsos negativos y es recomendada es el Recall.\n",
        "- Para aprobar cr√©ditos de alto riesgo, nos gustar√≠a maximizar la probabilidad de pago del cr√©dito del cliente. Para este objetivo el modelo debe aprobar cr√©ditos cuando la probabilidad de pago es relativamente alta. En ese sentido, si el modelo no aprueba un cr√©dito para un cliente con probabilidad alta de pago o realiza un falso negativo, la p√©rdida del banco en este caso no es tan alta dado que pierde principalmente la oportunidad de ofrecer el cr√©dito. POr otro lado, si el modelo aprueba el cr√©dito para un cliente muy riesgoso que finalmente incurre en impago, el costo para el banco de este error es el del valor del cr√©dito y en definitiva es un costo mayor. En ese sentido nos gustar√≠a un modelo que tenga pocos falsos positivos o que otorgue el cr√©dito siendo que la persona no pagar√°. Una m√©trica adecuada que penaliza por este valor es el Precision, que es la m√©trica recomendada.\n",
        "- Para detectar cr√≠mines podemos nuevamente evaluar el costo de cometer errores de predicci√≥n, en este caso predecir que una persona realiz√≥ un crimen cuando no lo hizo tiene un costo alto o es una acusaci√≥n grave de hacer, por otro lado predecir que una persona no realiz√≥ un crimen cuando si lo hizo deja en impunidad este crimen y es tambi√©n algo de relevancia para el modelo. En este sentido, una m√©trica recomendable es el F1-Score que encuentra un balance entre Precision y Recall que ser√≠a este caso, donde no queremos priorizar una mala clasificaci√≥n por sobre otra.\n",
        "6. La calibraci√≥n de modelos se utiliza para ajustar la probabilidad de clases que entregan las predicciones del modelo de forma que se ajusten a la probabilidad de clases real que se observa en los datos. Se usa para regularizar la salida de modelos de aprendizaje en general, sobre la distribuci√≥n de datos predichos como un conjunto. Muchos modelos no tienen este tipo de regularizaci√≥n agregada naturalmente como XGBoost, sin embargo hay otros que si tienen esta consideraci√≥n como regresi√≥n log√≠stica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte pr√°ctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/61L8z0w/renacin-by-volframio-dcirf4l-fullview.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "Tras el tr√°gico despido de la m√≠tica mascota de Maip√∫, Renac√≠n decide adentrarse como consultor en el mercado futbolero, el cu√°l (para variar...) est√° cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea ser√° asesorar a los directivos de los clubes sobre cu√°l jugador comprar y cu√°l no, Renac√≠n desea generar modelos predictivos que evalu√©n distintas caracter√≠sticas de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condici√≥n de corporeo le impidi√≥ tomar la versi√≥n anterior de MDS7202, por lo que este motivo Renac√≠n contrata a su equipo para lograr su objetivo final. Dado que a√∫n tiene fuertes v√≠nculos con la direcci√≥n de deportes de la municipalidad, el corporeo le entrega base de datos con las estad√≠sticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deber√°n trabajar con el csv `statsplayers.csv`, donde deber√°n aplicar algoritmos de aprendizaje supervisado de clasificaci√≥n en base a caracter√≠sticas que describen de jugadores de f√∫tbol.\n",
        "\n",
        "Para comenzar cargue el dataset se√±alado y a continuaci√≥n vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las caracter√≠sticas principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "execution_count": 2,
      "metadata": {
        "id": "mX6iwOWUfrp_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexi√≥n drive-colab\n"
          ]
        }
      ],
      "source": [
        "# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = 'Direcci√≥n donde tiene los archivos en el Drive'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paquetes a utilizar\n",
        "# Cl√°sicos\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>National_Position</th>\n",
              "      <th>Club_Position</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Preffered_Foot</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Rate</th>\n",
              "      <th>Weak_foot</th>\n",
              "      <th>...</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Shot_Power</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>Long_Shots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>Freekick_Accuracy</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>LS</td>\n",
              "      <td>LW</td>\n",
              "      <td>185</td>\n",
              "      <td>80</td>\n",
              "      <td>Right</td>\n",
              "      <td>32</td>\n",
              "      <td>High / Low</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>85</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>90</td>\n",
              "      <td>81</td>\n",
              "      <td>76</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>RW</td>\n",
              "      <td>RW</td>\n",
              "      <td>170</td>\n",
              "      <td>72</td>\n",
              "      <td>Left</td>\n",
              "      <td>29</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>85</td>\n",
              "      <td>95</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>74</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Neymar</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>LW</td>\n",
              "      <td>LW</td>\n",
              "      <td>174</td>\n",
              "      <td>68</td>\n",
              "      <td>Right</td>\n",
              "      <td>25</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>61</td>\n",
              "      <td>62</td>\n",
              "      <td>78</td>\n",
              "      <td>89</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>84</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Luis Su√°rez</td>\n",
              "      <td>Uruguay</td>\n",
              "      <td>LS</td>\n",
              "      <td>ST</td>\n",
              "      <td>182</td>\n",
              "      <td>85</td>\n",
              "      <td>Right</td>\n",
              "      <td>30</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>69</td>\n",
              "      <td>77</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manuel Neuer</td>\n",
              "      <td>Germany</td>\n",
              "      <td>GK</td>\n",
              "      <td>GK</td>\n",
              "      <td>193</td>\n",
              "      <td>92</td>\n",
              "      <td>Right</td>\n",
              "      <td>31</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name Nationality National_Position Club_Position  Height  \\\n",
              "0  Cristiano Ronaldo    Portugal                LS            LW     185   \n",
              "1       Lionel Messi   Argentina                RW            RW     170   \n",
              "2             Neymar      Brazil                LW            LW     174   \n",
              "3        Luis Su√°rez     Uruguay                LS            ST     182   \n",
              "4       Manuel Neuer     Germany                GK            GK     193   \n",
              "\n",
              "   Weight Preffered_Foot  Age        Work_Rate  Weak_foot  ...  Agility  \\\n",
              "0      80          Right   32       High / Low          4  ...       90   \n",
              "1      72           Left   29  Medium / Medium          4  ...       90   \n",
              "2      68          Right   25    High / Medium          5  ...       96   \n",
              "3      85          Right   30    High / Medium          4  ...       86   \n",
              "4      92          Right   31  Medium / Medium          4  ...       52   \n",
              "\n",
              "   Jumping  Heading  Shot_Power  Finishing  Long_Shots  Curve  \\\n",
              "0       95       85          92         93          90     81   \n",
              "1       68       71          85         95          88     89   \n",
              "2       61       62          78         89          77     79   \n",
              "3       69       77          87         94          86     86   \n",
              "4       78       25          25         13          16     14   \n",
              "\n",
              "   Freekick_Accuracy  Penalties  Volleys  \n",
              "0                 76         85       88  \n",
              "1                 90         74       85  \n",
              "2                 84         81       83  \n",
              "3                 84         85       88  \n",
              "4                 11         47       11  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"../temp/stats_players.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicci√≥n de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificaci√≥n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JhC2sZj9dSI1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de seleccionados nacionales: 1075\n",
            "Cantidad de no seleccionados nacionales: 16513\n",
            "Proporci√≥n clase 1 respecto a clase 0: 0.06510022406588749\n"
          ]
        }
      ],
      "source": [
        "# 1.\n",
        "# Creaci√≥n de columna\n",
        "data[\"label\"] = data[\"National_Position\"].apply(lambda x:1 if pd.notna(x) and x.strip() != '' else 0)\n",
        "# 2.\n",
        "# Ejemplos por clase\n",
        "print(\"Cantidad de seleccionados nacionales:\",data[\"label\"].value_counts()[1])\n",
        "print(\"Cantidad de no seleccionados nacionales:\",data[\"label\"].value_counts()[0])\n",
        "print(\"Proporci√≥n clase 1 respecto a clase 0:\",data[\"label\"].value_counts()[1]/data[\"label\"].value_counts()[0])\n",
        "# Se observa un desbalance de clases, donde un porcentaje menor de los jugadores son jugadores seleccionados\n",
        "# mientras que la mayor√≠a son no seleccionados.\n",
        "# 3. y 4.\n",
        "# ColumnTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# Utilizamos RobustScaler, dado que asumir distribuci√≥n normal sobre las 31 columnas num√©ricas pueden ser\n",
        "# inadecuado. MinMaxScaler puede ser susceptible a outliers que seg√∫n el reporte no se aprecian en los histogramas\n",
        "# pero no hemos a√∫n confirmado si hay o no.\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "robust_scaler = RobustScaler()\n",
        "# Utilizamos OneHotEncoder para las variables categ√≥ricas que no son identificadores como el nombre y que no son National_Position\n",
        "# dado que construimos la etiqueta con esta columna. Las columnas categ√≥ricas a incluir pueden en su mayor√≠a ser descompuestas en\n",
        "# pocas variables binarias por onehot, salvo por el pa√≠s. Luego podemos reevaluar esta decisi√≥n.\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "# Fuera de la variable National_Position, del reporte vemos que Club_Position tiene 1 valor faltante. Por esto necesitamos un imputador.\n",
        "# Utilizamos uno simple para pocos casos y de poco impacto que se asegure de que no hay nulos para ninguna variable, creamos uno por \n",
        "# tipo de variable.\n",
        "from sklearn.impute import SimpleImputer\n",
        "sim_imp_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "sim_imp_num = SimpleImputer(strategy=\"mean\")\n",
        "\n",
        "\n",
        "# Definimos las columnas a transformar\n",
        "categorical_columns = data.select_dtypes(include=['object', 'category']).drop(['Name', 'National_Position'], axis=1).columns.tolist()\n",
        "numerical_columns = data.select_dtypes(include=['int64', 'float64']).drop(['label'],axis=1).columns.tolist()\n",
        "\n",
        "# Pipelines separados por variable \n",
        "from sklearn.pipeline import Pipeline\n",
        "cat_pipe = Pipeline([\n",
        "    ('Imputer_mode',sim_imp_cat),\n",
        "    ('OneHotEncoder',one_hot)\n",
        "])\n",
        "num_pipe = Pipeline([\n",
        "    ('Imputer_mean',sim_imp_num),\n",
        "    ('RobustScaler',robust_scaler)\n",
        "])\n",
        "# ColumnTransformer\n",
        "col_transformer = ColumnTransformer([\n",
        "    (\"Categorical Transformation\",cat_pipe,categorical_columns),\n",
        "    (\"Numerical Transformation\",num_pipe,numerical_columns)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporci√≥n queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribuci√≥n original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentaci√≥n de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la secci√≥n de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lLtlXGTPdWAV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 860, number of negative: 13210\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2649\n",
            "[LightGBM] [Info] Number of data points in the train set: 14070, number of used features: 142\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061123 -> initscore=-2.731797\n",
            "[LightGBM] [Info] Start training from score -2.731797\n"
          ]
        }
      ],
      "source": [
        "# 1. Separamos la data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Ajustamos la data que nos interesa para el entrenamiento\n",
        "X = data.drop(['Name','National_Position','label'],axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Separamos aleatoriamente con mantenci√≥n de proporci√≥n de clases y seleccionamos un 20% como test arbitrariamente.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30,stratify=y)\n",
        "# 2. Pipeline XGBoost\n",
        "# Importamos\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "# Instanciamos los clasificadores\n",
        "xgb_model = XGBClassifier()\n",
        "lgbm_model = LGBMClassifier()\n",
        "\n",
        "# Creamos la instancia\n",
        "pipeline_xgboost = Pipeline([\n",
        "    ('Column_Transformer',col_transformer),\n",
        "    ('xgb_classifier',xgb_model)\n",
        "])\n",
        "pipeline_lightgbm = Pipeline([\n",
        "    ('Column_Transformer',col_transformer),\n",
        "    ('lgbm_classifier',lgbm_model)\n",
        "])\n",
        "# 3. Entrenamos\n",
        "y_pred_xgboost = pipeline_xgboost.fit(X_train, y_train)\n",
        "y_pred_lgbm = pipeline_lightgbm.fit(X_train, y_train)\n",
        "y_pred_xgboost = pipeline_xgboost.predict(X_test)\n",
        "y_pred_lgbm = pipeline_lightgbm.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las m√©tricas accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qu√© implican los valores de accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c√≥mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qu√© m√©trica le parece m√°s adecuada y concluya qu√© modelo tiene un mejor desempe√±o. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QNmI_tbbdQte"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M√©tricas de desempe√±o XGBoost:\n",
            "Accuracy: 0.9499715747583855\n",
            "Precisi√≥n para la clase 1: 0.6611570247933884\n",
            "Recall para la clase 1: 0.37209302325581395\n",
            "F1-Score para la clase 1: 0.47619047619047616\n",
            "Matriz de Confusi√≥n:\n",
            "[[3262   41]\n",
            " [ 135   80]]\n",
            "Clasification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      3303\n",
            "           1       0.66      0.37      0.48       215\n",
            "\n",
            "    accuracy                           0.95      3518\n",
            "   macro avg       0.81      0.68      0.72      3518\n",
            "weighted avg       0.94      0.95      0.94      3518\n",
            "\n",
            "M√©tricas de desempe√±o LGBM:\n",
            "Accuracy: 0.9502558271745309\n",
            "Precisi√≥n para la clase 1: 0.6666666666666666\n",
            "Recall para la clase 1: 0.37209302325581395\n",
            "F1-Score para la clase 1: 0.47761194029850745\n",
            "Matriz de Confusi√≥n:\n",
            "[[3263   40]\n",
            " [ 135   80]]\n",
            "Clasification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      3303\n",
            "           1       0.67      0.37      0.48       215\n",
            "\n",
            "    accuracy                           0.95      3518\n",
            "   macro avg       0.81      0.68      0.73      3518\n",
            "weighted avg       0.94      0.95      0.94      3518\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. \n",
        "# Importamos\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix\n",
        "# XGBoost\n",
        "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
        "precision_xgboost = precision_score(y_test, y_pred_xgboost, average=None)\n",
        "recall_xgboost = recall_score(y_test, y_pred_xgboost, average=None)\n",
        "f1_xgboost = f1_score(y_test, y_pred_xgboost, average=None)\n",
        "cm_xgboost = confusion_matrix(y_test, y_pred_xgboost)\n",
        "report_xgboost = classification_report(y_test, y_pred_xgboost)\n",
        "print(\"M√©tricas de desempe√±o XGBoost:\")\n",
        "print(\"Accuracy:\",accuracy_xgboost)\n",
        "print(\"Precisi√≥n para la clase 1:\",precision_xgboost[1])\n",
        "print(\"Recall para la clase 1:\",recall_xgboost[1])\n",
        "print(\"F1-Score para la clase 1:\",f1_xgboost[1])\n",
        "print(\"Matriz de Confusi√≥n:\")\n",
        "print(cm_xgboost)\n",
        "print(\"Clasification Report:\")\n",
        "print(report_xgboost)\n",
        "# LightGBM\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "precision_lgbm = precision_score(y_test, y_pred_lgbm, average=None)\n",
        "recall_lgbm = recall_score(y_test, y_pred_lgbm, average=None)\n",
        "f1_lgbm = f1_score(y_test, y_pred_lgbm, average=None)\n",
        "cm_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
        "report_lgbm = classification_report(y_test, y_pred_lgbm)\n",
        "print(\"M√©tricas de desempe√±o LGBM:\")\n",
        "print(\"Accuracy:\",accuracy_lgbm)\n",
        "print(\"Precisi√≥n para la clase 1:\",precision_lgbm[1])\n",
        "print(\"Recall para la clase 1:\",recall_lgbm[1])\n",
        "print(\"F1-Score para la clase 1:\",f1_lgbm[1])\n",
        "print(\"Matriz de Confusi√≥n:\")\n",
        "print(cm_lgbm)\n",
        "print(\"Clasification Report:\")\n",
        "print(report_lgbm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. De las m√©tricas entregadas, vemos que se tiene un accuracy alto lo cual quiere decir que el total de predicciones que hace el modelo son en su mayor√≠a correctas sin distinguir por clase. Sin embargo, si nos fijamos en la clase 1 minoritaria se tienen m√©tricas muy menores a lo que se esperar√≠a de un accuracy alto y de las m√©tricas para la clase 0, lo cual se debe al desbalance de clases. En primer lugar, el precision para ambos casos es de aproximadamente 0.66, es decir de todas las predicciones de 1 que realiz√≥ el modelo solo acerto 2/3 de ellas aproximadamente. El recall de 0.37 indica que de los valores con etiqueta 1 real, el modelo predice correctamente solo un 37% lo cual es desalentador. La cantidad de elementos de la clase minoritaria hace que los modelos sean menos potentes para detectar a la clase minoritaria lo cual es reflejado por el precision y recall de la clase 1. Cabe mencionar que F1-Score es cercano a 1/2 y el promedio arm√≥nico de ambas m√©tricas descritas es bajo y hay un mal desempe√±o en general.\n",
        "3. La mejor m√©trica en el caso de que nuestro objetivo sea predecir si un jugador es o no seleccionado nacional primero debe ser respecto a la clase 1, es decir evaluamos qu√© tan bueno es el modelo para predecir la clase minoritaria que es de inter√©s. La m√©trica podemos recomendarla acorde al costo que significar√≠a tener un falso positivo (Precision) o falso negativo (Recall). En este caso no hay un costo espec√≠fico asociado a privilegiar uno sobre el otro especialmente, pero si buscamos una m√©trica que considere ambos para predecir mejor la clase minoritaria. Por esto la m√©trica recomendada es el F1-Score que encuentra el balance entre ambas m√©tricas y considera ambos efectos.\n",
        "Finalmente, ambos modelos se comportan muy similarmente y no hay una diferencia sustancial que valga la pena destacar. Solo LGBM clasifica un ejemplo de la clase 0 corectamente m√°s que XGBoost, pero no necesariamente puede deberse a que un modelo es mejor que el otro basados solo en ese elemento. En ese sentido, ambos modelos se desempe√±an de igual forma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicci√≥n de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renac√≠n escuch√≥ a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posici√≥n en la cancha en la que juega. Y adem√°s, que hay bastantes jugadores nuevos que no tienen muy claro en que posici√≥n verdaderamente brillar√≠an, por lo que actualmente puede que actualmente est√©n jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer an√°lisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posici√≥n de los jugadores en la cancha seg√∫n sus caracter√≠sticas.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renac√≠n les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elecci√≥n del clasificador se justificar en base a la siguiente [gu√≠a](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificaci√≥n.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores se√±alados en esta secci√≥n y gu√°rdelos en la variable `label`.\n",
        "2. Cuente cu√°ntos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluaci√≥n de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ir_7zMh2i1vg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                Name Club_Position           label\n",
            "0  Cristiano Ronaldo            LW  central_ataque\n",
            "1       Lionel Messi            RW  central_ataque\n",
            "2             Neymar            LW  central_ataque\n",
            "3        Luis Su√°rez            ST          ataque\n",
            "4       Manuel Neuer            GK         arquero\n"
          ]
        }
      ],
      "source": [
        "# Diccionario que mapea las posiciones a las etiquetas correspondientes\n",
        "posicion_dict = {\n",
        "    'ST': 'ataque', 'CF': 'ataque',\n",
        "    'RW': 'central_ataque', 'CAM': 'central_ataque', 'LW': 'central_ataque',\n",
        "    'RM': 'central', 'CM': 'central', 'LM': 'central',\n",
        "    'RWB': 'central_defensa', 'CDM': 'central_defensa', 'LWB': 'central_defensa',\n",
        "    'RB': 'defensa', 'CB': 'defensa', 'LB': 'defensa',\n",
        "    'GK': 'arquero'\n",
        "}\n",
        "\n",
        "# Aplicar la funci√≥n lambda usando el diccionario\n",
        "df_labeled = data.copy()\n",
        "df_labeled['label'] = df_labeled['Club_Position'].map(posicion_dict)\n",
        "\n",
        "# Filtrar los valores no deseados: 'Sub' y 'Res'\n",
        "df_labeled = df_labeled[~df_labeled['Club_Position'].isin(['Sub', 'Res'])]\n",
        "\n",
        "# Revisar los primeros resultados\n",
        "print(df_labeled[['Name', 'Club_Position', 'label']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "defensa            1180\n",
            "central             907\n",
            "arquero             632\n",
            "central_ataque      581\n",
            "ataque              430\n",
            "central_defensa     209\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Contamos el n√∫mero de jugadores por clase\n",
        "conteo_clases = df_labeled['label'].value_counts()\n",
        "print(conteo_clases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Definir las caracter√≠sticas y etiquetas\n",
        "X = df_labeled[['Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle', 'Standing_Tackle',\n",
        "                'Aggression', 'Reactions', 'Interceptions', 'Vision', 'Composure',\n",
        "                'Crossing', 'Short_Pass', 'Long_Pass', 'Acceleration', 'Speed', 'Stamina',\n",
        "                'Strength', 'Balance', 'Agility', 'Jumping', 'Heading', 'Shot_Power',\n",
        "                'Finishing', 'Long_Shots', 'Curve', 'Freekick_Accuracy', 'Penalties', 'Volleys']]\n",
        "\n",
        "y = df_labeled['label']\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.43103802672147995\n",
            "[nan 'central' 'central_ataque' 'arquero' 'ataque' 'defensa'\n",
            " 'central_defensa']\n",
            "(2768, 28) (2768,)\n",
            "Accuracy: 0.7301451750640479\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        arquero       1.00      0.99      0.99       188\n",
            "         ataque       0.81      0.83      0.82       144\n",
            "        central       0.59      0.42      0.49       251\n",
            " central_ataque       0.42      0.61      0.50       179\n",
            "central_defensa       0.50      0.02      0.04        55\n",
            "        defensa       0.85      0.94      0.89       354\n",
            "\n",
            "       accuracy                           0.73      1171\n",
            "      macro avg       0.69      0.64      0.62      1171\n",
            "   weighted avg       0.73      0.73      0.71      1171\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calcular el porcentaje de valores faltantes en y_train\n",
        "porcentaje_nan_y_train = y_train.isna().mean()\n",
        "print(porcentaje_nan_y_train)\n",
        "\n",
        "# Verificar valores √∫nicos en y_test\n",
        "print(y_test.unique())\n",
        "\n",
        "# Notamos que existen valores Nan en y_test, por lo que los eliminamos y nos aseguramos de eliminar los mismos registrospara x_test\n",
        "X_test_clean = X_test[~y_test.isna()]\n",
        "y_test_clean = y_test.dropna()\n",
        "\n",
        "# Eliminar filas con valores NaN en y_train y los correspondientes en X_train\n",
        "X_train_clean = X_train[~y_train.isna()]  \n",
        "y_train_clean = y_train.dropna()         \n",
        "\n",
        "# Verificar que ambos tengan el mismo n√∫mero de muestras\n",
        "print(X_train_clean.shape, y_train_clean.shape)\n",
        "\n",
        "# Creamos el pipeline con estandarizaci√≥n y SGDClassifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', SGDClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Entrenamos el modelo\n",
        "pipeline.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predecir sobre el conjunto de prueba\n",
        "y_pred = pipeline.predict(X_test_clean)\n",
        "\n",
        "# Evaluar el rendimiento\n",
        "print(\"Accuracy:\", accuracy_score(y_test_clean, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_clean, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A partir de los pasos a seguir indicados en la gu√≠a, escogemos el m√©todo SGDClassifier para la clasificaci√≥n, esto debido a que estamos prediciendo una categor√≠a y nuestro dataset tiene m√°s de 100000 datos.\n",
        "\n",
        "Con respecto a los resultados obtenidos, notamos que hay un buen rendimiento con respecto a las predicciones para arquero y defensa (alta precisi√≥n y recall). Por otro lado, vemos que al modelo se le dificulta hacer la clasificaci√≥n para las posiciones intermedias (central y central_defensa), esto puede ser debido, posiblemente a que las caracter√≠sticas de los jugadores en estas posiciones son m√°s similares entre s√≠ o hay menos ejemplos para entrenar.\n",
        "\n",
        "En general, considerando el accuracy, vemos que el 73% de las predicciones del modelo son correctas, lo cual es aceptable, pero no excelente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Despu√©s de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el f√∫tbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teor√≠a es que muchos artistas del g√©nero urbano chileno, con sus habilidades √∫nicas y su disciplina, podr√≠an destacarse tambi√©n en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino tambi√©n demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 2.1 ¬øQu√© modelo de √°rbol es m√°s de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la secci√≥n 1.1. Para determinar cu√°l modelo de √°rbol ser√≠a m√°s adecuado para la tarea en cuesti√≥n, utilice PyCaret. Este deber√° centrarse exclusivamente en modelos de tipo √°rbol. Jere ha especificado que busca un modelo que tome decisiones r√°pidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos] \n",
        "\n",
        "Para la comparaci√≥n, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "3. Tras realizar la comparaci√≥n de modelos, seleccione aquel que muestre el mejor rendimiento en t√©rminos de velocidad y precisi√≥n, especialmente en la reducci√≥n de falsos positivos. Utilice la funci√≥n `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusi√≥n Matrix**: ¬øC√≥mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: ¬øEs acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: ¬øCu√°les son las variables con mejor desempe√±o? ¬øA qu√© podr√≠a deberse esto?\n",
        "  - **Learning Curve**: ¬øEl modelo presenta alg√∫n problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kUCjOjsEYUXL"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pycaret'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"
          ]
        }
      ],
      "source": [
        "from pycaret.datasets import get_data\n",
        "from pycaret.classification import *\n",
        "import os\n",
        "\n",
        "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
        "\n",
        "#Continuar c√≥digo aqu√≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 2.2 Reducci√≥n de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Adem√°s, se debe proceder a realizar una reducci√≥n de dimensionalidad basada en la importancia de las caracter√≠sticas.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las caracter√≠sticas disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo est√© entrenado, eval√∫e y clasifique las caracter√≠sticas seg√∫n su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificaci√≥n para ejecutar una b√∫squeda recursiva de eliminaci√≥n de caracter√≠sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe√±o del modelo hasta identificar las N caracter√≠sticas m√°s cr√≠ticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de caracter√≠sticas, entrene un nuevo modelo y eval√∫e su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez? [2 puntos]\n",
        "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre n√∫mero de festures y desempe√±o. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar m√°s features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwUd_nsuDOe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 2.3 Calibraci√≥n Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos m√°s modulares, se recomienda realizar una calibraci√≥n del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un m√©todo de calibraci√≥n que asegure que las probabilidades generadas incrementen de manera mon√≥tona. Una m√©trica ampliamente utilizada para evaluar la precisi√≥n de la calibraci√≥n de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como despu√©s de la calibraci√≥n. Esto le permitir√° realizar una comparaci√≥n cuantitativa y determinar si la calibraci√≥n ha mejorado el rendimiento del modelo. Para m√°s informaci√≥n sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibraci√≥n, examine y comente los resultados obtenidos. A su an√°lisis a√±ada una comparaci√≥n visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k-ao0mOU64Ru",
        "Jg_9jBqtgRDO",
        "JdcucZhp-M_0",
        "Qfre1YsSDqla",
        "Bv1HOfcNEPF4",
        "poc9HSNBFeKO",
        "uy5VMU6ae_g6",
        "9bL2m8nNojXM",
        "rD8pQ5Zfq8dE",
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
