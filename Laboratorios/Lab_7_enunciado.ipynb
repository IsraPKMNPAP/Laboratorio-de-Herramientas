{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tgm8mCA9Dp3"
      },
      "source": [
        "# Laboratorio 7: Clasificaci√≥n ü§ó\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Primavera 2024</strong></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Kc_ibM9GXH"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicol√°s Ojeda, Melanie Pe√±a, Valentina Rojas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9dUSltr9JrN"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Luis Pic√≥n\n",
        "- Nombre de alumno 2: Israel Astudillo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/IsraPKMNPAP/Laboratorio-de-Herramientas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBa48PDF9OHw"
      },
      "source": [
        "### Temas a tratar\n",
        "- Clasificaci√≥n en problemas desbalanceados\n",
        "- Lightgbm y xgboost\n",
        "- Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhnnMx49Qrh"
      },
      "source": [
        "### Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzJ48Vv8quO"
      },
      "source": [
        "\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo trabajar con problemas de clasificaci√≥n con clases desbalanceadas.\n",
        "- Aplicar los modelos lightgbm y xgboost.\n",
        "- Practicar Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ao0mOU64Ru"
      },
      "source": [
        "# Parte Te√≥rica [12 puntos]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXKwPDmxcEV"
      },
      "source": [
        "1. Explique cu√°l es la diferencia entre los datos de entrenamiento y validaci√≥n. [1 punto]\n",
        "\n",
        "2. Explique cu√°l es el principal desaf√≠o al trabajar problemas de clasificaci√≥n con data no supervisada. [1 punto]\n",
        "\n",
        "3. Explique en **sus palabras** qu√© es la matriz de confusi√≥n y para qu√© se utiliza. [1 puntos]\n",
        "\n",
        "4. Escriba la f√≥rmula de las siguientes m√©tricas y explique con **sus palabras** c√≥mo se interpretan. [1 punto cada uno]\n",
        "\n",
        "  * Accuracy\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1 score\n",
        "\n",
        "5. Explique qu√© m√©trica recomendar√≠a para los siguientes contextos de clasificaci√≥n. [1 punto cada uno]\n",
        "\n",
        "  * Mantenimiento predictivo de fallas de maquinaria pesada en la industria minera.  \n",
        "  * Detecci√≥n de enfermedades altamente contagiosas.\n",
        "  * Aprobaci√≥n de cr√©ditos de alto riesgo.\n",
        "  * Detecci√≥n de cr√≠menes.\n",
        "\n",
        "6. Explique qu√© es la calibraci√≥n de modelos y para qu√© se usa. [1 punto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4QMWD8-FPk"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFdD1aK-ICa"
      },
      "source": [
        "1. Los datos de entrenamiento son el conjunto de datos disponibles que son utilizados por alg√∫n modelo de aprendizaje para extraer relaciones o patrones que describan alguna variable dependiente de inter√©s. El modelo se basa en los datos de entrenamiento para generar predicciones de la variable de inter√©s utilizando los patrones que encontr√≥ en los datos de entrenamiento. Por otro lado, los datos de validaci√≥n son los utilizados para ajustar el modelo entrenado, sus hiperpar√°metros y revisar si cumple los est√°ndares m√≠nimos en primera instancia sobre un conjunto reducido de datos. El conjunto de testeo es un conjunto de datos sobre el cual el modelo ya entrenado y validado realiza predicciones de la variable dependiente, de forma de compararla luego con el valor real de esta variable y concluir sobre el desempe√±o general del modelo para predecir esta variable en base a m√©tricas. Cabe destacar que estos conjuntos deben ser disjuntos entre s√≠ para evitar sesgos dados por data leakage, es decir no queremos darle al modelo informaci√≥n de entrenamiento que se incluya en su testeo de forma de conocer el verdadero desempe√±o del modelo y caracterizar su capacidad de generalizaci√≥n.\n",
        "2. El principal desaf√≠o al trabajar con problemas de clasificaci√≥n con datos no supervisados es que al buscar agrupar datos por similaridad en sus caracter√≠sticas, los grupos encontrados pueden no ser diferenciables, identificables o interpretables y por sobre todo no se sabe a priori cu√°ntos grupos de datos existen realmente en la data, es decir se desconoce la cantidad de clases que caracterizan a la data y es este precisamente el problema que la clasificaci√≥n no supervisada busca resolver.\n",
        "3. La matriz de confusi√≥n es una forma de organizar y ordenar las predicciones correctas e incorrectas que realiza un modelo. Muestra la cantidad de aciertos y desaciertos por clase, permitiendo visualizar posibles problemas tempranamente como desbalance de clases y permite caracterizar el comportamiento predicitivo del modelo en base a las predicciones que realiza. Se usa como base para construir las distintas m√©tricas de evaluaci√≥n de modelos que representan razones entre predicciones correctas o incorrectas por sobre las totales para cierta clase o en general, dependiendo de la m√©trica.\n",
        "4. Se considerar√° la f√≥rmula para el caso de clasificaci√≥n binaria por simplicidad, donde TP son los verdaderos positivos, TN los verdaderos negativos, FP los falsos positivos y FN los falsos negativos. El Accuracy que viene dado por: \n",
        "$$\\text{Accuracy}=\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
        "Representa el porcentaje de aciertos que el modelo tuvo respecto al total de predicciones que realiz√≥.\n",
        "\n",
        "El Precision viene dado por:\n",
        "$$\\text{Precision}=\\frac{TP}{TP+FP}$$\n",
        "Representa el porcentaje de aciertos positivos que el modelo realiz√≥, es decir del total de positivos que predijo cuantos realmente eran positivos.\n",
        "\n",
        "El Recall viene dado por:\n",
        "$$\\text{Recall}=\\frac{TP}{TP+FN}$$\n",
        "Representa el porcentaje de clasificaciones positivas correctas del total de elementos con clase positiva. Es decir, de todos los elementos de clases positiva, cuantos identific√≥ correctamente el modelo.\n",
        "\n",
        "El F1-Score viene dado por:\n",
        "$$\\text{F1-Score}=2\\cdot\\frac{\\text{Precision}\\cdot\\text{Recall}}{\\text{Precision}+\\text{Recall}}$$\n",
        "Representa una media arm√≥nica entre el Precision y Recall, de forma que enterega un equilibrio entre el desempe√±o del modelo para ambas de estas m√©tricas.\n",
        "5. La m√©tricas recomendadas para los casos mostrados son:\n",
        "- Considerando que el matenimiento predictivo de fallas en la maquinaria busca reducir el tiempo de inactividad operacional por fallas y suponiendo que prepararse para una falla y que no haya falla implica un menor costo que remendar la falla una vez ocurre, preferimos que hayan falsos positivos sobre falsos negativos. Es decir, preferimos que nuestro modelo sobre prediga fallas de forma que tienda a reportar m√°s fallas de las que ocurren, de forma de minimizar las fallas imprevistas que son muy costosas. En este sentido la m√©trica recomendada es el recall que mide exactamente esto y penaliza por falsos negativos, es decir cuando el modelo dice que no hay falla pero realmente si hay.\n",
        "- Para la detecci√≥n de enfermedades altamente contagiosas preferimos siempre estar lo m√°s conscientes posibles de la cantidad de enfermos. Es decir, nos gustar√≠a que nuestro modelo prediga m√°s personas enfermas que no enfermas. As√≠ es necesario exigir al modelo tener pocos falsos negativos, es decir pocos casos que el modelo dice que no est√°n enfermos pero en realidad si lo estaban. Nuevamente la m√©trica que penaliza por falsos negativos y es recomendada es el Recall.\n",
        "- Para aprobar cr√©ditos de alto riesgo, nos gustar√≠a maximizar la probabilidad de pago del cr√©dito del cliente. Para este objetivo el modelo debe aprobar cr√©ditos cuando la probabilidad de pago es relativamente alta. En ese sentido, si el modelo no aprueba un cr√©dito para un cliente con probabilidad alta de pago o realiza un falso negativo, la p√©rdida del banco en este caso no es tan alta dado que pierde principalmente la oportunidad de ofrecer el cr√©dito. POr otro lado, si el modelo aprueba el cr√©dito para un cliente muy riesgoso que finalmente incurre en impago, el costo para el banco de este error es el del valor del cr√©dito y en definitiva es un costo mayor. En ese sentido nos gustar√≠a un modelo que tenga pocos falsos positivos o que otorgue el cr√©dito siendo que la persona no pagar√°. Una m√©trica adecuada que penaliza por este valor es el Precision, que es la m√©trica recomendada.\n",
        "- Para detectar cr√≠mines podemos nuevamente evaluar el costo de cometer errores de predicci√≥n, en este caso predecir que una persona realiz√≥ un crimen cuando no lo hizo tiene un costo alto o es una acusaci√≥n grave de hacer, por otro lado predecir que una persona no realiz√≥ un crimen cuando si lo hizo deja en impunidad este crimen y es tambi√©n algo de relevancia para el modelo. En este sentido, una m√©trica recomendable es el F1-Score que encuentra un balance entre Precision y Recall que ser√≠a este caso, donde no queremos priorizar una mala clasificaci√≥n por sobre otra.\n",
        "6. La calibraci√≥n de modelos se utiliza para ajustar la probabilidad de clases que entregan las predicciones del modelo de forma que se ajusten a la probabilidad de clases real que se observa en los datos. Se usa para regularizar la salida de modelos de aprendizaje en general, sobre la distribuci√≥n de datos predichos como un conjunto. Muchos modelos no tienen este tipo de regularizaci√≥n agregada naturalmente como XGBoost, sin embargo hay otros que si tienen esta consideraci√≥n como regresi√≥n log√≠stica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_9jBqtgRDO"
      },
      "source": [
        "# Parte pr√°ctica [48 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slm6yRfdfZwS"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/61L8z0w/renacin-by-volframio-dcirf4l-fullview.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "Tras el tr√°gico despido de la m√≠tica mascota de Maip√∫, Renac√≠n decide adentrarse como consultor en el mercado futbolero, el cu√°l (para variar...) est√° cargado en especulaciones.\n",
        "\n",
        "Como su principal tarea ser√° asesorar a los directivos de los clubes sobre cu√°l jugador comprar y cu√°l no, Renac√≠n desea generar modelos predictivos que evalu√©n distintas caracter√≠sticas de los jugadores; todo con el fin de tomar decisiones concretas basadas en los datos.\n",
        "\n",
        "Sin embargo, su condici√≥n de corporeo le impidi√≥ tomar la versi√≥n anterior de MDS7202, por lo que este motivo Renac√≠n contrata a su equipo para lograr su objetivo final. Dado que a√∫n tiene fuertes v√≠nculos con la direcci√≥n de deportes de la municipalidad, el corporeo le entrega base de datos con las estad√≠sticas de cada jugador para que su equipo empieze a trabajar ya con un dataset listo para ser usado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnbx7RwHfkue"
      },
      "source": [
        "**Los Datos**\n",
        "\n",
        "Para este laboratorio deber√°n trabajar con el csv `statsplayers.csv`, donde deber√°n aplicar algoritmos de aprendizaje supervisado de clasificaci√≥n en base a caracter√≠sticas que describen de jugadores de f√∫tbol.\n",
        "\n",
        "Para comenzar cargue el dataset se√±alado y a continuaci√≥n vea el reporte **`Player_Stats_Report.html`** (adjunto en la carpeta del enunciado) que describe las caracter√≠sticas principales del `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mX6iwOWUfrp_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexi√≥n drive-colab\n"
          ]
        }
      ],
      "source": [
        "# Si usted est√° utilizando Colabolatory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = 'Direcci√≥n donde tiene los archivos en el Drive'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paquetes a utilizar\n",
        "# Cl√°sicos\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>National_Position</th>\n",
              "      <th>Club_Position</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Preffered_Foot</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Rate</th>\n",
              "      <th>Weak_foot</th>\n",
              "      <th>...</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Heading</th>\n",
              "      <th>Shot_Power</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>Long_Shots</th>\n",
              "      <th>Curve</th>\n",
              "      <th>Freekick_Accuracy</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Volleys</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>LS</td>\n",
              "      <td>LW</td>\n",
              "      <td>185</td>\n",
              "      <td>80</td>\n",
              "      <td>Right</td>\n",
              "      <td>32</td>\n",
              "      <td>High / Low</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>85</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>90</td>\n",
              "      <td>81</td>\n",
              "      <td>76</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lionel Messi</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>RW</td>\n",
              "      <td>RW</td>\n",
              "      <td>170</td>\n",
              "      <td>72</td>\n",
              "      <td>Left</td>\n",
              "      <td>29</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>85</td>\n",
              "      <td>95</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>90</td>\n",
              "      <td>74</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Neymar</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>LW</td>\n",
              "      <td>LW</td>\n",
              "      <td>174</td>\n",
              "      <td>68</td>\n",
              "      <td>Right</td>\n",
              "      <td>25</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>96</td>\n",
              "      <td>61</td>\n",
              "      <td>62</td>\n",
              "      <td>78</td>\n",
              "      <td>89</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>84</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Luis Su√°rez</td>\n",
              "      <td>Uruguay</td>\n",
              "      <td>LS</td>\n",
              "      <td>ST</td>\n",
              "      <td>182</td>\n",
              "      <td>85</td>\n",
              "      <td>Right</td>\n",
              "      <td>30</td>\n",
              "      <td>High / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>69</td>\n",
              "      <td>77</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>86</td>\n",
              "      <td>86</td>\n",
              "      <td>84</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manuel Neuer</td>\n",
              "      <td>Germany</td>\n",
              "      <td>GK</td>\n",
              "      <td>GK</td>\n",
              "      <td>193</td>\n",
              "      <td>92</td>\n",
              "      <td>Right</td>\n",
              "      <td>31</td>\n",
              "      <td>Medium / Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>78</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name Nationality National_Position Club_Position  Height  \\\n",
              "0  Cristiano Ronaldo    Portugal                LS            LW     185   \n",
              "1       Lionel Messi   Argentina                RW            RW     170   \n",
              "2             Neymar      Brazil                LW            LW     174   \n",
              "3        Luis Su√°rez     Uruguay                LS            ST     182   \n",
              "4       Manuel Neuer     Germany                GK            GK     193   \n",
              "\n",
              "   Weight Preffered_Foot  Age        Work_Rate  Weak_foot  ...  Agility  \\\n",
              "0      80          Right   32       High / Low          4  ...       90   \n",
              "1      72           Left   29  Medium / Medium          4  ...       90   \n",
              "2      68          Right   25    High / Medium          5  ...       96   \n",
              "3      85          Right   30    High / Medium          4  ...       86   \n",
              "4      92          Right   31  Medium / Medium          4  ...       52   \n",
              "\n",
              "   Jumping  Heading  Shot_Power  Finishing  Long_Shots  Curve  \\\n",
              "0       95       85          92         93          90     81   \n",
              "1       68       71          85         95          88     89   \n",
              "2       61       62          78         89          77     79   \n",
              "3       69       77          87         94          86     86   \n",
              "4       78       25          25         13          16     14   \n",
              "\n",
              "   Freekick_Accuracy  Penalties  Volleys  \n",
              "0                 76         85       88  \n",
              "1                 90         74       85  \n",
              "2                 84         81       83  \n",
              "3                 84         85       88  \n",
              "4                 11         47       11  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"../temp/stats_players.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdcucZhp-M_0"
      },
      "source": [
        "## 1. Predicci√≥n de Seleccionados Nacionales [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrewqxjjzvA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://www.futuro.cl/wp-content/uploads/2016/06/chile-argentina-meme-12.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfre1YsSDqla"
      },
      "source": [
        "### 1.1 Preprocesamiento [5 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR00u4HTDtxv"
      },
      "source": [
        "Tareas:\n",
        "\n",
        "1. Genere los labels para la clasificaci√≥n binaria en una variable llamada `label`. Para esto, trabaje sobre el atributo `National_Position` suponiendo que los valores nulos son jugadores no seleccionados para representar a su pa√≠s. [Sin puntaje]\n",
        "\n",
        "2. Hecho esto, ¬øcu√°ntos se tienen ejemplos por cada clase? Comente lo que observa. [1 punto]\n",
        "\n",
        "3. Genere un `ColumnTransformer` en donde especifique las transformaciones que hay que realizar para cada columna (por ejemplo StandarScaler, MinMaxScaler, OneHotEncoder, etc...) para que puedan ser utilizadas correctamente por el modelo predictivo y gu√°rdelo una variable llamada `col_transformer`. [2 puntos]\n",
        "\n",
        "4. Comente y justifique las transformaciones elegidas sobre cada una de las variables (para esto utilice el material `Player_Stats_Report.html` que viene en el zip del lab), al igual que las transformaciones aplicadas. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgAk0kbPjEsx"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JhC2sZj9dSI1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de seleccionados nacionales: 1075\n",
            "Cantidad de no seleccionados nacionales: 16513\n",
            "Proporci√≥n clase 1 respecto a clase 0: 0.06510022406588749\n"
          ]
        }
      ],
      "source": [
        "# 1.\n",
        "# Creaci√≥n de columna\n",
        "data[\"label\"] = data[\"National_Position\"].apply(lambda x:1 if pd.notna(x) and x.strip() != '' else 0)\n",
        "# 2.\n",
        "# Ejemplos por clase\n",
        "print(\"Cantidad de seleccionados nacionales:\",data[\"label\"].value_counts()[1])\n",
        "print(\"Cantidad de no seleccionados nacionales:\",data[\"label\"].value_counts()[0])\n",
        "print(\"Proporci√≥n clase 1 respecto a clase 0:\",data[\"label\"].value_counts()[1]/data[\"label\"].value_counts()[0])\n",
        "# Se observa un desbalance de clases, donde un porcentaje menor de los jugadores son jugadores seleccionados\n",
        "# mientras que la mayor√≠a son no seleccionados.\n",
        "# 3. y 4.\n",
        "# ColumnTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# Utilizamos RobustScaler, dado que asumir distribuci√≥n normal sobre las 31 columnas num√©ricas pueden ser\n",
        "# inadecuado. MinMaxScaler puede ser susceptible a outliers que seg√∫n el reporte no se aprecian en los histogramas\n",
        "# pero no hemos a√∫n confirmado si hay o no.\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "robust_scaler = RobustScaler()\n",
        "# Utilizamos OneHotEncoder para las variables categ√≥ricas que no son identificadores como el nombre y que no son National_Position\n",
        "# dado que construimos la etiqueta con esta columna. Las columnas categ√≥ricas a incluir pueden en su mayor√≠a ser descompuestas en\n",
        "# pocas variables binarias por onehot, salvo por el pa√≠s. Luego podemos reevaluar esta decisi√≥n.\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot = OneHotEncoder(sparse_output=False)\n",
        "# Fuera de la variable National_Position, del reporte vemos que Club_Position tiene 1 valor faltante. Por esto necesitamos un imputador.\n",
        "# Utilizamos uno simple para pocos casos y de poco impacto que se asegure de que no hay nulos para ninguna variable, creamos uno por \n",
        "# tipo de variable.\n",
        "from sklearn.impute import SimpleImputer\n",
        "sim_imp_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "sim_imp_num = SimpleImputer(strategy=\"mean\")\n",
        "\n",
        "\n",
        "# Definimos las columnas a transformar\n",
        "categorical_columns = data.select_dtypes(include=['object', 'category']).drop(['Name', 'National_Position'], axis=1).columns.tolist()\n",
        "numerical_columns = data.select_dtypes(include=['int64', 'float64']).drop(['label'],axis=1).columns.tolist()\n",
        "# ColumnTransformer\n",
        "col_transformer = ColumnTransformer([\n",
        "    ('Imputer_mode',sim_imp_cat,categorical_columns),\n",
        "    ('OneHotEncoder',one_hot,categorical_columns),\n",
        "    ('RobustScaler',robust_scaler,numerical_columns),\n",
        "    ('Imputer_mean',sim_imp_num,numerical_columns)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Nationality', 'Club_Position', 'Preffered_Foot', 'Work_Rate']\n",
            "['Height', 'Weight', 'Age', 'Weak_foot', 'Skill_Moves', 'Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle', 'Standing_Tackle', 'Aggression', 'Reactions', 'Interceptions', 'Vision', 'Composure', 'Crossing', 'Short_Pass', 'Long_Pass', 'Acceleration', 'Speed', 'Stamina', 'Strength', 'Balance', 'Agility', 'Jumping', 'Heading', 'Shot_Power', 'Finishing', 'Long_Shots', 'Curve', 'Freekick_Accuracy', 'Penalties', 'Volleys']\n"
          ]
        }
      ],
      "source": [
        "print(categorical_columns)\n",
        "print(numerical_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Portugal' 'LW' 'Right' 'High / Low']\n",
            " ['Argentina' 'RW' 'Left' 'Medium / Medium']\n",
            " ['Brazil' 'LW' 'Right' 'High / Medium']\n",
            " ...\n",
            " ['England' 'Res' 'Right' 'High / Medium']\n",
            " ['Scotland' 'Sub' 'Right' 'Medium / Medium']\n",
            " ['England' 'Sub' 'Right' 'Medium / Medium']]\n"
          ]
        }
      ],
      "source": [
        "input_cat = sim_imp_cat.fit_transform(data[categorical_columns])\n",
        "print(input_cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv1HOfcNEPF4"
      },
      "source": [
        "### 1.2 Entrenamiento [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPkuXTUBvB0"
      },
      "source": [
        "Ahora, vamos a entrenar los pipelines generados en los pasos anteriores. Para esto, debe realizar las siguientes tareas:\n",
        "\n",
        "1. Separe los datos de entrenamiento en un conjunto de entrenamiento y de prueba  (la proporci√≥n queda a su juicio). En este paso, seleccione los ejemplos de forma aleatoria e intente mantener la distribuci√≥n original de labels de cada clase en los conjuntos de prueba/entrenamiento. (vea la documentaci√≥n de `train_test_split`). [1 puntos]\n",
        "\n",
        "\n",
        "2. Defina un pipeline llamado `pipeline_xgboost` y otro llamado `pipeline_lightgbm`. Estos pipelines deben tener el mismo ColumnTransformer definido en la secci√≥n de preprocesamiento, pero deben variar los clasificadores de acuerdo al nombre de cada pipeline. [1 puntos]\n",
        "\n",
        "3. Entrene los pipelines. [1 punto]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbadONFtjGnE"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lLtlXGTPdWAV"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Guinea'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m pipeline_lightgbm \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     24\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn_Transformer\u001b[39m\u001b[38;5;124m'\u001b[39m,col_transformer),\n\u001b[0;32m     25\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm_classifier\u001b[39m\u001b[38;5;124m'\u001b[39m,lgbm_model)\n\u001b[0;32m     26\u001b[0m ])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 3. Entrenamos\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mpipeline_xgboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m pipeline_lightgbm\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\sklearn.py:1512\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1532\u001b[0m     params,\n\u001b[0;32m   1533\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1543\u001b[0m )\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\sklearn.py:596\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    577\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    578\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    593\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 596\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\sklearn.py:1003\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1003\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_bin\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:1573\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1554\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m         )\n\u001b[0;32m   1567\u001b[0m     ):\n\u001b[0;32m   1568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1571\u001b[0m         )\n\u001b[1;32m-> 1573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:1632\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1620\u001b[0m config \u001b[38;5;241m=\u001b[39m make_jcargs(\n\u001b[0;32m   1621\u001b[0m     nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnthread, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m   1622\u001b[0m )\n\u001b[0;32m   1623\u001b[0m ret \u001b[38;5;241m=\u001b[39m _LIB\u001b[38;5;241m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1625\u001b[0m     it\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(handle),\n\u001b[0;32m   1631\u001b[0m )\n\u001b[1;32m-> 1632\u001b[0m \u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[0;32m   1634\u001b[0m _check_call(ret)\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:569\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    567\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:550\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[1;34m(self, fn, dft_ret)\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[0;32m    555\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:637\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\data.py:1416\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1416\u001b[0m \u001b[43minput_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\core.py:617\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[1;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 617\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43m_proxy_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_enable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;66;03m# Stage the data, meta info are copied inside C++ MetaInfo.\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_data \u001b[38;5;241m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\data.py:1441\u001b[0m, in \u001b[0;36m_proxy_transform\u001b[1;34m(data, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[1;32m-> 1441\u001b[0m     data, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_np_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, \u001b[38;5;28;01mNone\u001b[39;00m, feature_names, feature_types\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scipy_csr(data):\n",
            "File \u001b[1;32mc:\\Users\\Alumno\\miniconda3\\envs\\vanilla_ml_env\\Lib\\site-packages\\xgboost\\data.py:224\u001b[0m, in \u001b[0;36m_ensure_np_dtype\u001b[1;34m(data, dtype)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _array_hasobject(data) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m [np\u001b[38;5;241m.\u001b[39mfloat16, np\u001b[38;5;241m.\u001b[39mbool_]:\n\u001b[0;32m    223\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39maligned:\n\u001b[0;32m    226\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrequire(data, requirements\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Guinea'"
          ]
        }
      ],
      "source": [
        "# 1. Separamos la data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Ajustamos la data que nos interesa para el entrenamiento\n",
        "X = data.drop(['Name','National_Position','label'],axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Separamos aleatoriamente con mantenci√≥n de proporci√≥n de clases y seleccionamos un 20% como test arbitrariamente.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30,stratify=y)\n",
        "# 2. Pipeline XGBoost\n",
        "# Importamos\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "# Instanciamos los clasificadores\n",
        "xgb_model = XGBClassifier()\n",
        "lgbm_model = LGBMClassifier()\n",
        "\n",
        "# Creamos la instancia\n",
        "pipeline_xgboost = Pipeline([\n",
        "    ('Column_Transformer',col_transformer),\n",
        "    ('xgb_classifier',xgb_model)\n",
        "])\n",
        "pipeline_lightgbm = Pipeline([\n",
        "    ('Column_Transformer',col_transformer),\n",
        "    ('lgbm_classifier',lgbm_model)\n",
        "])\n",
        "# 3. Entrenamos\n",
        "pipeline_xgboost.fit(X_train, y_train)\n",
        "pipeline_lightgbm.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poc9HSNBFeKO"
      },
      "source": [
        "### 1.3 Resultados [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGGCj8YtFil1"
      },
      "source": [
        "1. Calcule las m√©tricas accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) para evaluar el rendimiento de los distintos modelos. Verifique sus resultados usando `classification_report`. [2 puntos]\n",
        "\n",
        "2. Explique qu√© implican los valores de accuracy, precisi√≥n y recall de la clase positiva (la que indica que un jugador es seleccionado nacional) y c√≥mo influye la cantidad de ejemplos por clase en los resultados obtenidos. [2 puntos]\n",
        "\n",
        "3. Explique qu√© m√©trica le parece m√°s adecuada y concluya qu√© modelo tiene un mejor desempe√±o. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hkVFdujJTi"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNmI_tbbdQte"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5VMU6ae_g6"
      },
      "source": [
        "## 2. Predicci√≥n de posiciones de jugadores [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PGg_hLgr4H"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/E1rfA1aWEAYU6Ny.jpg\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6rSnAesfOm3"
      },
      "source": [
        "En una nueva jornada de desmesuradas transacciones deportivas, Renac√≠n escuch√≥ a sus colegas discutir acerca de que el precio de cada jugador depende en gran medida de la posici√≥n en la cancha en la que juega. Y adem√°s, que hay bastantes jugadores nuevos que no tienen muy claro en que posici√≥n verdaderamente brillar√≠an, por lo que actualmente puede que actualmente est√©n jugando en posiciones sub-optimas.\n",
        "\n",
        "Viendo que los resultados del primer an√°lisis no son tan esperanzadores, el corporeo los comanda a cambiar su tarea: ahora, les solicita que construyan un clasificador enfocado en predecir la mejor posici√≥n de los jugadores en la cancha seg√∫n sus caracter√≠sticas.\n",
        "\n",
        "Para lograr esto, primero, les pide que etiqueten de la siguiente manera los valores que aparecen en el atributo `Club_Position`, pidiendo que agrupen los valores en los siguientes grupos:\n",
        "\n",
        "**Nota**:  Renac√≠n les recalca que **no deben utilizar los valores ```Sub``` y ```Res``` de esta columna**.\n",
        "\n",
        "```python\n",
        "ataque = ['ST', 'CF']\n",
        "central_ataque = ['RW', 'CAM', 'LW']\n",
        "central = ['RM', 'CM', 'LM']\n",
        "central_defensa = ['RWB', 'CDM', 'LWB']\n",
        "defensa = ['RB', 'CB', 'LB']\n",
        "arquero = ['GK']\n",
        "```\n",
        "\n",
        "La elecci√≥n del clasificador se justificar en base a la siguiente [gu√≠a](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) y se deben comentar los resultados obtenidos en la clasificaci√≥n.\n",
        "\n",
        "**Tareas:** [1 punto por tarea]\n",
        "\n",
        "1. En un nuevo dataframe, aplique las etiquetas descritas anteriormente en cada uno de los valores se√±alados en esta secci√≥n y gu√°rdelos en la variable `label`.\n",
        "2. Cuente cu√°ntos por clase quedan.\n",
        "3. Entrene el nuevo pipeline y ejecute una evaluaci√≥n de este.  \n",
        "4. Comente los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBmSaWh8i2MI"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ir_7zMh2i1vg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                Name Club_Position           label\n",
            "0  Cristiano Ronaldo            LW  central_ataque\n",
            "1       Lionel Messi            RW  central_ataque\n",
            "2             Neymar            LW  central_ataque\n",
            "3        Luis Su√°rez            ST          ataque\n",
            "4       Manuel Neuer            GK         arquero\n"
          ]
        }
      ],
      "source": [
        "# Diccionario que mapea las posiciones a las etiquetas correspondientes\n",
        "posicion_dict = {\n",
        "    'ST': 'ataque', 'CF': 'ataque',\n",
        "    'RW': 'central_ataque', 'CAM': 'central_ataque', 'LW': 'central_ataque',\n",
        "    'RM': 'central', 'CM': 'central', 'LM': 'central',\n",
        "    'RWB': 'central_defensa', 'CDM': 'central_defensa', 'LWB': 'central_defensa',\n",
        "    'RB': 'defensa', 'CB': 'defensa', 'LB': 'defensa',\n",
        "    'GK': 'arquero'\n",
        "}\n",
        "\n",
        "# Aplicar la funci√≥n lambda usando el diccionario\n",
        "df_labeled = data.copy()\n",
        "df_labeled['label'] = df_labeled['Club_Position'].map(posicion_dict)\n",
        "\n",
        "# Filtrar los valores no deseados: 'Sub' y 'Res'\n",
        "df_labeled = df_labeled[~df_labeled['Club_Position'].isin(['Sub', 'Res'])]\n",
        "\n",
        "# Revisar los primeros resultados\n",
        "print(df_labeled[['Name', 'Club_Position', 'label']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "defensa            1180\n",
            "central             907\n",
            "arquero             632\n",
            "central_ataque      581\n",
            "ataque              430\n",
            "central_defensa     209\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Contamos el n√∫mero de jugadores por clase\n",
        "conteo_clases = df_labeled['label'].value_counts()\n",
        "print(conteo_clases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Definir las caracter√≠sticas y etiquetas\n",
        "X = df_labeled[['Ball_Control', 'Dribbling', 'Marking', 'Sliding_Tackle', 'Standing_Tackle',\n",
        "                'Aggression', 'Reactions', 'Interceptions', 'Vision', 'Composure',\n",
        "                'Crossing', 'Short_Pass', 'Long_Pass', 'Acceleration', 'Speed', 'Stamina',\n",
        "                'Strength', 'Balance', 'Agility', 'Jumping', 'Heading', 'Shot_Power',\n",
        "                'Finishing', 'Long_Shots', 'Curve', 'Freekick_Accuracy', 'Penalties', 'Volleys']]\n",
        "\n",
        "y = df_labeled['label']\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.43103802672147995\n",
            "[nan 'central' 'central_ataque' 'arquero' 'ataque' 'defensa'\n",
            " 'central_defensa']\n",
            "(2768, 28) (2768,)\n",
            "Accuracy: 0.7301451750640479\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        arquero       1.00      0.99      0.99       188\n",
            "         ataque       0.81      0.83      0.82       144\n",
            "        central       0.59      0.42      0.49       251\n",
            " central_ataque       0.42      0.61      0.50       179\n",
            "central_defensa       0.50      0.02      0.04        55\n",
            "        defensa       0.85      0.94      0.89       354\n",
            "\n",
            "       accuracy                           0.73      1171\n",
            "      macro avg       0.69      0.64      0.62      1171\n",
            "   weighted avg       0.73      0.73      0.71      1171\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calcular el porcentaje de valores faltantes en y_train\n",
        "porcentaje_nan_y_train = y_train.isna().mean()\n",
        "print(porcentaje_nan_y_train)\n",
        "\n",
        "# Verificar valores √∫nicos en y_test\n",
        "print(y_test.unique())\n",
        "\n",
        "# Notamos que existen valores Nan en y_test, por lo que los eliminamos y nos aseguramos de eliminar los mismos registrospara x_test\n",
        "X_test_clean = X_test[~y_test.isna()]\n",
        "y_test_clean = y_test.dropna()\n",
        "\n",
        "# Eliminar filas con valores NaN en y_train y los correspondientes en X_train\n",
        "X_train_clean = X_train[~y_train.isna()]  \n",
        "y_train_clean = y_train.dropna()         \n",
        "\n",
        "# Verificar que ambos tengan el mismo n√∫mero de muestras\n",
        "print(X_train_clean.shape, y_train_clean.shape)\n",
        "\n",
        "# Creamos el pipeline con estandarizaci√≥n y SGDClassifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', SGDClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Entrenamos el modelo\n",
        "pipeline.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "# Predecir sobre el conjunto de prueba\n",
        "y_pred = pipeline.predict(X_test_clean)\n",
        "\n",
        "# Evaluar el rendimiento\n",
        "print(\"Accuracy:\", accuracy_score(y_test_clean, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_clean, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A partir de los pasos a seguir indicados en la gu√≠a, escogemos el m√©todo SGDClassifier para la clasificaci√≥n, esto debido a que estamos prediciendo una categor√≠a y nuestro dataset tiene m√°s de 100000 datos.\n",
        "\n",
        "Con respecto a los resultados obtenidos, notamos que hay un buen rendimiento con respecto a las predicciones para arquero y defensa (alta precisi√≥n y recall). Por otro lado, vemos que al modelo se le dificulta hacer la clasificaci√≥n para las posiciones intermedias (central y central_defensa), esto puede ser debido, posiblemente a que las caracter√≠sticas de los jugadores en estas posiciones son m√°s similares entre s√≠ o hay menos ejemplos para entrenar.\n",
        "\n",
        "En general, considerando el accuracy, vemos que el 73% de las predicciones del modelo son correctas, lo cual es aceptable, pero no excelente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bL2m8nNojXM"
      },
      "source": [
        "## 3. Predicciones de Seleccionados Nacionales para el Jere Klein [30 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XmRsJdsEh_"
      },
      "source": [
        "<center>\n",
        "<img src='https://www.radioactiva.cl/wp-content/uploads/2024/04/Jere-Klein-1-768x432.webp' width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmUoVDsqUPu"
      },
      "source": [
        "Despu√©s de alcanzar la fama como cantante urbano, Jere Klein decide explorar una nueva faceta. Con su amor por el f√∫tbol y convencido de que los artistas urbanos poseen un talento y versatilidad excepcionales, Jere se embarca en un proyecto innovador: desarrollar un sistema de inteligencia artificial capaz de identificar a jugadores que tienen potencial para convertirse en futbolistas profesionales. Su teor√≠a es que muchos artistas del g√©nero urbano chileno, con sus habilidades √∫nicas y su disciplina, podr√≠an destacarse tambi√©n en el deporte. Con este sistema, Jere espera no solo abrir nuevas oportunidades para sus colegas artistas, sino tambi√©n demostrar la amplia gama de talentos que pueden ofrecer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8pQ5Zfq8dE"
      },
      "source": [
        "### 2.1 ¬øQu√© modelo de √°rbol es m√°s de \"pana\"? [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-KUA4g99eo"
      },
      "source": [
        "<center>\n",
        "<img src='https://64.media.tumblr.com/39189215a7d3d96823cb359f35b44e05/tumblr_psmrhrR3Xw1qf5hjqo4_540.gif' width=300 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-moVhB9vPH"
      },
      "source": [
        "\n",
        "**Tareas**\n",
        "\n",
        "\n",
        "1. Considerando el la variable llamada `label` creada en la secci√≥n 1.1. Para determinar cu√°l modelo de √°rbol ser√≠a m√°s adecuado para la tarea en cuesti√≥n, utilice PyCaret. Este deber√° centrarse exclusivamente en modelos de tipo √°rbol. Jere ha especificado que busca un modelo que tome decisiones r√°pidamente y que tenga una baja tasa de falsos positivos, ya que planea invertir en estos jugadores. [3 puntos] \n",
        "\n",
        "Para la comparaci√≥n, utilice los siguientes modelos:\n",
        "\n",
        "```python\n",
        "['et', 'rf', 'dt', 'xgboost', 'lightgbm', 'catboost']\n",
        "```\n",
        "\n",
        "2. Explique en brevemente que son los modelos de la siguiente lista `['et', 'rf', 'dt']` y como funcionan. [3 punto]\n",
        "\n",
        "3. Tras realizar la comparaci√≥n de modelos, seleccione aquel que muestre el mejor rendimiento en t√©rminos de velocidad y precisi√≥n, especialmente en la reducci√≥n de falsos positivos. Utilice la funci√≥n `evaluate_model` de PyCaret para revisar y analizar los resultados obtenidos en los siguientes aspectos:\n",
        "\n",
        "  - **Confusi√≥n Matrix**: ¬øC√≥mo se encuentran la tasa de verdaderos positivos y verdaderos negativos?\n",
        "  - **Threshold**: ¬øEs acaso el umbral por defecto del modelo el mejor para las predicciones?\n",
        "  - **Feature Importance**: ¬øCu√°les son las variables con mejor desempe√±o? ¬øA qu√© podr√≠a deberse esto?\n",
        "  - **Learning Curve**: ¬øEl modelo presenta alg√∫n problema?\n",
        "\n",
        "  [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY85nrViYROF"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kUCjOjsEYUXL"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pycaret'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"
          ]
        }
      ],
      "source": [
        "from pycaret.datasets import get_data\n",
        "from pycaret.classification import *\n",
        "import os\n",
        "\n",
        "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
        "\n",
        "#Continuar c√≥digo aqu√≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8DSS3u1xMpB"
      },
      "source": [
        "### 2.2 Reducci√≥n de dimensionalidad [14 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLu0543p876P"
      },
      "source": [
        "<center>\n",
        "<img src='https://i.kym-cdn.com/photos/images/original/002/258/560/668.gif' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-bxJ0txwNF"
      },
      "source": [
        "A pesar de los resultados obtenidos previamente, el manager de Jere ha solicitado el entrenamiento de un modelo de XGBoost utilizando los datos disponibles. Adem√°s, se debe proceder a realizar una reducci√≥n de dimensionalidad basada en la importancia de las caracter√≠sticas.\n",
        "\n",
        "Para llevar a cabo esta tarea:\n",
        "\n",
        "1. Inicie entrenando un modelo XGBoost con todas las caracter√≠sticas disponibles. [2 puntos]\n",
        "\n",
        "2. Una vez el modelo est√© entrenado, eval√∫e y clasifique las caracter√≠sticas seg√∫n su importancia de forma descendente. [2 puntos]\n",
        "\n",
        "3. Utilice esta clasificaci√≥n para ejecutar una b√∫squeda recursiva de eliminaci√≥n de caracter√≠sticas, eliminando progresivamente las menos importantes y evaluando el impacto en el desempe√±o del modelo hasta identificar las N caracter√≠sticas m√°s cr√≠ticas. [2 puntos]\n",
        "\n",
        "4. Con este conjunto reducido de caracter√≠sticas, entrene un nuevo modelo y eval√∫e su rendimiento. [2 puntos]\n",
        "\n",
        "5. Posteriormente, responda a las siguientes preguntas para una comprensi√≥n m√°s profunda de los cambios y beneficios:\n",
        "\n",
        "  - ¬øEl rendimiento del modelo con las caracter√≠sticas seleccionadas es similar al del modelo original? ¬øC√≥mo se comparan en t√©rminos de precisi√≥n y robustez? [2 puntos]\n",
        "  - ¬øCu√°les son los beneficios potenciales de eliminar variables del modelo? Considere factores como la simplificaci√≥n del modelo, reducci√≥n del tiempo de entrenamiento, y mejora en la capacidad de generalizaci√≥n. [2 puntos]\n",
        "  - Comente si el modelo con menor dimensionalidad es m√°s sencillo de explicar. Explique brevemente por qu√© la eliminaci√≥n de ciertas caracter√≠sticas puede facilitar la comprensi√≥n y la explicaci√≥n del comportamiento del modelo. [2 puntos]\n",
        "\n",
        "Notar que con esta metodologia buscamos encontrar un punto entermedio entre n√∫mero de festures y desempe√±o. por esto, si observa que al aumentar festires el aumento es despreciable, puede no considerar agregar m√°s features a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfmK63TuDOS"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQwUd_nsuDOe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTG5cH9r3M9g"
      },
      "source": [
        "### 2.3 Calibraci√≥n Probabilistica [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL0VqjR7yvb"
      },
      "source": [
        "<center>\n",
        "<img src='https://media2.giphy.com/media/l2Je4Ku0Cx292KWv6/200w.gif?cid=6c09b952y0sihtq9tb6sz8j2023x3zxxp3qx1ocgonkpkblj&ep=v1_gifs_search&rid=200w.gif&ct=g' width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmOKxhAw3sic"
      },
      "source": [
        "Para lograr modelos m√°s modulares, se recomienda realizar una calibraci√≥n del modelo entrenado anteriormente, con el objetivo de obtener salidas que reflejen mayor modularidad.\n",
        "\n",
        "1. Se solicita que utilice un m√©todo de calibraci√≥n que asegure que las probabilidades generadas incrementen de manera mon√≥tona. Una m√©trica ampliamente utilizada para evaluar la precisi√≥n de la calibraci√≥n de un modelo es el Brier Score. Calcule el Brier Score para el modelo tanto antes como despu√©s de la calibraci√≥n. Esto le permitir√° realizar una comparaci√≥n cuantitativa y determinar si la calibraci√≥n ha mejorado el rendimiento del modelo. Para m√°s informaci√≥n sobre el Brier Score, puede consultar el siguiente enlace: [Scikit-Learn - Brier Score Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html). [3 puntos]\n",
        "\n",
        "2. Tras la calibraci√≥n, examine y comente los resultados obtenidos. A su an√°lisis a√±ada una comparaci√≥n visual de las ideales versus las salidas del modelo original (sin calibrar) y del modelo calibrado. [3 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiYz_qLuD19"
      },
      "source": [
        "**Respuesta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0bfSuiFuD2I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k-ao0mOU64Ru",
        "Jg_9jBqtgRDO",
        "JdcucZhp-M_0",
        "Qfre1YsSDqla",
        "Bv1HOfcNEPF4",
        "poc9HSNBFeKO",
        "uy5VMU6ae_g6",
        "9bL2m8nNojXM",
        "rD8pQ5Zfq8dE",
        "K8DSS3u1xMpB",
        "PTG5cH9r3M9g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
