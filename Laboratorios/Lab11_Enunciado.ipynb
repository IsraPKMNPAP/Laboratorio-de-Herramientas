{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29065d993b3a44e28f9daf5ed7132750": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_252a90d5f26640509f56bc360ed79326",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6,119/5,000 \u001b[0m [ \u001b[33m0:00:16\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m364 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">6,119/5,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:16</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">364 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "252a90d5f26640509f56bc360ed79326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17d97783064448fac8dd4f7d81875cf": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_20216105e8864df6bcc007401b99e6a5",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10,204/10,000 \u001b[0m [ \u001b[33m0:00:24\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m417 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">10,204/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:24</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">417 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "20216105e8864df6bcc007401b99e6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8a77a55dd74b50befd6d534246ba6e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_78344ce0eb5c469f86ceb45731e3bd25",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100,349/100,000 \u001b[0m [ \u001b[33m0:36:11\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m48 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">100,349/100,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:36:11</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">48 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "78344ce0eb5c469f86ceb45731e3bd25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Laboratorio 11: LLM y Agentes AutÃ³nomos ğŸ¤–**\n",
        "\n",
        "MDS7202: Laboratorio de ProgramaciÃ³n CientÃ­fica para Ciencia de Datos"
      ],
      "metadata": {
        "id": "PyPTffTLug7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, SebastiÃ¡n Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: NicolÃ¡s Ojeda, Melanie PeÃ±a, Valentina Rojas"
      ],
      "metadata": {
        "id": "5pbWVyntzbvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no serÃ¡n revisados**\n",
        "\n",
        "- Nombre de alumno 1: Luis PicÃ³n\n",
        "- Nombre de alumno 2: Israel Astudillo M."
      ],
      "metadata": {
        "id": "dy6ikgVYzghB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/IsraPKMNPAP/Laboratorio-de-Herramientas)"
      ],
      "metadata": {
        "id": "iMJ-owchzjFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Reinforcement Learning\n",
        "- Large Language Models\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serÃ¡n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- ResoluciÃ³n de problemas secuenciales usando Reinforcement Learning\n",
        "- Habilitar un Chatbot para entregar respuestas Ãºtiles usando Large Language Models.\n",
        "\n",
        "El laboratorio deberÃ¡ ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al mÃ¡ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante mÃ¡s eficientes que los iteradores nativos sobre DataFrames."
      ],
      "metadata": {
        "id": "WUuwsXrKzmkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secciÃ³n van a usar mÃ©todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ],
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ],
      "metadata": {
        "id": "gOcejYb6uzOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d444b4-9898-4a57-8606-f32c2146e60e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/958.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m952.3/958.1 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "La idea de esta subsecciÃ³n es que puedan implementar mÃ©todos de RL y asÃ­ generar una estrategia para jugar el clÃ¡sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de cÃ³digo transforma las observaciones del ambiente a `np.array`:\n"
      ],
      "metadata": {
        "id": "qBPet_Mq8dX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.1 DescripciÃ³n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripciÃ³n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaciÃ³n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ],
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El ambiente BlackJack es un ambiente de contexto de aprendizaje reforzado que impone las reglas y funcionamiento de la situaciÃ³n a simular, en este caso un juego de Black Jack.\n",
        "La formulaciÃ³n MDP es la siguiente en base a las variables que incluye el modelo:\n",
        "- Acciones: Hay dos posibles acciones realizables por el agente las cuales son \"stick\" o \"hit\" que representan quedarse con las cartas actuales o pedir una carta extra respectivamente. EstÃ¡ descrito formalmente como Discrete(2) dado que hay 2 acciones.\n",
        "- Estados: La informaciÃ³n que obtiene el agente de cada estado en el tiempo y que por tanto describen cada estado son la suma total de las cartas que posee el jugador, el valor de la carta del dealer boca arriba y si el jugador posee o no un as usable o que puede cambiar su valor. Descrito formalmente como Tuple(Discrete(32), Discrete(11), Discrete(2)) dado que la suma de cartas del jugador puede tomar 32 valores, la del dealer 11 valores y la si tiene un as dos valores. AsÃ­, hay 32 x 11 x 2 = 704 posibles estados que puede tener el espacio de observaciÃ³n.\n",
        "- Recompensas: Las recompensas entregadas son +1 si es que se gana el juego, -1 si se pierde, 0 si se empata y 1.5 si el blackjack de la victoria es natural."
      ],
      "metadata": {
        "id": "G5i1Wt1p770x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaciÃ³n 5000 veces y reporte el promedio y desviaciÃ³n de las recompensas. Â¿CÃ³mo calificarÃ­a el performance de esta polÃ­tica? Â¿CÃ³mo podrÃ­a interpretar las recompensas obtenidas?"
      ],
      "metadata": {
        "id": "pmcX6bRC9agQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recompensas\n",
        "R = []\n",
        "# Loop de simulaciones\n",
        "for episode in range(5000):\n",
        "  # Nueva iteraciÃ³n, reseteamos el juego\n",
        "  obs = env.reset()\n",
        "  # Inicializamos variable de tÃ©rmino del juego\n",
        "  done = False\n",
        "  # Loop de cada juego, utilizamos la variable de tÃ©rmino del juego\n",
        "  while not done:\n",
        "    # AcciÃ³n aleatoria\n",
        "    action = env.action_space.sample()\n",
        "    # Resultado de la acciÃ³n\n",
        "    obs, reward, done,truncated, info = env.step(action)\n",
        "    # ContinÃºa hasta que el juego termine, cuando done=True\n",
        "  # Terminado el juego actual, reportamos la recompensa\n",
        "  R.append(reward)\n",
        "  # Siguiente juego"
      ],
      "metadata": {
        "id": "TkcUmXkJH9n1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Promedio de recompensas: \", np.mean(R))\n",
        "print(\"DesviaciÃ³n de recompensas: \", np.std(R))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxeggWOmN-UF",
        "outputId": "3c1f00fb-2e6c-4fe1-b096-f89f88b1871d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio de recompensas:  -0.3894\n",
            "DesviaciÃ³n de recompensas:  0.8994262838054045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "yJJop0ePaW1n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El performance parece ser malo, dado que su promedio de ganancias es negativo.\n",
        "El performance de la polÃ­tica aleatoria tiene un valor promedio negativo, lo cual nos indica que en promedio se pierde mÃ¡s de lo que se gana. Por otro lado, la desviaciÃ³n de las recompensas es bastante alta, cercana a ser la unidad completa que se asigna de premio o castigo en el juego. En general las recompensas obtenidas con esta polÃ­tica no llevan a un desempeÃ±o promedio positivo."
      ],
      "metadata": {
        "id": "cK4gCmJBOSNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ],
      "metadata": {
        "id": "LEO_dY4x_SJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "8wXvKFvjaJRg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos PPO que soporta todos los tipos de conjuntos de acciones\n",
        "# sin embargo, en este caso el conjunto de acciones y de estados es discreto.\n",
        "from stable_baselines3 import PPO\n",
        "# init agent\n",
        "model = PPO(\"MlpPolicy\", env, verbose=0)"
      ],
      "metadata": {
        "id": "m9JsFA1wGmnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148b0a9e-b78d-4a28-a17b-7885168a445d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(5000), progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "29065d993b3a44e28f9daf5ed7132750",
            "252a90d5f26640509f56bc360ed79326"
          ]
        },
        "id": "ZVAR44UzX9zw",
        "outputId": "00788e33-f12a-4851-830f-608a5881a636"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29065d993b3a44e28f9daf5ed7132750"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7de7d0504f70>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"blackjack\")"
      ],
      "metadata": {
        "id": "BfMdcfTXYKuH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.4 EvaluaciÃ³n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. Â¿CÃ³mo es el performance de su agente? Â¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "E-bpdb8wZID1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = PPO.load(\"blackjack\")\n",
        "model.set_env(env)"
      ],
      "metadata": {
        "id": "N27jbsnQZwFs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Evaluate the agent\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "5-d7d8GFf7F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4319a0-88c2-48fa-99c5-37ed7b4b8428"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.2, 0.8717797887081348)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El performance del agente con el algoritmo PPO es peor que el aleatorio baseline, la pÃ©rdida es mayor pero la desviaciÃ³n estÃ¡ndar respecto a esta es menor lo cual puede ser un buen atributo de lo encontrado."
      ],
      "metadata": {
        "id": "sIrlqqn2cEQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "Genere una funciÃ³n que reciba un estado y retorne la accion del agente. Luego, use esta funciÃ³n para entregar la acciÃ³n escogida frente a los siguientes escenarios:\n",
        "\n",
        "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "Â¿Son coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: Â¿A que clase de python pertenecen los estados? Pruebe a usar el mÃ©todo `.reset` para saberlo."
      ],
      "metadata": {
        "id": "RO-EsAaPAYEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3vS0KKKz2x5",
        "outputId": "e870bd21-2adb-4bc2-c88d-2a15e1c17ff4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([17,  9,  0]), {})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que los estados pertenecen a la clase array de python, por lo que procesamos el estado en la funciÃ³n de la misma forma. Nuevamente haciendo flatten() para obtener las dimensiones correctas del array."
      ],
      "metadata": {
        "id": "4UpCLoqz0fJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_agent_action(model, player_sum, dealer_card, usable_ace):\n",
        "  state = np.array([player_sum, dealer_card, int(usable_ace)]).flatten()\n",
        "  action, _ = model.predict(state)\n",
        "  return action\n",
        "\n",
        "# Escenario 1\n",
        "player_sum_1 = 6\n",
        "dealer_card_1 = 7\n",
        "usable_ace_1 = False\n",
        "action_1 = get_agent_action(model, player_sum_1, dealer_card_1, usable_ace_1)\n",
        "print(f\"Escenario 1: AcciÃ³n = {action_1}\")\n",
        "\n",
        "# Escenario 2\n",
        "player_sum_2 = 19\n",
        "dealer_card_2 = 3\n",
        "usable_ace_2 = True\n",
        "action_2 = get_agent_action(model, player_sum_2, dealer_card_2, usable_ace_2)\n",
        "print(f\"Escenario 2: AcciÃ³n = {action_2}\")"
      ],
      "metadata": {
        "id": "Fh8XlGyzwtRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c05fd3-46ad-4daa-d40a-f822367e71f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escenario 1: AcciÃ³n = 0\n",
            "Escenario 2: AcciÃ³n = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien el modelo tiene un valor promedio de ganancia negativo, la respuesta a los casos especÃ­ficos probados parece ser razonabole y acorde a las reglas del juego dado que con una suma baja toma la acciÃ³n de pedir mÃ¡s cartas, que es la jugada esperable. Por otro lado, cuando la suma es alta no pide cartas, indicando que su decisiÃ³n estÃ¡ en cierta medida guiada por el castigo que existe al pasar el 21."
      ],
      "metadata": {
        "id": "yC1RB_-PzHTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "3HhOg64STxbK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secciÃ³n 2.1, en esta secciÃ³n usted se encargarÃ¡ de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
        "\n",
        "Comencemos preparando el ambiente:\n"
      ],
      "metadata": {
        "id": "SEqCTqqroh03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el parÃ¡metro continuous = True"
      ],
      "metadata": {
        "id": "nvQUyuZ_FtZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709f03d2-1b04-49c7-ff71-1cf33e5d2837"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noten que se especifica el parÃ¡metro `continuous = True`. Â¿Que implicancias tiene esto sobre el ambiente?\n",
        "\n",
        "AdemÃ¡s, se le facilita la funciÃ³n `export_gif` para el ejercicio 2.2.4:"
      ],
      "metadata": {
        "id": "FBU4lGX3wpN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto implica que el espacio de decisiÃ³n es continuo, expandiendo las posibles opciones que el modelo puede considerar."
      ],
      "metadata": {
        "id": "dAwxMReO9qjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funciÃ³n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ],
      "metadata": {
        "id": "bRiWpSo9yfr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6ff58d-1547-4cb3-a8cd-b409bd5abc5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 DescripciÃ³n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripciÃ³n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaciÃ³n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. Â¿Como se distinguen las acciones de este ambiente en comparaciÃ³n a `Blackjack`?\n",
        "\n",
        "Nota: recuerde que se especificÃ³ el parÃ¡metro `continuous = True`"
      ],
      "metadata": {
        "id": "sk5VJVppXh3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El ambiente LunarLander describe los estados, acciones y recompensas involucradas en la simulaciÃ³n del aterrizaje de una nave espacial virtual. Las coordenadas del punto objetivo estÃ¡n en (0,0) donde la grilla en la que se puede mover la nave va desde -2.5 a 2.5 tanto en el eje X como Y. Existen otras variables que describen el movimiento de la nave como su velocidad tanto vertical como horizontal y su Ã¡ngulo de orientaciÃ³n. Contiene tambiÃ©n indicadores por cada tren de aterrizaje para saber si estÃ¡n en contacto con el suelo o no.\n",
        "Los posibles estados son continuos dados por la posiciÃ³n y los otros parÃ¡metros descritos anteriormente, que estÃ¡n contenidos en un Box multidimensional condichas caracterÃ­sticas del movimiento de la nave.\n",
        "El posible espacio de acciÃ³n es discreto y puede tomar 4 valores, no hacer nada (0), activar el motor izquierdo (1), activar el motor principal (2) o activar el derecho (3).\n",
        "Se otorgan recompensas en cada paso para guiar el aterrizaje de la nave. La recompensa aumenta a medida que la nave se acerca al punto de aterrizaje y se mueve mÃ¡s lento, y disminuye si la nave estÃ¡ inclinada. Cada tren de aterrizaje que toca el suelo otorga 10 puntos adicionales. Se aplican penalizaciones pequeÃ±as en cada frame cuando los motores laterales estÃ¡n en uso (-0.03 puntos) y una penalizaciÃ³n mayor cuando el motor principal se enciende (-0.3 puntos). Al finalizar el episodio, una recompensa adicional de -100 puntos se asigna si la nave choca, y +100 puntos si aterriza exitosamente. Se considera que un episodio estÃ¡ resuelto si la nave obtiene al menos 200 puntos en total."
      ],
      "metadata": {
        "id": "Yb-u9LUE8O9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las acciones se distinguen de Black Jack principalmente en que hay mÃ¡s acciones que realizar y estas acciones tambiÃ©n interactÃºan mÃ¡s directamente con la recompensa alcanzada, mas allÃ¡ de quÃ© nÃºmero aleatorio se asigna o no."
      ],
      "metadata": {
        "id": "Tzdnm69aCB2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaciÃ³n 10 veces y reporte el promedio y desviaciÃ³n de las recompensas. Â¿CÃ³mo calificarÃ­a el performance de esta polÃ­tica?"
      ],
      "metadata": {
        "id": "YChodtNQwzG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R = []\n",
        "for episode in range(10):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        done = terminated or truncated\n",
        "    R.append(total_reward)\n",
        "env.close()\n",
        "\n",
        "print(\"Promedio de recompensas:\", np.mean(R))\n",
        "print(\"DesviaciÃ³n de recompensas:\", np.std(R))"
      ],
      "metadata": {
        "id": "5bwc3A0GX7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e97a50c-ce9e-4a0d-ed93-76cf6ac63b1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio de recompensas: -223.18599431399176\n",
            "DesviaciÃ³n de recompensas: 160.78440737748258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El performance de esta polÃ­tica es muy pobre, de hecho el promedio de las recompensas es exactamente lo contrario a la recompensa necesaria para decir que una iteraciÃ³n se da por terminada, que es 200 puntos. Una polÃ­tica de generaciÃ³n de acciones aleatorias no es adecuada."
      ],
      "metadata": {
        "id": "Eeo4feI9Pr9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ],
      "metadata": {
        "id": "hQrZVQflX_5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True)"
      ],
      "metadata": {
        "id": "y_6Ia9uoF7Hs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo A2C soporta el formato Box de"
      ],
      "metadata": {
        "id": "SyslBcd-VLJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "model.learn(total_timesteps=10000, progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "f17d97783064448fac8dd4f7d81875cf",
            "20216105e8864df6bcc007401b99e6a5"
          ]
        },
        "id": "tt6pjPYoSoH-",
        "outputId": "7f56d6f2-a352-41f4-dd68-c503865f965b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f17d97783064448fac8dd4f7d81875cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7de693323010>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"lunar_lander\")"
      ],
      "metadata": {
        "id": "xGyY4CJKTVhj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.4 EvaluaciÃ³n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. Â¿CÃ³mo es el performance de su agente? Â¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "3z-oIUSrlAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = PPO.load(\"lunar_lander\")\n",
        "model.set_env(env)"
      ],
      "metadata": {
        "id": "ophyU3KrWrwl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Evaluate the agent\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHDXMwkzT7ZG",
        "outputId": "18ff1043-d079-4d8a-e84c-7c9881f5e837"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-115.4697376, 79.61610107472136)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "RJYzp-PXV4rE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.5 OptimizaciÃ³n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parÃ¡metros como:\n",
        "- `total_timesteps`\n",
        "- `learning_rate`\n",
        "- `batch_size`\n",
        "\n",
        "Una vez optimizado el modelo, use la funciÃ³n `export_gif` para estudiar el comportamiento de su agente en la resoluciÃ³n del ambiente y comente sobre sus resultados.\n",
        "\n",
        "Adjunte el gif generado en su entrega (mejor aÃºn si ademÃ¡s adjuntan el gif en el markdown)."
      ],
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ConfiguraciÃ³n del ambiente\n",
        "env = gym.make(\"LunarLander-v3\", render_mode=\"human\", continuous=True)\n",
        "\n",
        "learning_rate = 0.03   # Ajusta segÃºn sea necesario\n",
        "n_steps = 2048           # NÃºmero de pasos antes de actualizar\n",
        "batch_size = 64          # TamaÃ±o del lote para la actualizaciÃ³n de gradiente\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=learning_rate, n_steps=n_steps, batch_size=batch_size)\n",
        "model.learn(total_timesteps=100000, progress_bar=True)  # Aumenta el nÃºmero de timesteps\n",
        "model.save(\"lunar_lander\")\n",
        "del model\n",
        "\n",
        "# Cargar el modelo y reestablecer el ambiente\n",
        "model = PPO.load(\"lunar_lander\")\n",
        "model.set_env(env)\n",
        "\n",
        "# EvaluaciÃ³n del agente\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=20)\n",
        "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")\n",
        "\n",
        "# Cerrar el ambiente\n",
        "env.close()"
      ],
      "metadata": {
        "id": "aItYF6sr6F_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df8a77a55dd74b50befd6d534246ba6e",
            "78344ce0eb5c469f86ceb45731e3bd25"
          ]
        },
        "outputId": "924e98e1-7e9d-49bf-d2a3-cccc766c4e38"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df8a77a55dd74b50befd6d534246ba6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 120      |\n",
            "|    ep_rew_mean     | -288     |\n",
            "| time/              |          |\n",
            "|    fps             | 47       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 83.1      |\n",
            "|    ep_rew_mean          | -446      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 88        |\n",
            "|    total_timesteps      | 4096      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 84.046196 |\n",
            "|    clip_fraction        | 0.945     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.17     |\n",
            "|    explained_variance   | 8.08e-05  |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 793       |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | 0.304     |\n",
            "|    std                  | 1.16      |\n",
            "|    value_loss           | 1.33e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 87.3      |\n",
            "|    ep_rew_mean          | -668      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 132       |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 404.18665 |\n",
            "|    clip_fraction        | 0.814     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.98     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 597       |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | 0.244     |\n",
            "|    std                  | 1.05      |\n",
            "|    value_loss           | 2.77e+03  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 89.9        |\n",
            "|    ep_rew_mean          | -803        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 177         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018468544 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.19        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.58e+03    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | 0.0143      |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.95e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 87.7        |\n",
            "|    ep_rew_mean          | -951        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 222         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.041742958 |\n",
            "|    clip_fraction        | 0.168       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0.423       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.81e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | 0.00595     |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.35e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.2        |\n",
            "|    ep_rew_mean          | -1.09e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 266         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006440241 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0.55        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.05e+03    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | 0.0121      |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.8e+03     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.4        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 310         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014650758 |\n",
            "|    clip_fraction        | 0.201       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.692       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.21e+03    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | 0.01        |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.83e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 88.7       |\n",
            "|    ep_rew_mean          | -1.1e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 355        |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02788722 |\n",
            "|    clip_fraction        | 0.206      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.89      |\n",
            "|    explained_variance   | 0.765      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 3.13e+03   |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | 0.00857    |\n",
            "|    std                  | 1.03       |\n",
            "|    value_loss           | 4.72e+03   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 87.6         |\n",
            "|    ep_rew_mean          | -1.08e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 46           |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 400          |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0141734425 |\n",
            "|    clip_fraction        | 0.213        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.796        |\n",
            "|    learning_rate        | 0.03         |\n",
            "|    loss                 | 1.78e+03     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | 0.0092       |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 4.13e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88          |\n",
            "|    ep_rew_mean          | -1.08e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 444         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012467621 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.851       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.85e+03    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | 0.00638     |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.08e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 89.1        |\n",
            "|    ep_rew_mean          | -1.1e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 488         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025172392 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0.861       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.03e+03    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | 0.0102      |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 3.92e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 89.9        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 532         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.053243008 |\n",
            "|    clip_fraction        | 0.244       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.9         |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.36e+03    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | 0.0147      |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 2.88e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.5        |\n",
            "|    ep_rew_mean          | -1.13e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 577         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008744486 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 0.92        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.4e+03     |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | 0.00745     |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 2.44e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 90.4         |\n",
            "|    ep_rew_mean          | -1.13e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 46           |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 621          |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075560976 |\n",
            "|    clip_fraction        | 0.19         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.937        |\n",
            "|    learning_rate        | 0.03         |\n",
            "|    loss                 | 937          |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 0.00947      |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 1.84e+03     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 88.7      |\n",
            "|    ep_rew_mean          | -1.12e+03 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 666       |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0156997 |\n",
            "|    clip_fraction        | 0.164     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.95     |\n",
            "|    explained_variance   | 0.948     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 922       |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | 0.00543   |\n",
            "|    std                  | 1.06      |\n",
            "|    value_loss           | 1.73e+03  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88.5        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 710         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006814571 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.95       |\n",
            "|    explained_variance   | 0.948       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 992         |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | 0.00637     |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 1.84e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.1        |\n",
            "|    ep_rew_mean          | -1.14e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 754         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017676163 |\n",
            "|    clip_fraction        | 0.329       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 0.956       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 637         |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | 0.0286      |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 1.42e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.7        |\n",
            "|    ep_rew_mean          | -1.15e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 799         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031070411 |\n",
            "|    clip_fraction        | 0.299       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.98       |\n",
            "|    explained_variance   | 0.953       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 576         |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | 0.0179      |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 1.81e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88.8        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 843         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012520591 |\n",
            "|    clip_fraction        | 0.279       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.97       |\n",
            "|    explained_variance   | 0.947       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 999         |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | 0.0203      |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 1.61e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 89.7       |\n",
            "|    ep_rew_mean          | -1.11e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 887        |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06749683 |\n",
            "|    clip_fraction        | 0.333      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.99      |\n",
            "|    explained_variance   | 0.952      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 665        |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | 0.0238     |\n",
            "|    std                  | 1.09       |\n",
            "|    value_loss           | 1.79e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 90.3       |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 932        |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.18329155 |\n",
            "|    clip_fraction        | 0.416      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3         |\n",
            "|    explained_variance   | 0.943      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 1.02e+03   |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | 0.0434     |\n",
            "|    std                  | 1.08       |\n",
            "|    value_loss           | 1.87e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 90.5       |\n",
            "|    ep_rew_mean          | -1.14e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 976        |\n",
            "|    total_timesteps      | 45056      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16025296 |\n",
            "|    clip_fraction        | 0.387      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.01      |\n",
            "|    explained_variance   | 0.96       |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 872        |\n",
            "|    n_updates            | 210        |\n",
            "|    policy_gradient_loss | 0.0371     |\n",
            "|    std                  | 1.13       |\n",
            "|    value_loss           | 1.99e+03   |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 88.5     |\n",
            "|    ep_rew_mean          | -1.1e+03 |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 23       |\n",
            "|    time_elapsed         | 1020     |\n",
            "|    total_timesteps      | 47104    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 18.56445 |\n",
            "|    clip_fraction        | 0.84     |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -3.12    |\n",
            "|    explained_variance   | 0.957    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 821      |\n",
            "|    n_updates            | 220      |\n",
            "|    policy_gradient_loss | 0.246    |\n",
            "|    std                  | 1.16     |\n",
            "|    value_loss           | 1.42e+03 |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88.4        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 1064        |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012657851 |\n",
            "|    clip_fraction        | 0.32        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.957       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 436         |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | 0.0231      |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 1.58e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 87.4        |\n",
            "|    ep_rew_mean          | -1.11e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 1109        |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.052262332 |\n",
            "|    clip_fraction        | 0.571       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.3        |\n",
            "|    explained_variance   | 0.982       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 315         |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | 0.0891      |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 1.04e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 85.7       |\n",
            "|    ep_rew_mean          | -1.08e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 1153       |\n",
            "|    total_timesteps      | 53248      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02710073 |\n",
            "|    clip_fraction        | 0.393      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.31      |\n",
            "|    explained_variance   | 0.965      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 710        |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | 0.0428     |\n",
            "|    std                  | 1.26       |\n",
            "|    value_loss           | 1.72e+03   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 86.7        |\n",
            "|    ep_rew_mean          | -1.1e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 1198        |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020032255 |\n",
            "|    clip_fraction        | 0.435       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.36       |\n",
            "|    explained_variance   | 0.96        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 723         |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | 0.0368      |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 1.66e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 86.8       |\n",
            "|    ep_rew_mean          | -1.1e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 1242       |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.36360073 |\n",
            "|    clip_fraction        | 0.545      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.32      |\n",
            "|    explained_variance   | 0.966      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 493        |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | 0.0948     |\n",
            "|    std                  | 1.26       |\n",
            "|    value_loss           | 1.44e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 88         |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 1287       |\n",
            "|    total_timesteps      | 59392      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.29276985 |\n",
            "|    clip_fraction        | 0.492      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.37      |\n",
            "|    explained_variance   | 0.963      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 1.42e+03   |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | 0.0611     |\n",
            "|    std                  | 1.45       |\n",
            "|    value_loss           | 1.75e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 89.5       |\n",
            "|    ep_rew_mean          | -1.14e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 1331       |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.48085427 |\n",
            "|    clip_fraction        | 0.482      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.65      |\n",
            "|    explained_variance   | 0.961      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 356        |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | 0.0632     |\n",
            "|    std                  | 1.63       |\n",
            "|    value_loss           | 1.04e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 88.8       |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 1375       |\n",
            "|    total_timesteps      | 63488      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03108428 |\n",
            "|    clip_fraction        | 0.524      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.82      |\n",
            "|    explained_variance   | 0.975      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 801        |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | 0.0751     |\n",
            "|    std                  | 1.61       |\n",
            "|    value_loss           | 1.08e+03   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 87.5      |\n",
            "|    ep_rew_mean          | -1.12e+03 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 1420      |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.2449437 |\n",
            "|    clip_fraction        | 0.451     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.79     |\n",
            "|    explained_variance   | 0.971     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 488       |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | 0.0688    |\n",
            "|    std                  | 1.48      |\n",
            "|    value_loss           | 1.21e+03  |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 87.7       |\n",
            "|    ep_rew_mean          | -1.13e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 33         |\n",
            "|    time_elapsed         | 1464       |\n",
            "|    total_timesteps      | 67584      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08201048 |\n",
            "|    clip_fraction        | 0.5        |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.72      |\n",
            "|    explained_variance   | 0.97       |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 454        |\n",
            "|    n_updates            | 320        |\n",
            "|    policy_gradient_loss | 0.0724     |\n",
            "|    std                  | 1.55       |\n",
            "|    value_loss           | 1.15e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 87.8       |\n",
            "|    ep_rew_mean          | -1.13e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 34         |\n",
            "|    time_elapsed         | 1509       |\n",
            "|    total_timesteps      | 69632      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06625369 |\n",
            "|    clip_fraction        | 0.425      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.76      |\n",
            "|    explained_variance   | 0.974      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 446        |\n",
            "|    n_updates            | 330        |\n",
            "|    policy_gradient_loss | 0.0465     |\n",
            "|    std                  | 1.6        |\n",
            "|    value_loss           | 1.15e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 87         |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 1554       |\n",
            "|    total_timesteps      | 71680      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.32693458 |\n",
            "|    clip_fraction        | 0.503      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.92      |\n",
            "|    explained_variance   | 0.971      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 1.02e+03   |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | 0.0806     |\n",
            "|    std                  | 2.14       |\n",
            "|    value_loss           | 1.38e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 89         |\n",
            "|    ep_rew_mean          | -1.15e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 36         |\n",
            "|    time_elapsed         | 1598       |\n",
            "|    total_timesteps      | 73728      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11241681 |\n",
            "|    clip_fraction        | 0.282      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.33      |\n",
            "|    explained_variance   | 0.962      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 788        |\n",
            "|    n_updates            | 350        |\n",
            "|    policy_gradient_loss | 0.0222     |\n",
            "|    std                  | 2.17       |\n",
            "|    value_loss           | 1.47e+03   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 86.8        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 1642        |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028586946 |\n",
            "|    clip_fraction        | 0.389       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.4        |\n",
            "|    explained_variance   | 0.971       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 648         |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 0.0406      |\n",
            "|    std                  | 2.16        |\n",
            "|    value_loss           | 1.1e+03     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 86.6       |\n",
            "|    ep_rew_mean          | -1.11e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 1687       |\n",
            "|    total_timesteps      | 77824      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03465491 |\n",
            "|    clip_fraction        | 0.419      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.41      |\n",
            "|    explained_variance   | 0.971      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 691        |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | 0.042      |\n",
            "|    std                  | 2.12       |\n",
            "|    value_loss           | 1.3e+03    |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 80        |\n",
            "|    ep_rew_mean          | -941      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 39        |\n",
            "|    time_elapsed         | 1732      |\n",
            "|    total_timesteps      | 79872     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1696.9004 |\n",
            "|    clip_fraction        | 0.856     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.34     |\n",
            "|    explained_variance   | 0.941     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 585       |\n",
            "|    n_updates            | 380       |\n",
            "|    policy_gradient_loss | 0.222     |\n",
            "|    std                  | 1.01      |\n",
            "|    value_loss           | 1.34e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 73.1      |\n",
            "|    ep_rew_mean          | -771      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 1777      |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 530.52527 |\n",
            "|    clip_fraction        | 0.957     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.85     |\n",
            "|    explained_variance   | 0.857     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 793       |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | 0.3       |\n",
            "|    std                  | 1.02      |\n",
            "|    value_loss           | 1.62e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 65.1      |\n",
            "|    ep_rew_mean          | -582      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 41        |\n",
            "|    time_elapsed         | 1821      |\n",
            "|    total_timesteps      | 83968     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 213.64673 |\n",
            "|    clip_fraction        | 0.963     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.16     |\n",
            "|    explained_variance   | 0.9       |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 585       |\n",
            "|    n_updates            | 400       |\n",
            "|    policy_gradient_loss | 0.291     |\n",
            "|    std                  | 1.21      |\n",
            "|    value_loss           | 1.11e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 64.1      |\n",
            "|    ep_rew_mean          | -559      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 42        |\n",
            "|    time_elapsed         | 1866      |\n",
            "|    total_timesteps      | 86016     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 16144.814 |\n",
            "|    clip_fraction        | 0.95      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.5      |\n",
            "|    explained_variance   | 0.925     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 241       |\n",
            "|    n_updates            | 410       |\n",
            "|    policy_gradient_loss | 0.302     |\n",
            "|    std                  | 0.465     |\n",
            "|    value_loss           | 741       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 65.4     |\n",
            "|    ep_rew_mean          | -574     |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 43       |\n",
            "|    time_elapsed         | 1911     |\n",
            "|    total_timesteps      | 88064    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 93.41362 |\n",
            "|    clip_fraction        | 0.995    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.37    |\n",
            "|    explained_variance   | 0.943    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 294      |\n",
            "|    n_updates            | 420      |\n",
            "|    policy_gradient_loss | 0.299    |\n",
            "|    std                  | 0.487    |\n",
            "|    value_loss           | 694      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 66.9      |\n",
            "|    ep_rew_mean          | -575      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 44        |\n",
            "|    time_elapsed         | 1956      |\n",
            "|    total_timesteps      | 90112     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 109.50314 |\n",
            "|    clip_fraction        | 0.981     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.45     |\n",
            "|    explained_variance   | 0.931     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 335       |\n",
            "|    n_updates            | 430       |\n",
            "|    policy_gradient_loss | 0.279     |\n",
            "|    std                  | 0.512     |\n",
            "|    value_loss           | 1.01e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 69.1      |\n",
            "|    ep_rew_mean          | -589      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 45        |\n",
            "|    time_elapsed         | 2001      |\n",
            "|    total_timesteps      | 92160     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 59.785126 |\n",
            "|    clip_fraction        | 0.988     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.47     |\n",
            "|    explained_variance   | 0.912     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 579       |\n",
            "|    n_updates            | 440       |\n",
            "|    policy_gradient_loss | 0.268     |\n",
            "|    std                  | 0.518     |\n",
            "|    value_loss           | 1.26e+03  |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 69.5     |\n",
            "|    ep_rew_mean          | -593     |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 46       |\n",
            "|    time_elapsed         | 2045     |\n",
            "|    total_timesteps      | 94208    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 80.72317 |\n",
            "|    clip_fraction        | 0.982    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.73    |\n",
            "|    explained_variance   | 0.908    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 633      |\n",
            "|    n_updates            | 450      |\n",
            "|    policy_gradient_loss | 0.26     |\n",
            "|    std                  | 0.607    |\n",
            "|    value_loss           | 1.17e+03 |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 69        |\n",
            "|    ep_rew_mean          | -593      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 47        |\n",
            "|    time_elapsed         | 2090      |\n",
            "|    total_timesteps      | 96256     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 40.688507 |\n",
            "|    clip_fraction        | 0.995     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.74     |\n",
            "|    explained_variance   | 0.952     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 290       |\n",
            "|    n_updates            | 460       |\n",
            "|    policy_gradient_loss | 0.291     |\n",
            "|    std                  | 0.596     |\n",
            "|    value_loss           | 735       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 67.5     |\n",
            "|    ep_rew_mean          | -584     |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 48       |\n",
            "|    time_elapsed         | 2135     |\n",
            "|    total_timesteps      | 98304    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 506.1672 |\n",
            "|    clip_fraction        | 0.958    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.75    |\n",
            "|    explained_variance   | 0.942    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 250      |\n",
            "|    n_updates            | 470      |\n",
            "|    policy_gradient_loss | 0.262    |\n",
            "|    std                  | 0.578    |\n",
            "|    value_loss           | 964      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 67.8      |\n",
            "|    ep_rew_mean          | -583      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 49        |\n",
            "|    time_elapsed         | 2180      |\n",
            "|    total_timesteps      | 100352    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 549.52594 |\n",
            "|    clip_fraction        | 0.979     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.71     |\n",
            "|    explained_variance   | 0.93      |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 285       |\n",
            "|    n_updates            | 480       |\n",
            "|    policy_gradient_loss | 0.261     |\n",
            "|    std                  | 0.572     |\n",
            "|    value_loss           | 542       |\n",
            "---------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Mean reward: -611.78407625, Std reward: 183.49704239646204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Large Language Models (4.0 puntos)**\n",
        "\n",
        "En esta secciÃ³n se enfocarÃ¡n en habilitar un Chatbot que nos permita responder preguntas Ãºtiles a travÃ©s de LLMs."
      ],
      "metadata": {
        "id": "mPUY-Ktgf2BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.0 ConfiguraciÃ³n Inicial**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Como siempre, cargamos todas nuestras API KEY al entorno:"
      ],
      "metadata": {
        "id": "mQ4fPRRihGLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ],
      "metadata": {
        "id": "Ud2Xm_k-hFJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef5ae4f-c972-4b10-b5a7-f4d629867b26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Enter your Tavily API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecciÃ³n es que habiliten un chatbot que pueda responder preguntas usando informaciÃ³n contenida en documentos PDF a travÃ©s de **Retrieval Augmented Generation.**"
      ],
      "metadata": {
        "id": "Rj9JvQUsgZZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
        "\n",
        "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
        "  - 2 documentos .pdf como mÃ­nimo.\n",
        "  - 50 pÃ¡ginas de contenido como mÃ­nimo entre todos los documentos.\n",
        "  - Ideas para documentos: Documentos relacionados a temas acadÃ©micos, laborales o de ocio. Aprovechen este ejercicio para construir algo Ãºtil y/o relevante para ustedes!\n",
        "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
        "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
        "  - **Recuerden adjuntar los documentos en su entrega**."
      ],
      "metadata": {
        "id": "ZrxOQroVnaZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet PyPDF2"
      ],
      "metadata": {
        "id": "5D1tIRCi4oJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58420841-4f22-4837-afd4-d5b6741bfc6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "doc_paths = [\"/content/Dialnet-FundacionDeColoColoEnChile1925-9639350.pdf\",\"/content/El-rol-socio-cultural-del-futbol-en-el-Chile-de-la-segunda-mitad-del-siglo-XX.pdf\",\"/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf\"] # rellenar con los path a sus documentos\n",
        "\n",
        "assert len(doc_paths) >= 2, \"Deben adjuntar un mÃ­nimo de 2 documentos\"\n",
        "\n",
        "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
        "assert total_paginas >= 50, f\"PÃ¡ginas insuficientes: {total_paginas}\""
      ],
      "metadata": {
        "id": "kzq2TjWCnu15"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
        "\n",
        "Vectorice los documentos y almacene sus representaciones de manera acorde."
      ],
      "metadata": {
        "id": "r811-P71nizA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D-B6sK2IihNU",
        "outputId": "278b7eab-30c1-48a4-a652-7b9488feec96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DLuqklaTi6Ig",
        "outputId": "7341ab6e-8cff-416d-90cc-14603068c002"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m297.0/298.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "ylmwLBFagUEX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar documentos\n",
        "docs = []\n",
        "for doc_path in doc_paths:\n",
        "    loader = PyPDFLoader(doc_path)\n",
        "    docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "o775M4d9gU16"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "xxHObXVDgcQb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWWeSByTjFoU",
        "outputId": "7c6fc142-05d4-4c72-b3b9-808b32fe3b26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.19)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-2.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGLDATSNjgX_",
        "outputId": "ddbf11d4-e38a-4129-b0b2-2904ebbf0ae5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n"
      ],
      "metadata": {
        "id": "1ArNa2Pkhiel"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRGqU5KJhv26",
        "outputId": "c456c940-055d-4b3b-8098-80ad1c04a696"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x7ace9dae7040>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
        "\n",
        "Habilite la soluciÃ³n RAG a travÃ©s de una *chain* y guÃ¡rdela en una variable."
      ],
      "metadata": {
        "id": "hAUkP5zrnyBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # mÃ©todo de bÃºsqueda\n",
        "                                     search_kwargs={\"k\": 3}, # nÂ° documentos a recuperar\n",
        "                                     )\n",
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzm26_xyj4aH",
        "outputId": "fb51ece0-b627-4a90-f0b7-d8f7b94a2c70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ace9dae7040>, search_kwargs={'k': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"cuando se fundo el club deportivo Colo-Colo?\" # pregunta\n",
        "relevant_documents = retriever.invoke(question) # top k documentos relevantes a la pregunta\n",
        "relevant_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyBTjrJNj-rY",
        "outputId": "798fccea-2ab6-4789-9f9a-addaebc2cb11"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf', 'page': 0}, page_content='instituciÃ³n,4  finalmente optaron por formar un nuevo club con sÃ³lidos principios deportivos y morales,\\npretensiÃ³n que fue estipulada en el acta de fundaciÃ³n de Colo-Colo.5  Tras una serie de reuniones, que\\ncomenzaron la noche del 12 de abril en la calle Covadonga del barrio EstaciÃ³n Central, la fundaciÃ³n de\\nColo-Colo quedÃ³ sellada el 19 de abril de 1925 en el Estadio El Llano.6\\nEn la primera reuniÃ³n del club, presidida de forma interina por Juan QuiÃ±ones, fueron propuestos varios'),\n",
              " Document(metadata={'source': '/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf', 'page': 1}, page_content='obligatorios, preparaciÃ³n de jugadas y aplicaciÃ³n de tÃ¡cticas,\\nasÃ­ como la disponibilidad de implementos y mÃ©dicos.10 \\nLuego de la fundaciÃ³n el equipo se inscribiÃ³ en la Primera DivisiÃ³n de la Liga Metropolitana. El primer\\npartido que jugÃ³ Colo-Colo en su historia y en esa divisiÃ³n fue ante el English, el 31 de mayo de 1925, y\\nque terminÃ³ con una victoria para Colo-Colo de 6:0. En la misma temporada ganaron su primer \"clÃ¡sico\"'),\n",
              " Document(metadata={'source': '/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf', 'page': 6}, page_content='futbolÃ­stico como en lo financiero. El 23 de enero de 2002 la justicia decretÃ³ la quiebra del club,\\ndejÃ¡ndolo a cargo del sÃ­ndico Juan Carlos Saffie, cuya gestiÃ³n permitiÃ³ la continuidad de giro del club,\\nnecesaria para que Colo-Colo no perdiera su personalidad jurÃ­dica y sus bienes no fueran a remate.\\nEn una de las etapas mÃ¡s difÃ­ciles para el club y despuÃ©s de cuatro aÃ±os, Colo-Colo se consagrÃ³ campeÃ³n')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
      ],
      "metadata": {
        "id": "-oQUEkxHkpNb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_chain = retriever | format_docs # chain\n",
        "print(retriever_chain.invoke(\"cuando se fundo el club deportivo Colo-Colo?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGvDmtbhkpF4",
        "outputId": "e0b8799b-9842-4ca1-92c7-4ca8ab2fcfd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instituciÃ³n,4  finalmente optaron por formar un nuevo club con sÃ³lidos principios deportivos y morales,\n",
            "pretensiÃ³n que fue estipulada en el acta de fundaciÃ³n de Colo-Colo.5  Tras una serie de reuniones, que\n",
            "comenzaron la noche del 12 de abril en la calle Covadonga del barrio EstaciÃ³n Central, la fundaciÃ³n de\n",
            "Colo-Colo quedÃ³ sellada el 19 de abril de 1925 en el Estadio El Llano.6\n",
            "En la primera reuniÃ³n del club, presidida de forma interina por Juan QuiÃ±ones, fueron propuestos varios\n",
            "\n",
            "obligatorios, preparaciÃ³n de jugadas y aplicaciÃ³n de tÃ¡cticas,\n",
            "asÃ­ como la disponibilidad de implementos y mÃ©dicos.10 \n",
            "Luego de la fundaciÃ³n el equipo se inscribiÃ³ en la Primera DivisiÃ³n de la Liga Metropolitana. El primer\n",
            "partido que jugÃ³ Colo-Colo en su historia y en esa divisiÃ³n fue ante el English, el 31 de mayo de 1925, y\n",
            "que terminÃ³ con una victoria para Colo-Colo de 6:0. En la misma temporada ganaron su primer \"clÃ¡sico\"\n",
            "\n",
            "futbolÃ­stico como en lo financiero. El 23 de enero de 2002 la justicia decretÃ³ la quiebra del club,\n",
            "dejÃ¡ndolo a cargo del sÃ­ndico Juan Carlos Saffie, cuya gestiÃ³n permitiÃ³ la continuidad de giro del club,\n",
            "necesaria para que Colo-Colo no perdiera su personalidad jurÃ­dica y sus bienes no fueran a remate.\n",
            "En una de las etapas mÃ¡s difÃ­ciles para el club y despuÃ©s de cuatro aÃ±os, Colo-Colo se consagrÃ³ campeÃ³n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\", # modelo de lenguaje\n",
        "    temperature=0, # probabilidad de \"respuestas creativas\"\n",
        "    max_tokens=None, # sin tope de tokens\n",
        "    timeout=None, # sin timeout\n",
        "    max_retries=2, # nÃºmero mÃ¡ximo de intentos\n",
        ")\n",
        "\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keGeZcJ1nF81",
        "outputId": "61dc7396-619e-415e-8da2-e0f0cfaa8836"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7ace9dae6d70>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "rag_template = '''\n",
        "Eres un historiador que conoce mucho sobre el club deportivo Colo Colo.\n",
        "Tu Ãºnico rol es contestar preguntas del usuario a partir de informaciÃ³n relevante que te sea proporcionada.\n",
        "Responde siempre de la forma mÃ¡s completa posible y usando toda la informaciÃ³n entregada.\n",
        "Responde sÃ³lo lo que te pregunten a partir de la informaciÃ³n relevante, NUNCA inventes una respuesta.\n",
        "\n",
        "InformaciÃ³n relevante: {context}\n",
        "Pregunta: {question}\n",
        "Respuesta Ãºtil:\n",
        "'''\n",
        "\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)"
      ],
      "metadata": {
        "id": "FZCuUquIlWZn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "vQXH6lq1naiL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain,\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos sÃ³lo la respuesta\n",
        ")"
      ],
      "metadata": {
        "id": "jNUEdlSJmRkQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.4 VerificaciÃ³n de respuestas (0.5 puntos)**\n",
        "\n",
        "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluciÃ³n para cada una. Â¿Su soluciÃ³n RAG entrega las respuestas que esperaba?\n",
        "\n",
        "Ejemplo de tupla:\n",
        "- Pregunta: Â¿QuiÃ©n es el presidente de Chile?\n",
        "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
      ],
      "metadata": {
        "id": "ycg5S5i_n-kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    (\"Â¿CuÃ¡ndo se fundÃ³ Colo Colo?\"),   # Colo Colo se fundÃ³ el 19 de abril de 1925.\n",
        "     (\"Â¿QuiÃ©n fue el primer presidente de Colo Colo?\"),   # El primer presidente fue David Arellano.\n",
        "     (\"Â¿CuÃ¡l es el estadio de Colo Colo?\")   # El estadio de Colo Colo es el Estadio Monumental.\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "\n",
        "  response = rag_chain.invoke(question)\n",
        "  result_tuple = (question, response)\n",
        "  print(result_tuple)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsKryS3NuCpR",
        "outputId": "8b0b3cf9-e727-4c6f-8048-bcc50a6dafa5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'La informaciÃ³n proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', 'De acuerdo a la informaciÃ³n proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  TambiÃ©n se menciona el estadio \"Calvo y BascuÃ±Ã¡n\", pero en el contexto de daÃ±os causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la soluciÃ³n RAG entrega las repsuestas correctas para 2 de las 3 preguntas, sÃ³lamente fallando en una pregunta debido a que, al parecer, la respuesta no se puede encontrar dentro de los documentos entregados al inicio."
      ],
      "metadata": {
        "id": "yITk-vLWxvQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.5 Sensibilidad de HiperparÃ¡metros (0.5 puntos)**\n",
        "\n",
        "Extienda el anÃ¡lisis del punto 2.1.4 analizando cÃ³mo cambian las respuestas entregadas cambiando los siguientes hiperparÃ¡metros:\n",
        "- `TamaÃ±o del chunk`. (*Â¿CÃ³mo repercute que los chunks sean mas grandes o chicos?*)\n",
        "- `La cantidad de chunks recuperados`. (*Â¿QuÃ© pasa si se devuelven muchos/pocos chunks?*)\n",
        "- `El tipo de bÃºsqueda`. (*Â¿CÃ³mo afecta el tipo de bÃºsqueda a las respuestas de mi RAG?*)"
      ],
      "metadata": {
        "id": "X8d5zTMHoUgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_sizes = [200, 1000]\n",
        "for chunk_size in chunk_sizes:\n",
        "    print(f\"\\nProbando con chunk size: {chunk_size}\")\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
        "    splits = text_splitter.split_documents(docs)\n",
        "\n",
        "    vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
        "\n",
        "    for question in questions:\n",
        "      response = rag_chain.invoke(question)\n",
        "      result_tuple = (question, response)\n",
        "      print(result_tuple)\n",
        "\n"
      ],
      "metadata": {
        "id": "UDh_QgeXLGHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dae0da-ab7a-44cf-88e7-2475976b3caf"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando con chunk size: 200\n",
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'La informaciÃ³n proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', 'De acuerdo a la informaciÃ³n proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  TambiÃ©n se menciona el estadio \"Calvo y BascuÃ±Ã¡n\", pero en el contexto de daÃ±os causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', 'La informaciÃ³n proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', 'Colo-Colo ganÃ³ la Copa Libertadores en 1991.\\n')\n",
            "\n",
            "Probando con chunk size: 1000\n",
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'La informaciÃ³n proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', 'De acuerdo a la informaciÃ³n proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  TambiÃ©n se menciona el estadio \"Calvo y BascuÃ±Ã¡n\", pero en el contexto de daÃ±os causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', 'La informaciÃ³n proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', 'Colo-Colo ganÃ³ la Copa Libertadores en 1991.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de las preguntas, no se observan diferencias en las respuestas generadas variando el tamaÃ±o de los chunks."
      ],
      "metadata": {
        "id": "6B5S-G3SahzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_chunks = [2, 10]  # Cantidades de chunks\n",
        "for k in retrieved_chunks:\n",
        "    print(f\"\\nProbando con {k} chunks recuperados\")\n",
        "\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", # mÃ©todo de bÃºsqueda\n",
        "                                     search_kwargs={\"k\": retrieved_chunks}, # nÂ° documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "    for question in questions:\n",
        "\n",
        "      response = rag_chain.invoke(question)\n",
        "      result_tuple = (question, response)\n",
        "      print(result_tuple)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfTK94ZZ-qzY",
        "outputId": "e67025f9-2be3-4974-ad85-e7992ddb2735"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando con 2 chunks recuperados\n",
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'La informaciÃ³n proporcionada no indica quiÃ©n fue el primer presidente de Colo Colo.\\n')\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', 'De acuerdo a la informaciÃ³n proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  TambiÃ©n se menciona el estadio \"Calvo y BascuÃ±Ã¡n\", pero en el contexto de daÃ±os causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', 'La informaciÃ³n proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', 'Colo-Colo ganÃ³ la Copa Libertadores en 1991.\\n')\n",
            "\n",
            "Probando con 10 chunks recuperados\n",
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'La informaciÃ³n proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', 'De acuerdo a la informaciÃ³n proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989, con un partido entre Colo-Colo y PeÃ±arol.  TambiÃ©n se menciona el estadio \"Calvo y BascuÃ±Ã¡n\", donde ocurrieron incidentes con barristas de Colo Colo tras una derrota contra Antofagasta.  Sin embargo, la informaciÃ³n no indica que \"Calvo y BascuÃ±Ã¡n\" sea el estadio de Colo Colo.\\n')\n",
            "('CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', 'La informaciÃ³n proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', 'Colo-Colo ganÃ³ la Copa Libertadores en 1991.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de las preguntas, no se observan diferencias en las respuestas generadas variando el nÃºmero de chunks seleccionados."
      ],
      "metadata": {
        "id": "kt00yIbjbArC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_types = [\"similarity\", \"mmr\"]  # Ejemplo de tipos de bÃºsqueda\n",
        "for search_type in search_types:\n",
        "    print(f\"\\nProbando con tipo de bÃºsqueda: {search_type}\")\n",
        "\n",
        "    retriever = vectorstore.as_retriever(search_type=search_type, # mÃ©todo de bÃºsqueda\n",
        "                                     search_kwargs={\"k\": 3}, # nÂ° documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "    for question in questions:\n",
        "\n",
        "      response = rag_chain.invoke(question)\n",
        "      result_tuple = (question, response)\n",
        "      print(result_tuple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrm4XGFt-ugq",
        "outputId": "99ee4296-43a5-49d4-e769-6a3446f66b6e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando con tipo de bÃºsqueda: similarity\n",
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'La informaciÃ³n proporcionada no indica quiÃ©n fue el primer presidente de Colo Colo.\\n')\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', 'De acuerdo a la informaciÃ³n proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  TambiÃ©n se menciona el estadio \"Calvo y BascuÃ±Ã¡n\", pero en el contexto de daÃ±os causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', 'La informaciÃ³n proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', 'Colo-Colo ganÃ³ la Copa Libertadores en 1991.\\n')\n",
            "\n",
            "Probando con tipo de bÃºsqueda: mmr\n",
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'La informaciÃ³n proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', 'De acuerdo a la informaciÃ³n proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  TambiÃ©n se menciona el estadio \"Calvo y BascuÃ±Ã¡n\", pero en el contexto de daÃ±os causados por barristas de Colo Colo tras una derrota.  No se indica que sea el estadio del club.\\n')\n",
            "('CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', 'La informaciÃ³n proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', 'Colo-Colo ganÃ³ la Copa Libertadores en 1991.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 Agentes (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secciÃ³n anterior, en esta secciÃ³n se busca habilitar **Agentes** para obtener informaciÃ³n a travÃ©s de tools y asÃ­ responder la pregunta del usuario."
      ],
      "metadata": {
        "id": "ENJiPPM0giX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas al motor de bÃºsqueda **Tavily**."
      ],
      "metadata": {
        "id": "V47l7Mjfrk0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_search = TavilySearchResults(max_results = 1) # inicializamos tool\n",
        "tools = [tavily_search] # guardamos las tools en una lista"
      ],
      "metadata": {
        "id": "_rJUQvTs0hAO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet langchain requests\n"
      ],
      "metadata": {
        "id": "R6SLKwcWr0AG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
        "\n",
        "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
      ],
      "metadata": {
        "id": "SonB1A-9rtRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r6l4lyZV1tEQ",
        "outputId": "49f8139a-0824-4bb7-98ce-31915d3bb2ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=28ba588c2765042a34f7abef07340c004564dc04920be4b9572bd9fad58df5e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ],
      "metadata": {
        "id": "_di_zcxz1SiX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
        "wiki_search = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "tools.append(wiki_search)"
      ],
      "metadata": {
        "id": "047lv-Oc1X4q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iC0RrVGYADqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
        "\n",
        "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. AsegÃºrese que su agente responda en espaÃ±ol. Por Ãºltimo, guarde el agente en una variable."
      ],
      "metadata": {
        "id": "CvUIMdX6r0ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "react_prompt = hub.pull(\"hwchase17/react\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkgB93fE2Tt8",
        "outputId": "287a117e-f691-41d2-f726-327287d0bfb3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "\n",
        "agent = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=50,max_execution_time=60) # lo transformamos a AgentExecutor para habilitar la ejecuciÃ³n de tools\n",
        "agent_executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_pfFH4y12kvI",
        "outputId": "a0a9c21b-4e74-4ca8-f4b9-08eac58d9e32"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
              "})\n",
              "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'tavily_search_results_json - A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\\nwikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'tool_names': 'tavily_search_results_json, wikipedia'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
              "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7ace9dae6d70>, default_metadata=()), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
              "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[TavilySearchResults(max_results=1, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=100))], max_iterations=50, max_execution_time=60.0)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.4 VerificaciÃ³n de respuestas (0.3 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente y asegÃºrese que el agente estÃ© ocupando correctamente las tools disponibles. Â¿En quÃ© casos el agente deberÃ­a ocupar la tool de Tavily? Â¿En quÃ© casos deberÃ­a ocupar la tool de Wikipedia?"
      ],
      "metadata": {
        "id": "dKV0JxK3r-XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = agent_executor.invoke({\"input\": \"CuÃ¡l es el precio del Bitcoin en pesos Chilenos?\"})\n",
        "print(response1[\"output\"])\n",
        "\n",
        "response2 = agent_executor.invoke({\"input\": \"quÃ© equipo ganÃ³ la copa Libertadores en 1991?\"})\n",
        "print(response2[\"output\"])"
      ],
      "metadata": {
        "id": "Pqo2dsxvywW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "882217da-336a-42be-a7f8-d55747840122"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Bitcoin in Chilean Pesos.  A real-time price is needed, so a search engine is the best option.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"Bitcoin price in Chilean Pesos\"\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://coinmarketcap.com/currencies/bitcoin/btc/clp/', 'content': 'Bitcoin to Chilean Peso Data. The BTC to CLP conversion rate today is $70,203.23. This is a decrease of 0.18% in the last hour and a decrease of 2.89% in the last 24 hours. The recent price direction of Bitcoin is a decrease because BTC is up by 14.58% against CLP in the last 30 days. Our converter updates in real time, giving you accurate'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now have the current Bitcoin price in Chilean Pesos from a reliable source.\n",
            "\n",
            "Final Answer: El precio actual de Bitcoin en pesos chilenos es aproximadamente $70,203.23.  Tenga en cuenta que este precio puede variar rÃ¡pidamente.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "El precio actual de Bitcoin en pesos chilenos es aproximadamente $70,203.23.  Tenga en cuenta que este precio puede variar rÃ¡pidamente.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out which team won the Copa Libertadores in 1991.  Wikipedia should have this information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: 1991 Copa Libertadores\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mPage: 1991 Copa Libertadores\n",
            "Summary: The 1991 Copa Libertadores was won by Colo-Colo of Chile after\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: Colo-Colo\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Colo-Colo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de las respuestas podemos ver que el Agente utiliza la tool de Wikipedia cuando para responder la pregunta se necesita de informaciÃ³n histÃ³rica o mÃ¡s consolidada. Por otro lado, el Agente utiliza la tool de tavily cuando se necesita informaciÃ³n mÃ¡s reciente o especÃ­fica."
      ],
      "metadata": {
        "id": "Rs67wV358Rif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3 Multi Agente (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
        "\" width=\"450\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecciÃ³n es encapsular las funcionalidades creadas en una soluciÃ³n multiagente con un **supervisor**.\n"
      ],
      "metadata": {
        "id": "cZbDTYiogquv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
        "\n",
        "Transforme la soluciÃ³n RAG de la secciÃ³n 2.1 y el agente de la secciÃ³n 2.2 a *tools* (una tool por cada uno)."
      ],
      "metadata": {
        "id": "7-iUfH0WvI6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "react_tool = Tool(\n",
        "    name=\"ReAct_Agent\",\n",
        "    func=lambda query: agent_executor.invoke({\"input\": query}),\n",
        "    description=\"Un agente que responde preguntas utilizando las tools Wikipedia y Tavily.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "srKKF4iD__nC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_tool = Tool(\n",
        "    name=\"RAG_Solution\",\n",
        "    func=lambda query: rag_chain.invoke({\"question\": query}),\n",
        "    description=\"Una soluciÃ³n basada en RAG que responde preguntas utilizando un modelo de recuperaciÃ³n y generaciÃ³n.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "bhqJt69wA4Xs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
        "\n",
        "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
      ],
      "metadata": {
        "id": "HQYNjT_0vPCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [react_tool, rag_tool]"
      ],
      "metadata": {
        "id": "yv2ZY0BAv1RD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supervisor = create_react_agent(llm, tools, react_prompt)\n",
        "supervisor_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=100,max_execution_time=120)"
      ],
      "metadata": {
        "id": "g7XzHyQ1LXfu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.3 VerificaciÃ³n de respuestas (0.25 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. Â¿CÃ³mo varÃ­an las respuestas bajo este enfoque?"
      ],
      "metadata": {
        "id": "ea3zWlvyvY7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions2 = [\n",
        "    \"Â¿CuÃ¡ndo se fundÃ³ Colo Colo?\",\n",
        "    \"Â¿QuiÃ©n fue el primer presidente de Colo Colo?\",\n",
        "    \"Â¿CuÃ¡l es el estadio de Colo Colo?\",\n",
        "    \"CuÃ¡l es el precio del Bitcoin en pesos Chilenos?\",\n",
        "    \"QuÃ© equipo ganÃ³ la copa Libertadores en 1991?\"\n",
        "]\n",
        "\n",
        "for question in questions2:\n",
        "\n",
        "  response = supervisor_executor.invoke({\"input\": question})\n",
        "  result_tuple = (question, response)\n",
        "  print(result_tuple)"
      ],
      "metadata": {
        "id": "6_1t0zkgv1qW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f3ba0b88-9bb8-40db-8739-157deb75dcd4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To answer when Colo Colo was founded, I need to consult a reliable source with information on the history of the Chilean football club. Wikipedia is a good starting point.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Colo-Colo\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I tried to use a tool that wasn't available.  I'll try a different approach.  I'll use a general web search to find the founding date of Colo-Colo.  Since I don't have access to `tavily_search_results_json`, I'll assume a general web search will suffice.  I'll need to find a reliable source, such as a reputable sports website or encyclopedia.\n",
            "\n",
            "Action:  (Simulated Web Search)\n",
            "Action Input: \"Colo-Colo founding date\"\n",
            "\u001b[0m(Simulated Web Search) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using tools that are unavailable.  I will attempt to answer based on my existing knowledge.\n",
            "\n",
            "Thought: I know that Colo-Colo is a Chilean football club with a long history.  While I don't have access to specific databases, I can recall that its founding date is generally accepted to be in the early 20th century.  I'll need to refine my answer.\n",
            "\n",
            "Thought: I will try to recall the specific year.  My knowledge suggests it was around 1925.  I need to verify this.\n",
            "\n",
            "Thought: I cannot verify this information without access to external resources.  Therefore, I will provide the best answer I can based on my limited knowledge.\n",
            "\n",
            "Final Answer: Colo-Colo was founded in the early 20th century, around 1925.  This answer should be verified with a reliable source for accuracy.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', {'input': 'Â¿CuÃ¡ndo se fundÃ³ Colo Colo?', 'output': 'Colo-Colo was founded in the early 20th century, around 1925.  This answer should be verified with a reliable source for accuracy.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find information about the first president of the Colo-Colo football club.  Wikipedia is a good resource for this type of information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Colo-Colo\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I tried to use a tool that wasn't available.  I'll try a different approach.  I'll search for information about the first president of Colo-Colo using a web search.  Since I don't have access to `tavily_search_results_json`, I'll assume it's similar to a standard web search and proceed accordingly.  I'll need to formulate a search query in Spanish.\n",
            "\n",
            "Action:  (Simulated Web Search)\n",
            "Action Input: \"primer presidente Colo Colo\"\n",
            "\u001b[0m(Simulated Web Search) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find information about the first president of Colo-Colo.  Since I don't have access to the specified tools, I will attempt to answer based on my existing knowledge.  My knowledge base is limited, so the answer may be incomplete or inaccurate.\n",
            "\n",
            "Thought: I will try to find information online using a general search engine.\n",
            "\n",
            "Action: (Simulated Web Search)\n",
            "Action Input: \"primer presidente Colo Colo\"\n",
            "\u001b[0m(Simulated Web Search) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I don't have access to any of the specified tools, and my attempts to simulate web searches have failed.  Therefore, I cannot answer the question definitively.  I need access to a working search engine or knowledge base to find the answer.\n",
            "\n",
            "Final Answer: I am unable to answer the question due to a lack of access to functional search tools.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('Â¿QuiÃ©n fue el primer presidente de Colo Colo?', {'input': 'Â¿QuiÃ©n fue el primer presidente de Colo Colo?', 'output': 'I am unable to answer the question due to a lack of access to functional search tools.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out the name of the stadium where the Chilean football club Colo-Colo plays its home games.  Wikipedia should have this information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Colo-Colo\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I used an invalid tool.  I'll try a different approach using a web search.  I'll use a search engine to find the stadium of Colo-Colo.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"Colo-Colo stadium\"\n",
            "\u001b[0mtavily_search_results_json is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the unavailable tools.  I will try to answer based on my general knowledge.\n",
            "\n",
            "Thought: I know that Colo-Colo plays its home games at the Estadio Monumental David Arellano.\n",
            "\n",
            "Final Answer: El estadio de Colo Colo es el Estadio Monumental David Arellano.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('Â¿CuÃ¡l es el estadio de Colo Colo?', {'input': 'Â¿CuÃ¡l es el estadio de Colo Colo?', 'output': 'El estadio de Colo Colo es el Estadio Monumental David Arellano.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Bitcoin in Chilean Pesos.  A real-time price is needed, so a search engine is the best option.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"Bitcoin price in Chilean Pesos\"\n",
            "\u001b[0mtavily_search_results_json is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Bitcoin in Chilean Pesos.  Since I don't have access to `tavily_search_results_json`, I'll try a general web search using a different method.  I cannot guarantee real-time accuracy without a dedicated financial API.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: \"Bitcoin\"\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I cannot answer the question without access to a real-time price feed for Bitcoin.  Wikipedia and a hypothetical \"tavily_search_results_json\" are not suitable for obtaining this information.  The price of Bitcoin fluctuates constantly.\n",
            "\n",
            "Final Answer: I cannot provide the current price of Bitcoin in Chilean Pesos.  To get this information, you need to consult a live cryptocurrency exchange that displays prices in Chilean Pesos.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', {'input': 'CuÃ¡l es el precio del Bitcoin en pesos Chilenos?', 'output': 'I cannot provide the current price of Bitcoin in Chilean Pesos.  To get this information, you need to consult a live cryptocurrency exchange that displays prices in Chilean Pesos.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out which team won the Copa Libertadores in 1991.  Wikipedia should have this information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: 1991 Copa Libertadores\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I used an invalid tool.  I'll try a different approach using a search engine.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mtavily_search_results_json is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will try to formulate a search query that a standard search engine can understand.\n",
            "\n",
            "Action: Google Search (simulated)\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mGoogle Search (simulated) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will try to formulate a search query that a standard search engine can understand.  I will assume access to a standard search engine.\n",
            "\n",
            "Action: Google Search (simulated)\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mGoogle Search (simulated) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will try to formulate a search query that a standard search engine can understand.  I will assume access to a standard search engine and will simulate the results.\n",
            "\n",
            "Action: Simulated Google Search\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mSimulated Google Search is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will use my own knowledge base.\n",
            "\n",
            "Thought: I now know the final answer.\n",
            "Final Answer:  Colo-Colo won the Copa Libertadores in 1991.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', {'input': 'QuÃ© equipo ganÃ³ la copa Libertadores en 1991?', 'output': 'Colo-Colo won the Copa Libertadores in 1991.'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La principal diferencia es que el agente genera respuestas en inglÃ©s y, ademÃ¡s, las respuestas parecen ser un poco mÃ¡s completas, en el sentido de que entregan la misma informaciÃ³n, pero contenidas en una oraciÃ³n mÃ¡s extensa, por ejemplo para la pregunta \"Â¿QuÃ© equipo ganÃ³ la copa Libertadores en 1991?, este modelo responde \"Colo colo ganÃ³ la copa Libertadores en 1991\", mientras que el agente anterior solamente respondÃ­a \"Colo Colo\""
      ],
      "metadata": {
        "id": "orUQ55amT74h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.4 AnÃ¡lisis (0.25 puntos)**\n",
        "\n",
        "Â¿QuÃ© diferencias tiene este enfoque con la soluciÃ³n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
      ],
      "metadata": {
        "id": "Qb8bdAmYvgwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este enfoque es mÃ¡s recomendable que la soluciÃ³n Router cuando el usuario requiere responder preguntas basadas en un tema en especÃ­fico (por ejemplo, documentaciÃ³n empresarial, artÃ­culos cientÃ­ficos, etc.) ya que en este caso se necesita un agente capaz de manejar informaciÃ³n mÃ¡s especÃ­fica y contextualizada.Sin embargo, tambiÃ©n tiene una desventaja con respecto a Router a la hora de tratar con tareas de Ã¡mbitos diferentes, ya que en este caso la soluciÃ³n Router es mejor debido a su capacidad para manejar preguntas de naturaleza diversa."
      ],
      "metadata": {
        "id": "YAUlJxqoLK5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
        "\n",
        "- Pregunta 1: \"Hola! mi nombre es SebastiÃ¡n\"\n",
        "  - Respuesta esperada: \"Hola SebastiÃ¡n! ...\"\n",
        "- Pregunta 2: \"Cual es mi nombre?\"\n",
        "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
        "  - **Respuesta esperada: \"Tu nombre es SebastiÃ¡n\"**\n",
        "\n",
        "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluciÃ³n entregada en el punto 2.3.\n",
        "\n",
        "**Nota: El Bonus es vÃ¡lido <u>sÃ³lo para la secciÃ³n 2 de Large Language Models.</u>**"
      ],
      "metadata": {
        "id": "4JWVSuWiZ8Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6Y7tIPJLPfB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.5 Despliegue (0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a travÃ©s de `gradio`, una librerÃ­a especializada en el levantamiento rÃ¡pido de demos basadas en ML.\n",
        "\n",
        "Primero instalamos la librerÃ­a:"
      ],
      "metadata": {
        "id": "vFc3jBT5g0kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet gradio"
      ],
      "metadata": {
        "id": "T8TsvnCPbkIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5e781b-02d9-4214-ba6c-ae5f88bdc300"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego sÃ³lo deben ejecutar el siguiente cÃ³digo e interactuar con la interfaz a travÃ©s del notebook o del link generado:"
      ],
      "metadata": {
        "id": "HJBztEUovKsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def agent_response(message, history):\n",
        "  '''\n",
        "  FunciÃ³n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
        "  '''\n",
        "  # get chatbot response\n",
        "  response = agent_executor.invoke({\"input\": message})[\"output\"] # rellenar con la respuesta de su chat\n",
        "\n",
        "  # assert\n",
        "  assert type(response) == str, \"output de route_question debe ser string\"\n",
        "\n",
        "  # \"streaming\" response\n",
        "  for i in range(len(response)):\n",
        "    time.sleep(0.015)\n",
        "    yield response[: i+1]\n",
        "\n",
        "gr.ChatInterface(\n",
        "    agent_response,\n",
        "    type=\"messages\",\n",
        "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
        "    description=\"Hola! Soy un chatbot muy Ãºtil :)\", # tambiÃ©n la descripciÃ³n\n",
        "    theme=\"soft\",\n",
        "    ).launch(\n",
        "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
        "        debug = False,\n",
        "        )"
      ],
      "metadata": {
        "id": "Z3KedQSvg1-n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "fbf588e3-6caf-4602-94c6-f37cc1548054"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://250ecad1d8bb704850.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://250ecad1d8bb704850.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}