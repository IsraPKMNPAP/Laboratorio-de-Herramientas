{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29065d993b3a44e28f9daf5ed7132750": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_252a90d5f26640509f56bc360ed79326",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6,119/5,000 \u001b[0m [ \u001b[33m0:00:16\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m364 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">6,119/5,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:16</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">364 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "252a90d5f26640509f56bc360ed79326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17d97783064448fac8dd4f7d81875cf": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_20216105e8864df6bcc007401b99e6a5",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10,204/10,000 \u001b[0m [ \u001b[33m0:00:24\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m417 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">10,204/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:24</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">417 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "20216105e8864df6bcc007401b99e6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8a77a55dd74b50befd6d534246ba6e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_78344ce0eb5c469f86ceb45731e3bd25",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100,349/100,000 \u001b[0m [ \u001b[33m0:36:11\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m48 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">100,349/100,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:36:11</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">48 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "78344ce0eb5c469f86ceb45731e3bd25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Laboratorio 11: LLM y Agentes Autónomos 🤖**\n",
        "\n",
        "MDS7202: Laboratorio de Programación Científica para Ciencia de Datos"
      ],
      "metadata": {
        "id": "PyPTffTLug7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cuerpo Docente:**\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
        "- Auxiliar: Eduardo Moya\n",
        "- Ayudantes: Nicolás Ojeda, Melanie Peña, Valentina Rojas"
      ],
      "metadata": {
        "id": "5pbWVyntzbvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados**\n",
        "\n",
        "- Nombre de alumno 1: Luis Picón\n",
        "- Nombre de alumno 2: Israel Astudillo M."
      ],
      "metadata": {
        "id": "dy6ikgVYzghB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/IsraPKMNPAP/Laboratorio-de-Herramientas)"
      ],
      "metadata": {
        "id": "iMJ-owchzjFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Reinforcement Learning\n",
        "- Large Language Models\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Resolución de problemas secuenciales usando Reinforcement Learning\n",
        "- Habilitar un Chatbot para entregar respuestas útiles usando Large Language Models.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ],
      "metadata": {
        "id": "WUuwsXrKzmkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta sección van a usar métodos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ],
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq gymnasium[box2d]"
      ],
      "metadata": {
        "id": "gOcejYb6uzOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d444b4-9898-4a57-8606-f32c2146e60e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/958.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m952.3/958.1 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "La idea de esta subsección es que puedan implementar métodos de RL y así generar una estrategia para jugar el clásico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
      ],
      "metadata": {
        "id": "qBPet_Mq8dX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.1 Descripción de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripción sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ],
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El ambiente BlackJack es un ambiente de contexto de aprendizaje reforzado que impone las reglas y funcionamiento de la situación a simular, en este caso un juego de Black Jack.\n",
        "La formulación MDP es la siguiente en base a las variables que incluye el modelo:\n",
        "- Acciones: Hay dos posibles acciones realizables por el agente las cuales son \"stick\" o \"hit\" que representan quedarse con las cartas actuales o pedir una carta extra respectivamente. Está descrito formalmente como Discrete(2) dado que hay 2 acciones.\n",
        "- Estados: La información que obtiene el agente de cada estado en el tiempo y que por tanto describen cada estado son la suma total de las cartas que posee el jugador, el valor de la carta del dealer boca arriba y si el jugador posee o no un as usable o que puede cambiar su valor. Descrito formalmente como Tuple(Discrete(32), Discrete(11), Discrete(2)) dado que la suma de cartas del jugador puede tomar 32 valores, la del dealer 11 valores y la si tiene un as dos valores. Así, hay 32 x 11 x 2 = 704 posibles estados que puede tener el espacio de observación.\n",
        "- Recompensas: Las recompensas entregadas son +1 si es que se gana el juego, -1 si se pierde, 0 si se empata y 1.5 si el blackjack de la victoria es natural."
      ],
      "metadata": {
        "id": "G5i1Wt1p770x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 5000 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política? ¿Cómo podría interpretar las recompensas obtenidas?"
      ],
      "metadata": {
        "id": "pmcX6bRC9agQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recompensas\n",
        "R = []\n",
        "# Loop de simulaciones\n",
        "for episode in range(5000):\n",
        "  # Nueva iteración, reseteamos el juego\n",
        "  obs = env.reset()\n",
        "  # Inicializamos variable de término del juego\n",
        "  done = False\n",
        "  # Loop de cada juego, utilizamos la variable de término del juego\n",
        "  while not done:\n",
        "    # Acción aleatoria\n",
        "    action = env.action_space.sample()\n",
        "    # Resultado de la acción\n",
        "    obs, reward, done,truncated, info = env.step(action)\n",
        "    # Continúa hasta que el juego termine, cuando done=True\n",
        "  # Terminado el juego actual, reportamos la recompensa\n",
        "  R.append(reward)\n",
        "  # Siguiente juego"
      ],
      "metadata": {
        "id": "TkcUmXkJH9n1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Promedio de recompensas: \", np.mean(R))\n",
        "print(\"Desviación de recompensas: \", np.std(R))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxeggWOmN-UF",
        "outputId": "3c1f00fb-2e6c-4fe1-b096-f89f88b1871d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio de recompensas:  -0.3894\n",
            "Desviación de recompensas:  0.8994262838054045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "yJJop0ePaW1n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El performance parece ser malo, dado que su promedio de ganancias es negativo.\n",
        "El performance de la política aleatoria tiene un valor promedio negativo, lo cual nos indica que en promedio se pierde más de lo que se gana. Por otro lado, la desviación de las recompensas es bastante alta, cercana a ser la unidad completa que se asigna de premio o castigo en el juego. En general las recompensas obtenidas con esta política no llevan a un desempeño promedio positivo."
      ],
      "metadata": {
        "id": "cK4gCmJBOSNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ],
      "metadata": {
        "id": "LEO_dY4x_SJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ],
      "metadata": {
        "id": "8wXvKFvjaJRg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos PPO que soporta todos los tipos de conjuntos de acciones\n",
        "# sin embargo, en este caso el conjunto de acciones y de estados es discreto.\n",
        "from stable_baselines3 import PPO\n",
        "# init agent\n",
        "model = PPO(\"MlpPolicy\", env, verbose=0)"
      ],
      "metadata": {
        "id": "m9JsFA1wGmnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148b0a9e-b78d-4a28-a17b-7885168a445d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(5000), progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "29065d993b3a44e28f9daf5ed7132750",
            "252a90d5f26640509f56bc360ed79326"
          ]
        },
        "id": "ZVAR44UzX9zw",
        "outputId": "00788e33-f12a-4851-830f-608a5881a636"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29065d993b3a44e28f9daf5ed7132750"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7de7d0504f70>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"blackjack\")"
      ],
      "metadata": {
        "id": "BfMdcfTXYKuH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "E-bpdb8wZID1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = PPO.load(\"blackjack\")\n",
        "model.set_env(env)"
      ],
      "metadata": {
        "id": "N27jbsnQZwFs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Evaluate the agent\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "id": "5-d7d8GFf7F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4319a0-88c2-48fa-99c5-37ed7b4b8428"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.2, 0.8717797887081348)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El performance del agente con el algoritmo PPO es peor que el aleatorio baseline, la pérdida es mayor pero la desviación estándar respecto a esta es menor lo cual puede ser un buen atributo de lo encontrado."
      ],
      "metadata": {
        "id": "sIrlqqn2cEQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "Genere una función que reciba un estado y retorne la accion del agente. Luego, use esta función para entregar la acción escogida frente a los siguientes escenarios:\n",
        "\n",
        "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "¿Son coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¿A que clase de python pertenecen los estados? Pruebe a usar el método `.reset` para saberlo."
      ],
      "metadata": {
        "id": "RO-EsAaPAYEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3vS0KKKz2x5",
        "outputId": "e870bd21-2adb-4bc2-c88d-2a15e1c17ff4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([17,  9,  0]), {})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que los estados pertenecen a la clase array de python, por lo que procesamos el estado en la función de la misma forma. Nuevamente haciendo flatten() para obtener las dimensiones correctas del array."
      ],
      "metadata": {
        "id": "4UpCLoqz0fJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_agent_action(model, player_sum, dealer_card, usable_ace):\n",
        "  state = np.array([player_sum, dealer_card, int(usable_ace)]).flatten()\n",
        "  action, _ = model.predict(state)\n",
        "  return action\n",
        "\n",
        "# Escenario 1\n",
        "player_sum_1 = 6\n",
        "dealer_card_1 = 7\n",
        "usable_ace_1 = False\n",
        "action_1 = get_agent_action(model, player_sum_1, dealer_card_1, usable_ace_1)\n",
        "print(f\"Escenario 1: Acción = {action_1}\")\n",
        "\n",
        "# Escenario 2\n",
        "player_sum_2 = 19\n",
        "dealer_card_2 = 3\n",
        "usable_ace_2 = True\n",
        "action_2 = get_agent_action(model, player_sum_2, dealer_card_2, usable_ace_2)\n",
        "print(f\"Escenario 2: Acción = {action_2}\")"
      ],
      "metadata": {
        "id": "Fh8XlGyzwtRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c05fd3-46ad-4daa-d40a-f822367e71f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escenario 1: Acción = 0\n",
            "Escenario 2: Acción = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien el modelo tiene un valor promedio de ganancia negativo, la respuesta a los casos específicos probados parece ser razonabole y acorde a las reglas del juego dado que con una suma baja toma la acción de pedir más cartas, que es la jugada esperable. Por otro lado, cuando la suma es alta no pide cartas, indicando que su decisión está en cierta medida guiada por el castigo que existe al pasar el 21."
      ],
      "metadata": {
        "id": "yC1RB_-PzHTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "3HhOg64STxbK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la sección 2.1, en esta sección usted se encargará de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
        "\n",
        "Comencemos preparando el ambiente:\n"
      ],
      "metadata": {
        "id": "SEqCTqqroh03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el parámetro continuous = True"
      ],
      "metadata": {
        "id": "nvQUyuZ_FtZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709f03d2-1b04-49c7-ff71-1cf33e5d2837"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noten que se especifica el parámetro `continuous = True`. ¿Que implicancias tiene esto sobre el ambiente?\n",
        "\n",
        "Además, se le facilita la función `export_gif` para el ejercicio 2.2.4:"
      ],
      "metadata": {
        "id": "FBU4lGX3wpN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto implica que el espacio de decisión es continuo, expandiendo las posibles opciones que el modelo puede considerar."
      ],
      "metadata": {
        "id": "dAwxMReO9qjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  función que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ],
      "metadata": {
        "id": "bRiWpSo9yfr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6ff58d-1547-4cb3-a8cd-b409bd5abc5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.1 Descripción de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripción sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. ¿Como se distinguen las acciones de este ambiente en comparación a `Blackjack`?\n",
        "\n",
        "Nota: recuerde que se especificó el parámetro `continuous = True`"
      ],
      "metadata": {
        "id": "sk5VJVppXh3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El ambiente LunarLander describe los estados, acciones y recompensas involucradas en la simulación del aterrizaje de una nave espacial virtual. Las coordenadas del punto objetivo están en (0,0) donde la grilla en la que se puede mover la nave va desde -2.5 a 2.5 tanto en el eje X como Y. Existen otras variables que describen el movimiento de la nave como su velocidad tanto vertical como horizontal y su ángulo de orientación. Contiene también indicadores por cada tren de aterrizaje para saber si están en contacto con el suelo o no.\n",
        "Los posibles estados son continuos dados por la posición y los otros parámetros descritos anteriormente, que están contenidos en un Box multidimensional condichas características del movimiento de la nave.\n",
        "El posible espacio de acción es discreto y puede tomar 4 valores, no hacer nada (0), activar el motor izquierdo (1), activar el motor principal (2) o activar el derecho (3).\n",
        "Se otorgan recompensas en cada paso para guiar el aterrizaje de la nave. La recompensa aumenta a medida que la nave se acerca al punto de aterrizaje y se mueve más lento, y disminuye si la nave está inclinada. Cada tren de aterrizaje que toca el suelo otorga 10 puntos adicionales. Se aplican penalizaciones pequeñas en cada frame cuando los motores laterales están en uso (-0.03 puntos) y una penalización mayor cuando el motor principal se enciende (-0.3 puntos). Al finalizar el episodio, una recompensa adicional de -100 puntos se asigna si la nave choca, y +100 puntos si aterriza exitosamente. Se considera que un episodio está resuelto si la nave obtiene al menos 200 puntos en total."
      ],
      "metadata": {
        "id": "Yb-u9LUE8O9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las acciones se distinguen de Black Jack principalmente en que hay más acciones que realizar y estas acciones también interactúan más directamente con la recompensa alcanzada, mas allá de qué número aleatorio se asigna o no."
      ],
      "metadata": {
        "id": "Tzdnm69aCB2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 10 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política?"
      ],
      "metadata": {
        "id": "YChodtNQwzG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R = []\n",
        "for episode in range(10):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        done = terminated or truncated\n",
        "    R.append(total_reward)\n",
        "env.close()\n",
        "\n",
        "print(\"Promedio de recompensas:\", np.mean(R))\n",
        "print(\"Desviación de recompensas:\", np.std(R))"
      ],
      "metadata": {
        "id": "5bwc3A0GX7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e97a50c-ce9e-4a0d-ed93-76cf6ac63b1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio de recompensas: -223.18599431399176\n",
            "Desviación de recompensas: 160.78440737748258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El performance de esta política es muy pobre, de hecho el promedio de las recompensas es exactamente lo contrario a la recompensa necesaria para decir que una iteración se da por terminada, que es 200 puntos. Una política de generación de acciones aleatorias no es adecuada."
      ],
      "metadata": {
        "id": "Eeo4feI9Pr9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ],
      "metadata": {
        "id": "hQrZVQflX_5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True)"
      ],
      "metadata": {
        "id": "y_6Ia9uoF7Hs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo A2C soporta el formato Box de"
      ],
      "metadata": {
        "id": "SyslBcd-VLJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "model.learn(total_timesteps=10000, progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "f17d97783064448fac8dd4f7d81875cf",
            "20216105e8864df6bcc007401b99e6a5"
          ]
        },
        "id": "tt6pjPYoSoH-",
        "outputId": "7f56d6f2-a352-41f4-dd68-c503865f965b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f17d97783064448fac8dd4f7d81875cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7de693323010>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"lunar_lander\")"
      ],
      "metadata": {
        "id": "xGyY4CJKTVhj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
      ],
      "metadata": {
        "id": "3z-oIUSrlAsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = PPO.load(\"lunar_lander\")\n",
        "model.set_env(env)"
      ],
      "metadata": {
        "id": "ophyU3KrWrwl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "# Evaluate the agent\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "mean_reward, std_reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHDXMwkzT7ZG",
        "outputId": "18ff1043-d079-4d8a-e84c-7c9881f5e837"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-115.4697376, 79.61610107472136)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "RJYzp-PXV4rE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2.5 Optimización de modelo (0.2 puntos)**\n",
        "\n",
        "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parámetros como:\n",
        "- `total_timesteps`\n",
        "- `learning_rate`\n",
        "- `batch_size`\n",
        "\n",
        "Una vez optimizado el modelo, use la función `export_gif` para estudiar el comportamiento de su agente en la resolución del ambiente y comente sobre sus resultados.\n",
        "\n",
        "Adjunte el gif generado en su entrega (mejor aún si además adjuntan el gif en el markdown)."
      ],
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración del ambiente\n",
        "env = gym.make(\"LunarLander-v3\", render_mode=\"human\", continuous=True)\n",
        "\n",
        "learning_rate = 0.03   # Ajusta según sea necesario\n",
        "n_steps = 2048           # Número de pasos antes de actualizar\n",
        "batch_size = 64          # Tamaño del lote para la actualización de gradiente\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=learning_rate, n_steps=n_steps, batch_size=batch_size)\n",
        "model.learn(total_timesteps=100000, progress_bar=True)  # Aumenta el número de timesteps\n",
        "model.save(\"lunar_lander\")\n",
        "del model\n",
        "\n",
        "# Cargar el modelo y reestablecer el ambiente\n",
        "model = PPO.load(\"lunar_lander\")\n",
        "model.set_env(env)\n",
        "\n",
        "# Evaluación del agente\n",
        "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=20)\n",
        "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")\n",
        "\n",
        "# Cerrar el ambiente\n",
        "env.close()"
      ],
      "metadata": {
        "id": "aItYF6sr6F_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df8a77a55dd74b50befd6d534246ba6e",
            "78344ce0eb5c469f86ceb45731e3bd25"
          ]
        },
        "outputId": "924e98e1-7e9d-49bf-d2a3-cccc766c4e38"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df8a77a55dd74b50befd6d534246ba6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 120      |\n",
            "|    ep_rew_mean     | -288     |\n",
            "| time/              |          |\n",
            "|    fps             | 47       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 43       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 83.1      |\n",
            "|    ep_rew_mean          | -446      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 88        |\n",
            "|    total_timesteps      | 4096      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 84.046196 |\n",
            "|    clip_fraction        | 0.945     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.17     |\n",
            "|    explained_variance   | 8.08e-05  |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 793       |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | 0.304     |\n",
            "|    std                  | 1.16      |\n",
            "|    value_loss           | 1.33e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 87.3      |\n",
            "|    ep_rew_mean          | -668      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 132       |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 404.18665 |\n",
            "|    clip_fraction        | 0.814     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.98     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 597       |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | 0.244     |\n",
            "|    std                  | 1.05      |\n",
            "|    value_loss           | 2.77e+03  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 89.9        |\n",
            "|    ep_rew_mean          | -803        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 177         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018468544 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.19        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.58e+03    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | 0.0143      |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.95e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 87.7        |\n",
            "|    ep_rew_mean          | -951        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 222         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.041742958 |\n",
            "|    clip_fraction        | 0.168       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0.423       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.81e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | 0.00595     |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.35e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.2        |\n",
            "|    ep_rew_mean          | -1.09e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 266         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006440241 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0.55        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.05e+03    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | 0.0121      |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.8e+03     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.4        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 310         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014650758 |\n",
            "|    clip_fraction        | 0.201       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.692       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.21e+03    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | 0.01        |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.83e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 88.7       |\n",
            "|    ep_rew_mean          | -1.1e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 355        |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02788722 |\n",
            "|    clip_fraction        | 0.206      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.89      |\n",
            "|    explained_variance   | 0.765      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 3.13e+03   |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | 0.00857    |\n",
            "|    std                  | 1.03       |\n",
            "|    value_loss           | 4.72e+03   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 87.6         |\n",
            "|    ep_rew_mean          | -1.08e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 46           |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 400          |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0141734425 |\n",
            "|    clip_fraction        | 0.213        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.796        |\n",
            "|    learning_rate        | 0.03         |\n",
            "|    loss                 | 1.78e+03     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | 0.0092       |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 4.13e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88          |\n",
            "|    ep_rew_mean          | -1.08e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 444         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012467621 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.851       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.85e+03    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | 0.00638     |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.08e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 89.1        |\n",
            "|    ep_rew_mean          | -1.1e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 488         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025172392 |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0.861       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 2.03e+03    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | 0.0102      |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 3.92e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 89.9        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 532         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.053243008 |\n",
            "|    clip_fraction        | 0.244       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.9         |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.36e+03    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | 0.0147      |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 2.88e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.5        |\n",
            "|    ep_rew_mean          | -1.13e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 577         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008744486 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 0.92        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 1.4e+03     |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | 0.00745     |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 2.44e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 90.4         |\n",
            "|    ep_rew_mean          | -1.13e+03    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 46           |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 621          |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075560976 |\n",
            "|    clip_fraction        | 0.19         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.937        |\n",
            "|    learning_rate        | 0.03         |\n",
            "|    loss                 | 937          |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 0.00947      |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 1.84e+03     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 88.7      |\n",
            "|    ep_rew_mean          | -1.12e+03 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 666       |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0156997 |\n",
            "|    clip_fraction        | 0.164     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.95     |\n",
            "|    explained_variance   | 0.948     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 922       |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | 0.00543   |\n",
            "|    std                  | 1.06      |\n",
            "|    value_loss           | 1.73e+03  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88.5        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 710         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006814571 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.95       |\n",
            "|    explained_variance   | 0.948       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 992         |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | 0.00637     |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 1.84e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.1        |\n",
            "|    ep_rew_mean          | -1.14e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 754         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017676163 |\n",
            "|    clip_fraction        | 0.329       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 0.956       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 637         |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | 0.0286      |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 1.42e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 90.7        |\n",
            "|    ep_rew_mean          | -1.15e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 799         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031070411 |\n",
            "|    clip_fraction        | 0.299       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.98       |\n",
            "|    explained_variance   | 0.953       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 576         |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | 0.0179      |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 1.81e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88.8        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 843         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012520591 |\n",
            "|    clip_fraction        | 0.279       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.97       |\n",
            "|    explained_variance   | 0.947       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 999         |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | 0.0203      |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 1.61e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 89.7       |\n",
            "|    ep_rew_mean          | -1.11e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 887        |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06749683 |\n",
            "|    clip_fraction        | 0.333      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.99      |\n",
            "|    explained_variance   | 0.952      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 665        |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | 0.0238     |\n",
            "|    std                  | 1.09       |\n",
            "|    value_loss           | 1.79e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 90.3       |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 932        |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.18329155 |\n",
            "|    clip_fraction        | 0.416      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3         |\n",
            "|    explained_variance   | 0.943      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 1.02e+03   |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | 0.0434     |\n",
            "|    std                  | 1.08       |\n",
            "|    value_loss           | 1.87e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 90.5       |\n",
            "|    ep_rew_mean          | -1.14e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 976        |\n",
            "|    total_timesteps      | 45056      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16025296 |\n",
            "|    clip_fraction        | 0.387      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.01      |\n",
            "|    explained_variance   | 0.96       |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 872        |\n",
            "|    n_updates            | 210        |\n",
            "|    policy_gradient_loss | 0.0371     |\n",
            "|    std                  | 1.13       |\n",
            "|    value_loss           | 1.99e+03   |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 88.5     |\n",
            "|    ep_rew_mean          | -1.1e+03 |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 23       |\n",
            "|    time_elapsed         | 1020     |\n",
            "|    total_timesteps      | 47104    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 18.56445 |\n",
            "|    clip_fraction        | 0.84     |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -3.12    |\n",
            "|    explained_variance   | 0.957    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 821      |\n",
            "|    n_updates            | 220      |\n",
            "|    policy_gradient_loss | 0.246    |\n",
            "|    std                  | 1.16     |\n",
            "|    value_loss           | 1.42e+03 |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 88.4        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 1064        |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012657851 |\n",
            "|    clip_fraction        | 0.32        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.957       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 436         |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | 0.0231      |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 1.58e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 87.4        |\n",
            "|    ep_rew_mean          | -1.11e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 1109        |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.052262332 |\n",
            "|    clip_fraction        | 0.571       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.3        |\n",
            "|    explained_variance   | 0.982       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 315         |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | 0.0891      |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 1.04e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 85.7       |\n",
            "|    ep_rew_mean          | -1.08e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 1153       |\n",
            "|    total_timesteps      | 53248      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02710073 |\n",
            "|    clip_fraction        | 0.393      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.31      |\n",
            "|    explained_variance   | 0.965      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 710        |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | 0.0428     |\n",
            "|    std                  | 1.26       |\n",
            "|    value_loss           | 1.72e+03   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 86.7        |\n",
            "|    ep_rew_mean          | -1.1e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 1198        |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020032255 |\n",
            "|    clip_fraction        | 0.435       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.36       |\n",
            "|    explained_variance   | 0.96        |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 723         |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | 0.0368      |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 1.66e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 86.8       |\n",
            "|    ep_rew_mean          | -1.1e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 1242       |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.36360073 |\n",
            "|    clip_fraction        | 0.545      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.32      |\n",
            "|    explained_variance   | 0.966      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 493        |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | 0.0948     |\n",
            "|    std                  | 1.26       |\n",
            "|    value_loss           | 1.44e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 88         |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 1287       |\n",
            "|    total_timesteps      | 59392      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.29276985 |\n",
            "|    clip_fraction        | 0.492      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.37      |\n",
            "|    explained_variance   | 0.963      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 1.42e+03   |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | 0.0611     |\n",
            "|    std                  | 1.45       |\n",
            "|    value_loss           | 1.75e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 89.5       |\n",
            "|    ep_rew_mean          | -1.14e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 1331       |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.48085427 |\n",
            "|    clip_fraction        | 0.482      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.65      |\n",
            "|    explained_variance   | 0.961      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 356        |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | 0.0632     |\n",
            "|    std                  | 1.63       |\n",
            "|    value_loss           | 1.04e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 88.8       |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 1375       |\n",
            "|    total_timesteps      | 63488      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03108428 |\n",
            "|    clip_fraction        | 0.524      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.82      |\n",
            "|    explained_variance   | 0.975      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 801        |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | 0.0751     |\n",
            "|    std                  | 1.61       |\n",
            "|    value_loss           | 1.08e+03   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 87.5      |\n",
            "|    ep_rew_mean          | -1.12e+03 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 1420      |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.2449437 |\n",
            "|    clip_fraction        | 0.451     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.79     |\n",
            "|    explained_variance   | 0.971     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 488       |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | 0.0688    |\n",
            "|    std                  | 1.48      |\n",
            "|    value_loss           | 1.21e+03  |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 87.7       |\n",
            "|    ep_rew_mean          | -1.13e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 33         |\n",
            "|    time_elapsed         | 1464       |\n",
            "|    total_timesteps      | 67584      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08201048 |\n",
            "|    clip_fraction        | 0.5        |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.72      |\n",
            "|    explained_variance   | 0.97       |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 454        |\n",
            "|    n_updates            | 320        |\n",
            "|    policy_gradient_loss | 0.0724     |\n",
            "|    std                  | 1.55       |\n",
            "|    value_loss           | 1.15e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 87.8       |\n",
            "|    ep_rew_mean          | -1.13e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 34         |\n",
            "|    time_elapsed         | 1509       |\n",
            "|    total_timesteps      | 69632      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06625369 |\n",
            "|    clip_fraction        | 0.425      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.76      |\n",
            "|    explained_variance   | 0.974      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 446        |\n",
            "|    n_updates            | 330        |\n",
            "|    policy_gradient_loss | 0.0465     |\n",
            "|    std                  | 1.6        |\n",
            "|    value_loss           | 1.15e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 87         |\n",
            "|    ep_rew_mean          | -1.12e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 1554       |\n",
            "|    total_timesteps      | 71680      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.32693458 |\n",
            "|    clip_fraction        | 0.503      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.92      |\n",
            "|    explained_variance   | 0.971      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 1.02e+03   |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | 0.0806     |\n",
            "|    std                  | 2.14       |\n",
            "|    value_loss           | 1.38e+03   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 89         |\n",
            "|    ep_rew_mean          | -1.15e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 36         |\n",
            "|    time_elapsed         | 1598       |\n",
            "|    total_timesteps      | 73728      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11241681 |\n",
            "|    clip_fraction        | 0.282      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.33      |\n",
            "|    explained_variance   | 0.962      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 788        |\n",
            "|    n_updates            | 350        |\n",
            "|    policy_gradient_loss | 0.0222     |\n",
            "|    std                  | 2.17       |\n",
            "|    value_loss           | 1.47e+03   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 86.8        |\n",
            "|    ep_rew_mean          | -1.12e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 46          |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 1642        |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028586946 |\n",
            "|    clip_fraction        | 0.389       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.4        |\n",
            "|    explained_variance   | 0.971       |\n",
            "|    learning_rate        | 0.03        |\n",
            "|    loss                 | 648         |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 0.0406      |\n",
            "|    std                  | 2.16        |\n",
            "|    value_loss           | 1.1e+03     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 86.6       |\n",
            "|    ep_rew_mean          | -1.11e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 46         |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 1687       |\n",
            "|    total_timesteps      | 77824      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03465491 |\n",
            "|    clip_fraction        | 0.419      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.41      |\n",
            "|    explained_variance   | 0.971      |\n",
            "|    learning_rate        | 0.03       |\n",
            "|    loss                 | 691        |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | 0.042      |\n",
            "|    std                  | 2.12       |\n",
            "|    value_loss           | 1.3e+03    |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 80        |\n",
            "|    ep_rew_mean          | -941      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 39        |\n",
            "|    time_elapsed         | 1732      |\n",
            "|    total_timesteps      | 79872     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1696.9004 |\n",
            "|    clip_fraction        | 0.856     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.34     |\n",
            "|    explained_variance   | 0.941     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 585       |\n",
            "|    n_updates            | 380       |\n",
            "|    policy_gradient_loss | 0.222     |\n",
            "|    std                  | 1.01      |\n",
            "|    value_loss           | 1.34e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 73.1      |\n",
            "|    ep_rew_mean          | -771      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 1777      |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 530.52527 |\n",
            "|    clip_fraction        | 0.957     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.85     |\n",
            "|    explained_variance   | 0.857     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 793       |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | 0.3       |\n",
            "|    std                  | 1.02      |\n",
            "|    value_loss           | 1.62e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 65.1      |\n",
            "|    ep_rew_mean          | -582      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 41        |\n",
            "|    time_elapsed         | 1821      |\n",
            "|    total_timesteps      | 83968     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 213.64673 |\n",
            "|    clip_fraction        | 0.963     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.16     |\n",
            "|    explained_variance   | 0.9       |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 585       |\n",
            "|    n_updates            | 400       |\n",
            "|    policy_gradient_loss | 0.291     |\n",
            "|    std                  | 1.21      |\n",
            "|    value_loss           | 1.11e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 64.1      |\n",
            "|    ep_rew_mean          | -559      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 42        |\n",
            "|    time_elapsed         | 1866      |\n",
            "|    total_timesteps      | 86016     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 16144.814 |\n",
            "|    clip_fraction        | 0.95      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.5      |\n",
            "|    explained_variance   | 0.925     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 241       |\n",
            "|    n_updates            | 410       |\n",
            "|    policy_gradient_loss | 0.302     |\n",
            "|    std                  | 0.465     |\n",
            "|    value_loss           | 741       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 65.4     |\n",
            "|    ep_rew_mean          | -574     |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 43       |\n",
            "|    time_elapsed         | 1911     |\n",
            "|    total_timesteps      | 88064    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 93.41362 |\n",
            "|    clip_fraction        | 0.995    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.37    |\n",
            "|    explained_variance   | 0.943    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 294      |\n",
            "|    n_updates            | 420      |\n",
            "|    policy_gradient_loss | 0.299    |\n",
            "|    std                  | 0.487    |\n",
            "|    value_loss           | 694      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 66.9      |\n",
            "|    ep_rew_mean          | -575      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 44        |\n",
            "|    time_elapsed         | 1956      |\n",
            "|    total_timesteps      | 90112     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 109.50314 |\n",
            "|    clip_fraction        | 0.981     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.45     |\n",
            "|    explained_variance   | 0.931     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 335       |\n",
            "|    n_updates            | 430       |\n",
            "|    policy_gradient_loss | 0.279     |\n",
            "|    std                  | 0.512     |\n",
            "|    value_loss           | 1.01e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 69.1      |\n",
            "|    ep_rew_mean          | -589      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 45        |\n",
            "|    time_elapsed         | 2001      |\n",
            "|    total_timesteps      | 92160     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 59.785126 |\n",
            "|    clip_fraction        | 0.988     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.47     |\n",
            "|    explained_variance   | 0.912     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 579       |\n",
            "|    n_updates            | 440       |\n",
            "|    policy_gradient_loss | 0.268     |\n",
            "|    std                  | 0.518     |\n",
            "|    value_loss           | 1.26e+03  |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 69.5     |\n",
            "|    ep_rew_mean          | -593     |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 46       |\n",
            "|    time_elapsed         | 2045     |\n",
            "|    total_timesteps      | 94208    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 80.72317 |\n",
            "|    clip_fraction        | 0.982    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.73    |\n",
            "|    explained_variance   | 0.908    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 633      |\n",
            "|    n_updates            | 450      |\n",
            "|    policy_gradient_loss | 0.26     |\n",
            "|    std                  | 0.607    |\n",
            "|    value_loss           | 1.17e+03 |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 69        |\n",
            "|    ep_rew_mean          | -593      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 47        |\n",
            "|    time_elapsed         | 2090      |\n",
            "|    total_timesteps      | 96256     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 40.688507 |\n",
            "|    clip_fraction        | 0.995     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.74     |\n",
            "|    explained_variance   | 0.952     |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 290       |\n",
            "|    n_updates            | 460       |\n",
            "|    policy_gradient_loss | 0.291     |\n",
            "|    std                  | 0.596     |\n",
            "|    value_loss           | 735       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| rollout/                |          |\n",
            "|    ep_len_mean          | 67.5     |\n",
            "|    ep_rew_mean          | -584     |\n",
            "| time/                   |          |\n",
            "|    fps                  | 46       |\n",
            "|    iterations           | 48       |\n",
            "|    time_elapsed         | 2135     |\n",
            "|    total_timesteps      | 98304    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 506.1672 |\n",
            "|    clip_fraction        | 0.958    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.75    |\n",
            "|    explained_variance   | 0.942    |\n",
            "|    learning_rate        | 0.03     |\n",
            "|    loss                 | 250      |\n",
            "|    n_updates            | 470      |\n",
            "|    policy_gradient_loss | 0.262    |\n",
            "|    std                  | 0.578    |\n",
            "|    value_loss           | 964      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 67.8      |\n",
            "|    ep_rew_mean          | -583      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 46        |\n",
            "|    iterations           | 49        |\n",
            "|    time_elapsed         | 2180      |\n",
            "|    total_timesteps      | 100352    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 549.52594 |\n",
            "|    clip_fraction        | 0.979     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.71     |\n",
            "|    explained_variance   | 0.93      |\n",
            "|    learning_rate        | 0.03      |\n",
            "|    loss                 | 285       |\n",
            "|    n_updates            | 480       |\n",
            "|    policy_gradient_loss | 0.261     |\n",
            "|    std                  | 0.572     |\n",
            "|    value_loss           | 542       |\n",
            "---------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Mean reward: -611.78407625, Std reward: 183.49704239646204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Large Language Models (4.0 puntos)**\n",
        "\n",
        "En esta sección se enfocarán en habilitar un Chatbot que nos permita responder preguntas útiles a través de LLMs."
      ],
      "metadata": {
        "id": "mPUY-Ktgf2BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.0 Configuración Inicial**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Como siempre, cargamos todas nuestras API KEY al entorno:"
      ],
      "metadata": {
        "id": "mQ4fPRRihGLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ],
      "metadata": {
        "id": "Ud2Xm_k-hFJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef5ae4f-c972-4b10-b5a7-f4d629867b26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n",
            "Enter your Tavily API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsección es que habiliten un chatbot que pueda responder preguntas usando información contenida en documentos PDF a través de **Retrieval Augmented Generation.**"
      ],
      "metadata": {
        "id": "Rj9JvQUsgZZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
        "\n",
        "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
        "  - 2 documentos .pdf como mínimo.\n",
        "  - 50 páginas de contenido como mínimo entre todos los documentos.\n",
        "  - Ideas para documentos: Documentos relacionados a temas académicos, laborales o de ocio. Aprovechen este ejercicio para construir algo útil y/o relevante para ustedes!\n",
        "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
        "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
        "  - **Recuerden adjuntar los documentos en su entrega**."
      ],
      "metadata": {
        "id": "ZrxOQroVnaZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet PyPDF2"
      ],
      "metadata": {
        "id": "5D1tIRCi4oJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58420841-4f22-4837-afd4-d5b6741bfc6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "doc_paths = [\"/content/Dialnet-FundacionDeColoColoEnChile1925-9639350.pdf\",\"/content/El-rol-socio-cultural-del-futbol-en-el-Chile-de-la-segunda-mitad-del-siglo-XX.pdf\",\"/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf\"] # rellenar con los path a sus documentos\n",
        "\n",
        "assert len(doc_paths) >= 2, \"Deben adjuntar un mínimo de 2 documentos\"\n",
        "\n",
        "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
        "assert total_paginas >= 50, f\"Páginas insuficientes: {total_paginas}\""
      ],
      "metadata": {
        "id": "kzq2TjWCnu15"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
        "\n",
        "Vectorice los documentos y almacene sus representaciones de manera acorde."
      ],
      "metadata": {
        "id": "r811-P71nizA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D-B6sK2IihNU",
        "outputId": "278b7eab-30c1-48a4-a652-7b9488feec96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DLuqklaTi6Ig",
        "outputId": "7341ab6e-8cff-416d-90cc-14603068c002"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/298.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "ylmwLBFagUEX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar documentos\n",
        "docs = []\n",
        "for doc_path in doc_paths:\n",
        "    loader = PyPDFLoader(doc_path)\n",
        "    docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "o775M4d9gU16"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "xxHObXVDgcQb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWWeSByTjFoU",
        "outputId": "7c6fc142-05d4-4c72-b3b9-808b32fe3b26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.19)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-2.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGLDATSNjgX_",
        "outputId": "ddbf11d4-e38a-4129-b0b2-2904ebbf0ae5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n"
      ],
      "metadata": {
        "id": "1ArNa2Pkhiel"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRGqU5KJhv26",
        "outputId": "c456c940-055d-4b3b-8098-80ad1c04a696"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x7ace9dae7040>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
        "\n",
        "Habilite la solución RAG a través de una *chain* y guárdela en una variable."
      ],
      "metadata": {
        "id": "hAUkP5zrnyBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", # método de búsqueda\n",
        "                                     search_kwargs={\"k\": 3}, # n° documentos a recuperar\n",
        "                                     )\n",
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzm26_xyj4aH",
        "outputId": "fb51ece0-b627-4a90-f0b7-d8f7b94a2c70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ace9dae7040>, search_kwargs={'k': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"cuando se fundo el club deportivo Colo-Colo?\" # pregunta\n",
        "relevant_documents = retriever.invoke(question) # top k documentos relevantes a la pregunta\n",
        "relevant_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyBTjrJNj-rY",
        "outputId": "798fccea-2ab6-4789-9f9a-addaebc2cb11"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf', 'page': 0}, page_content='institución,4  finalmente optaron por formar un nuevo club con sólidos principios deportivos y morales,\\npretensión que fue estipulada en el acta de fundación de Colo-Colo.5  Tras una serie de reuniones, que\\ncomenzaron la noche del 12 de abril en la calle Covadonga del barrio Estación Central, la fundación de\\nColo-Colo quedó sellada el 19 de abril de 1925 en el Estadio El Llano.6\\nEn la primera reunión del club, presidida de forma interina por Juan Quiñones, fueron propuestos varios'),\n",
              " Document(metadata={'source': '/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf', 'page': 1}, page_content='obligatorios, preparación de jugadas y aplicación de tácticas,\\nasí como la disponibilidad de implementos y médicos.10 \\nLuego de la fundación el equipo se inscribió en la Primera División de la Liga Metropolitana. El primer\\npartido que jugó Colo-Colo en su historia y en esa división fue ante el English, el 31 de mayo de 1925, y\\nque terminó con una victoria para Colo-Colo de 6:0. En la misma temporada ganaron su primer \"clásico\"'),\n",
              " Document(metadata={'source': '/content/Historia_del_Club_Social_y_Deportivo_Colo-Colo.pdf', 'page': 6}, page_content='futbolístico como en lo financiero. El 23 de enero de 2002 la justicia decretó la quiebra del club,\\ndejándolo a cargo del síndico Juan Carlos Saffie, cuya gestión permitió la continuidad de giro del club,\\nnecesaria para que Colo-Colo no perdiera su personalidad jurídica y sus bienes no fueran a remate.\\nEn una de las etapas más difíciles para el club y después de cuatro años, Colo-Colo se consagró campeón')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
      ],
      "metadata": {
        "id": "-oQUEkxHkpNb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_chain = retriever | format_docs # chain\n",
        "print(retriever_chain.invoke(\"cuando se fundo el club deportivo Colo-Colo?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGvDmtbhkpF4",
        "outputId": "e0b8799b-9842-4ca1-92c7-4ca8ab2fcfd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "institución,4  finalmente optaron por formar un nuevo club con sólidos principios deportivos y morales,\n",
            "pretensión que fue estipulada en el acta de fundación de Colo-Colo.5  Tras una serie de reuniones, que\n",
            "comenzaron la noche del 12 de abril en la calle Covadonga del barrio Estación Central, la fundación de\n",
            "Colo-Colo quedó sellada el 19 de abril de 1925 en el Estadio El Llano.6\n",
            "En la primera reunión del club, presidida de forma interina por Juan Quiñones, fueron propuestos varios\n",
            "\n",
            "obligatorios, preparación de jugadas y aplicación de tácticas,\n",
            "así como la disponibilidad de implementos y médicos.10 \n",
            "Luego de la fundación el equipo se inscribió en la Primera División de la Liga Metropolitana. El primer\n",
            "partido que jugó Colo-Colo en su historia y en esa división fue ante el English, el 31 de mayo de 1925, y\n",
            "que terminó con una victoria para Colo-Colo de 6:0. En la misma temporada ganaron su primer \"clásico\"\n",
            "\n",
            "futbolístico como en lo financiero. El 23 de enero de 2002 la justicia decretó la quiebra del club,\n",
            "dejándolo a cargo del síndico Juan Carlos Saffie, cuya gestión permitió la continuidad de giro del club,\n",
            "necesaria para que Colo-Colo no perdiera su personalidad jurídica y sus bienes no fueran a remate.\n",
            "En una de las etapas más difíciles para el club y después de cuatro años, Colo-Colo se consagró campeón\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\", # modelo de lenguaje\n",
        "    temperature=0, # probabilidad de \"respuestas creativas\"\n",
        "    max_tokens=None, # sin tope de tokens\n",
        "    timeout=None, # sin timeout\n",
        "    max_retries=2, # número máximo de intentos\n",
        ")\n",
        "\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keGeZcJ1nF81",
        "outputId": "61dc7396-619e-415e-8da2-e0f0cfaa8836"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7ace9dae6d70>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "rag_template = '''\n",
        "Eres un historiador que conoce mucho sobre el club deportivo Colo Colo.\n",
        "Tu único rol es contestar preguntas del usuario a partir de información relevante que te sea proporcionada.\n",
        "Responde siempre de la forma más completa posible y usando toda la información entregada.\n",
        "Responde sólo lo que te pregunten a partir de la información relevante, NUNCA inventes una respuesta.\n",
        "\n",
        "Información relevante: {context}\n",
        "Pregunta: {question}\n",
        "Respuesta útil:\n",
        "'''\n",
        "\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)"
      ],
      "metadata": {
        "id": "FZCuUquIlWZn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "vQXH6lq1naiL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever_chain,\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | rag_prompt # prompt con las variables question y context\n",
        "    | llm # llm recibe el prompt y responde\n",
        "    | StrOutputParser() # recuperamos sólo la respuesta\n",
        ")"
      ],
      "metadata": {
        "id": "jNUEdlSJmRkQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.4 Verificación de respuestas (0.5 puntos)**\n",
        "\n",
        "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su solución para cada una. ¿Su solución RAG entrega las respuestas que esperaba?\n",
        "\n",
        "Ejemplo de tupla:\n",
        "- Pregunta: ¿Quién es el presidente de Chile?\n",
        "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
      ],
      "metadata": {
        "id": "ycg5S5i_n-kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    (\"¿Cuándo se fundó Colo Colo?\"),   # Colo Colo se fundó el 19 de abril de 1925.\n",
        "     (\"¿Quién fue el primer presidente de Colo Colo?\"),   # El primer presidente fue David Arellano.\n",
        "     (\"¿Cuál es el estadio de Colo Colo?\")   # El estadio de Colo Colo es el Estadio Monumental.\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "\n",
        "  response = rag_chain.invoke(question)\n",
        "  result_tuple = (question, response)\n",
        "  print(result_tuple)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsKryS3NuCpR",
        "outputId": "8b0b3cf9-e727-4c6f-8048-bcc50a6dafa5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('¿Cuándo se fundó Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('¿Quién fue el primer presidente de Colo Colo?', 'La información proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('¿Cuál es el estadio de Colo Colo?', 'De acuerdo a la información proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  También se menciona el estadio \"Calvo y Bascuñán\", pero en el contexto de daños causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que la solución RAG entrega las repsuestas correctas para 2 de las 3 preguntas, sólamente fallando en una pregunta debido a que, al parecer, la respuesta no se puede encontrar dentro de los documentos entregados al inicio."
      ],
      "metadata": {
        "id": "yITk-vLWxvQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1.5 Sensibilidad de Hiperparámetros (0.5 puntos)**\n",
        "\n",
        "Extienda el análisis del punto 2.1.4 analizando cómo cambian las respuestas entregadas cambiando los siguientes hiperparámetros:\n",
        "- `Tamaño del chunk`. (*¿Cómo repercute que los chunks sean mas grandes o chicos?*)\n",
        "- `La cantidad de chunks recuperados`. (*¿Qué pasa si se devuelven muchos/pocos chunks?*)\n",
        "- `El tipo de búsqueda`. (*¿Cómo afecta el tipo de búsqueda a las respuestas de mi RAG?*)"
      ],
      "metadata": {
        "id": "X8d5zTMHoUgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_sizes = [200, 1000]\n",
        "for chunk_size in chunk_sizes:\n",
        "    print(f\"\\nProbando con chunk size: {chunk_size}\")\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
        "    splits = text_splitter.split_documents(docs)\n",
        "\n",
        "    vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)\n",
        "\n",
        "    for question in questions:\n",
        "      response = rag_chain.invoke(question)\n",
        "      result_tuple = (question, response)\n",
        "      print(result_tuple)\n",
        "\n"
      ],
      "metadata": {
        "id": "UDh_QgeXLGHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dae0da-ab7a-44cf-88e7-2475976b3caf"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando con chunk size: 200\n",
            "('¿Cuándo se fundó Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('¿Quién fue el primer presidente de Colo Colo?', 'La información proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('¿Cuál es el estadio de Colo Colo?', 'De acuerdo a la información proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  También se menciona el estadio \"Calvo y Bascuñán\", pero en el contexto de daños causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('Cuál es el precio del Bitcoin en pesos Chilenos?', 'La información proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('Qué equipo ganó la copa Libertadores en 1991?', 'Colo-Colo ganó la Copa Libertadores en 1991.\\n')\n",
            "\n",
            "Probando con chunk size: 1000\n",
            "('¿Cuándo se fundó Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('¿Quién fue el primer presidente de Colo Colo?', 'La información proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('¿Cuál es el estadio de Colo Colo?', 'De acuerdo a la información proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  También se menciona el estadio \"Calvo y Bascuñán\", pero en el contexto de daños causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('Cuál es el precio del Bitcoin en pesos Chilenos?', 'La información proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('Qué equipo ganó la copa Libertadores en 1991?', 'Colo-Colo ganó la Copa Libertadores en 1991.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de las preguntas, no se observan diferencias en las respuestas generadas variando el tamaño de los chunks."
      ],
      "metadata": {
        "id": "6B5S-G3SahzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_chunks = [2, 10]  # Cantidades de chunks\n",
        "for k in retrieved_chunks:\n",
        "    print(f\"\\nProbando con {k} chunks recuperados\")\n",
        "\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", # método de búsqueda\n",
        "                                     search_kwargs={\"k\": retrieved_chunks}, # n° documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "    for question in questions:\n",
        "\n",
        "      response = rag_chain.invoke(question)\n",
        "      result_tuple = (question, response)\n",
        "      print(result_tuple)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfTK94ZZ-qzY",
        "outputId": "e67025f9-2be3-4974-ad85-e7992ddb2735"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando con 2 chunks recuperados\n",
            "('¿Cuándo se fundó Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('¿Quién fue el primer presidente de Colo Colo?', 'La información proporcionada no indica quién fue el primer presidente de Colo Colo.\\n')\n",
            "('¿Cuál es el estadio de Colo Colo?', 'De acuerdo a la información proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  También se menciona el estadio \"Calvo y Bascuñán\", pero en el contexto de daños causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('Cuál es el precio del Bitcoin en pesos Chilenos?', 'La información proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('Qué equipo ganó la copa Libertadores en 1991?', 'Colo-Colo ganó la Copa Libertadores en 1991.\\n')\n",
            "\n",
            "Probando con 10 chunks recuperados\n",
            "('¿Cuándo se fundó Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('¿Quién fue el primer presidente de Colo Colo?', 'La información proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('¿Cuál es el estadio de Colo Colo?', 'De acuerdo a la información proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989, con un partido entre Colo-Colo y Peñarol.  También se menciona el estadio \"Calvo y Bascuñán\", donde ocurrieron incidentes con barristas de Colo Colo tras una derrota contra Antofagasta.  Sin embargo, la información no indica que \"Calvo y Bascuñán\" sea el estadio de Colo Colo.\\n')\n",
            "('Cuál es el precio del Bitcoin en pesos Chilenos?', 'La información proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('Qué equipo ganó la copa Libertadores en 1991?', 'Colo-Colo ganó la Copa Libertadores en 1991.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de las preguntas, no se observan diferencias en las respuestas generadas variando el número de chunks seleccionados."
      ],
      "metadata": {
        "id": "kt00yIbjbArC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_types = [\"similarity\", \"mmr\"]  # Ejemplo de tipos de búsqueda\n",
        "for search_type in search_types:\n",
        "    print(f\"\\nProbando con tipo de búsqueda: {search_type}\")\n",
        "\n",
        "    retriever = vectorstore.as_retriever(search_type=search_type, # método de búsqueda\n",
        "                                     search_kwargs={\"k\": 3}, # n° documentos a recuperar\n",
        "                                     )\n",
        "\n",
        "    for question in questions:\n",
        "\n",
        "      response = rag_chain.invoke(question)\n",
        "      result_tuple = (question, response)\n",
        "      print(result_tuple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrm4XGFt-ugq",
        "outputId": "99ee4296-43a5-49d4-e769-6a3446f66b6e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Probando con tipo de búsqueda: similarity\n",
            "('¿Cuándo se fundó Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('¿Quién fue el primer presidente de Colo Colo?', 'La información proporcionada no indica quién fue el primer presidente de Colo Colo.\\n')\n",
            "('¿Cuál es el estadio de Colo Colo?', 'De acuerdo a la información proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  También se menciona el estadio \"Calvo y Bascuñán\", pero en el contexto de daños causados por barristas de Colo Colo tras una derrota contra Antofagasta.  No se indica que sea el estadio del club.\\n')\n",
            "('Cuál es el precio del Bitcoin en pesos Chilenos?', 'La información proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('Qué equipo ganó la copa Libertadores en 1991?', 'Colo-Colo ganó la Copa Libertadores en 1991.\\n')\n",
            "\n",
            "Probando con tipo de búsqueda: mmr\n",
            "('¿Cuándo se fundó Colo Colo?', 'Colo-Colo fue fundado el 19 de abril de 1925 en el Estadio El Llano.\\n')\n",
            "('¿Quién fue el primer presidente de Colo Colo?', 'La información proporcionada no incluye el nombre del primer presidente de Colo Colo.\\n')\n",
            "('¿Cuál es el estadio de Colo Colo?', 'De acuerdo a la información proporcionada, se menciona el Estadio Monumental, inaugurado definitivamente el 30 de septiembre de 1989.  También se menciona el estadio \"Calvo y Bascuñán\", pero en el contexto de daños causados por barristas de Colo Colo tras una derrota.  No se indica que sea el estadio del club.\\n')\n",
            "('Cuál es el precio del Bitcoin en pesos Chilenos?', 'La información proporcionada no contiene datos sobre el precio del Bitcoin en pesos chilenos.  Por lo tanto, no puedo responder a tu pregunta.\\n')\n",
            "('Qué equipo ganó la copa Libertadores en 1991?', 'Colo-Colo ganó la Copa Libertadores en 1991.\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 Agentes (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la sección anterior, en esta sección se busca habilitar **Agentes** para obtener información a través de tools y así responder la pregunta del usuario."
      ],
      "metadata": {
        "id": "ENJiPPM0giX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas al motor de búsqueda **Tavily**."
      ],
      "metadata": {
        "id": "V47l7Mjfrk0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_search = TavilySearchResults(max_results = 1) # inicializamos tool\n",
        "tools = [tavily_search] # guardamos las tools en una lista"
      ],
      "metadata": {
        "id": "_rJUQvTs0hAO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet langchain requests\n"
      ],
      "metadata": {
        "id": "R6SLKwcWr0AG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
        "\n",
        "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
      ],
      "metadata": {
        "id": "SonB1A-9rtRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r6l4lyZV1tEQ",
        "outputId": "49f8139a-0824-4bb7-98ce-31915d3bb2ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=28ba588c2765042a34f7abef07340c004564dc04920be4b9572bd9fad58df5e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ],
      "metadata": {
        "id": "_di_zcxz1SiX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
        "wiki_search = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "tools.append(wiki_search)"
      ],
      "metadata": {
        "id": "047lv-Oc1X4q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iC0RrVGYADqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
        "\n",
        "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Asegúrese que su agente responda en español. Por último, guarde el agente en una variable."
      ],
      "metadata": {
        "id": "CvUIMdX6r0ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "react_prompt = hub.pull(\"hwchase17/react\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkgB93fE2Tt8",
        "outputId": "287a117e-f691-41d2-f726-327287d0bfb3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "\n",
        "agent = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=50,max_execution_time=60) # lo transformamos a AgentExecutor para habilitar la ejecución de tools\n",
        "agent_executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_pfFH4y12kvI",
        "outputId": "a0a9c21b-4e74-4ca8-f4b9-08eac58d9e32"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
              "})\n",
              "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'tavily_search_results_json - A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\\nwikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'tool_names': 'tavily_search_results_json, wikipedia'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
              "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7ace9dae6d70>, default_metadata=()), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
              "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[TavilySearchResults(max_results=1, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=100))], max_iterations=50, max_execution_time=60.0)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.4 Verificación de respuestas (0.3 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente y asegúrese que el agente esté ocupando correctamente las tools disponibles. ¿En qué casos el agente debería ocupar la tool de Tavily? ¿En qué casos debería ocupar la tool de Wikipedia?"
      ],
      "metadata": {
        "id": "dKV0JxK3r-XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = agent_executor.invoke({\"input\": \"Cuál es el precio del Bitcoin en pesos Chilenos?\"})\n",
        "print(response1[\"output\"])\n",
        "\n",
        "response2 = agent_executor.invoke({\"input\": \"qué equipo ganó la copa Libertadores en 1991?\"})\n",
        "print(response2[\"output\"])"
      ],
      "metadata": {
        "id": "Pqo2dsxvywW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "882217da-336a-42be-a7f8-d55747840122"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Bitcoin in Chilean Pesos.  A real-time price is needed, so a search engine is the best option.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"Bitcoin price in Chilean Pesos\"\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://coinmarketcap.com/currencies/bitcoin/btc/clp/', 'content': 'Bitcoin to Chilean Peso Data. The BTC to CLP conversion rate today is $70,203.23. This is a decrease of 0.18% in the last hour and a decrease of 2.89% in the last 24 hours. The recent price direction of Bitcoin is a decrease because BTC is up by 14.58% against CLP in the last 30 days. Our converter updates in real time, giving you accurate'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now have the current Bitcoin price in Chilean Pesos from a reliable source.\n",
            "\n",
            "Final Answer: El precio actual de Bitcoin en pesos chilenos es aproximadamente $70,203.23.  Tenga en cuenta que este precio puede variar rápidamente.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "El precio actual de Bitcoin en pesos chilenos es aproximadamente $70,203.23.  Tenga en cuenta que este precio puede variar rápidamente.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out which team won the Copa Libertadores in 1991.  Wikipedia should have this information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: 1991 Copa Libertadores\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mPage: 1991 Copa Libertadores\n",
            "Summary: The 1991 Copa Libertadores was won by Colo-Colo of Chile after\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: Colo-Colo\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Colo-Colo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de las respuestas podemos ver que el Agente utiliza la tool de Wikipedia cuando para responder la pregunta se necesita de información histórica o más consolidada. Por otro lado, el Agente utiliza la tool de tavily cuando se necesita información más reciente o específica."
      ],
      "metadata": {
        "id": "Rs67wV358Rif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3 Multi Agente (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
        "\" width=\"450\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsección es encapsular las funcionalidades creadas en una solución multiagente con un **supervisor**.\n"
      ],
      "metadata": {
        "id": "cZbDTYiogquv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
        "\n",
        "Transforme la solución RAG de la sección 2.1 y el agente de la sección 2.2 a *tools* (una tool por cada uno)."
      ],
      "metadata": {
        "id": "7-iUfH0WvI6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "react_tool = Tool(\n",
        "    name=\"ReAct_Agent\",\n",
        "    func=lambda query: agent_executor.invoke({\"input\": query}),\n",
        "    description=\"Un agente que responde preguntas utilizando las tools Wikipedia y Tavily.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "srKKF4iD__nC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_tool = Tool(\n",
        "    name=\"RAG_Solution\",\n",
        "    func=lambda query: rag_chain.invoke({\"question\": query}),\n",
        "    description=\"Una solución basada en RAG que responde preguntas utilizando un modelo de recuperación y generación.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "bhqJt69wA4Xs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
        "\n",
        "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
      ],
      "metadata": {
        "id": "HQYNjT_0vPCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [react_tool, rag_tool]"
      ],
      "metadata": {
        "id": "yv2ZY0BAv1RD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supervisor = create_react_agent(llm, tools, react_prompt)\n",
        "supervisor_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=100,max_execution_time=120)"
      ],
      "metadata": {
        "id": "g7XzHyQ1LXfu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.3 Verificación de respuestas (0.25 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. ¿Cómo varían las respuestas bajo este enfoque?"
      ],
      "metadata": {
        "id": "ea3zWlvyvY7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions2 = [\n",
        "    \"¿Cuándo se fundó Colo Colo?\",\n",
        "    \"¿Quién fue el primer presidente de Colo Colo?\",\n",
        "    \"¿Cuál es el estadio de Colo Colo?\",\n",
        "    \"Cuál es el precio del Bitcoin en pesos Chilenos?\",\n",
        "    \"Qué equipo ganó la copa Libertadores en 1991?\"\n",
        "]\n",
        "\n",
        "for question in questions2:\n",
        "\n",
        "  response = supervisor_executor.invoke({\"input\": question})\n",
        "  result_tuple = (question, response)\n",
        "  print(result_tuple)"
      ],
      "metadata": {
        "id": "6_1t0zkgv1qW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f3ba0b88-9bb8-40db-8739-157deb75dcd4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To answer when Colo Colo was founded, I need to consult a reliable source with information on the history of the Chilean football club. Wikipedia is a good starting point.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Colo-Colo\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I tried to use a tool that wasn't available.  I'll try a different approach.  I'll use a general web search to find the founding date of Colo-Colo.  Since I don't have access to `tavily_search_results_json`, I'll assume a general web search will suffice.  I'll need to find a reliable source, such as a reputable sports website or encyclopedia.\n",
            "\n",
            "Action:  (Simulated Web Search)\n",
            "Action Input: \"Colo-Colo founding date\"\n",
            "\u001b[0m(Simulated Web Search) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using tools that are unavailable.  I will attempt to answer based on my existing knowledge.\n",
            "\n",
            "Thought: I know that Colo-Colo is a Chilean football club with a long history.  While I don't have access to specific databases, I can recall that its founding date is generally accepted to be in the early 20th century.  I'll need to refine my answer.\n",
            "\n",
            "Thought: I will try to recall the specific year.  My knowledge suggests it was around 1925.  I need to verify this.\n",
            "\n",
            "Thought: I cannot verify this information without access to external resources.  Therefore, I will provide the best answer I can based on my limited knowledge.\n",
            "\n",
            "Final Answer: Colo-Colo was founded in the early 20th century, around 1925.  This answer should be verified with a reliable source for accuracy.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('¿Cuándo se fundó Colo Colo?', {'input': '¿Cuándo se fundó Colo Colo?', 'output': 'Colo-Colo was founded in the early 20th century, around 1925.  This answer should be verified with a reliable source for accuracy.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find information about the first president of the Colo-Colo football club.  Wikipedia is a good resource for this type of information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Colo-Colo\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I tried to use a tool that wasn't available.  I'll try a different approach.  I'll search for information about the first president of Colo-Colo using a web search.  Since I don't have access to `tavily_search_results_json`, I'll assume it's similar to a standard web search and proceed accordingly.  I'll need to formulate a search query in Spanish.\n",
            "\n",
            "Action:  (Simulated Web Search)\n",
            "Action Input: \"primer presidente Colo Colo\"\n",
            "\u001b[0m(Simulated Web Search) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find information about the first president of Colo-Colo.  Since I don't have access to the specified tools, I will attempt to answer based on my existing knowledge.  My knowledge base is limited, so the answer may be incomplete or inaccurate.\n",
            "\n",
            "Thought: I will try to find information online using a general search engine.\n",
            "\n",
            "Action: (Simulated Web Search)\n",
            "Action Input: \"primer presidente Colo Colo\"\n",
            "\u001b[0m(Simulated Web Search) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I don't have access to any of the specified tools, and my attempts to simulate web searches have failed.  Therefore, I cannot answer the question definitively.  I need access to a working search engine or knowledge base to find the answer.\n",
            "\n",
            "Final Answer: I am unable to answer the question due to a lack of access to functional search tools.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('¿Quién fue el primer presidente de Colo Colo?', {'input': '¿Quién fue el primer presidente de Colo Colo?', 'output': 'I am unable to answer the question due to a lack of access to functional search tools.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out the name of the stadium where the Chilean football club Colo-Colo plays its home games.  Wikipedia should have this information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Colo-Colo\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I used an invalid tool.  I'll try a different approach using a web search.  I'll use a search engine to find the stadium of Colo-Colo.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"Colo-Colo stadium\"\n",
            "\u001b[0mtavily_search_results_json is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the unavailable tools.  I will try to answer based on my general knowledge.\n",
            "\n",
            "Thought: I know that Colo-Colo plays its home games at the Estadio Monumental David Arellano.\n",
            "\n",
            "Final Answer: El estadio de Colo Colo es el Estadio Monumental David Arellano.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('¿Cuál es el estadio de Colo Colo?', {'input': '¿Cuál es el estadio de Colo Colo?', 'output': 'El estadio de Colo Colo es el Estadio Monumental David Arellano.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Bitcoin in Chilean Pesos.  A real-time price is needed, so a search engine is the best option.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"Bitcoin price in Chilean Pesos\"\n",
            "\u001b[0mtavily_search_results_json is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Bitcoin in Chilean Pesos.  Since I don't have access to `tavily_search_results_json`, I'll try a general web search using a different method.  I cannot guarantee real-time accuracy without a dedicated financial API.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: \"Bitcoin\"\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I cannot answer the question without access to a real-time price feed for Bitcoin.  Wikipedia and a hypothetical \"tavily_search_results_json\" are not suitable for obtaining this information.  The price of Bitcoin fluctuates constantly.\n",
            "\n",
            "Final Answer: I cannot provide the current price of Bitcoin in Chilean Pesos.  To get this information, you need to consult a live cryptocurrency exchange that displays prices in Chilean Pesos.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('Cuál es el precio del Bitcoin en pesos Chilenos?', {'input': 'Cuál es el precio del Bitcoin en pesos Chilenos?', 'output': 'I cannot provide the current price of Bitcoin in Chilean Pesos.  To get this information, you need to consult a live cryptocurrency exchange that displays prices in Chilean Pesos.'})\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out which team won the Copa Libertadores in 1991.  Wikipedia should have this information.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: 1991 Copa Libertadores\n",
            "\u001b[0mwikipedia is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: My previous attempt failed because I used an invalid tool.  I'll try a different approach using a search engine.\n",
            "\n",
            "Action: tavily_search_results_json\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mtavily_search_results_json is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will try to formulate a search query that a standard search engine can understand.\n",
            "\n",
            "Action: Google Search (simulated)\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mGoogle Search (simulated) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will try to formulate a search query that a standard search engine can understand.  I will assume access to a standard search engine.\n",
            "\n",
            "Action: Google Search (simulated)\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mGoogle Search (simulated) is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will try to formulate a search query that a standard search engine can understand.  I will assume access to a standard search engine and will simulate the results.\n",
            "\n",
            "Action: Simulated Google Search\n",
            "Action Input: \"1991 Copa Libertadores winner\"\n",
            "\u001b[0mSimulated Google Search is not a valid tool, try one of [ReAct_Agent, RAG_Solution].\u001b[32;1m\u001b[1;3mThought: I need to find a way to answer the question without using the invalid tools.  I will use my own knowledge base.\n",
            "\n",
            "Thought: I now know the final answer.\n",
            "Final Answer:  Colo-Colo won the Copa Libertadores in 1991.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "('Qué equipo ganó la copa Libertadores en 1991?', {'input': 'Qué equipo ganó la copa Libertadores en 1991?', 'output': 'Colo-Colo won the Copa Libertadores in 1991.'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La principal diferencia es que el agente genera respuestas en inglés y, además, las respuestas parecen ser un poco más completas, en el sentido de que entregan la misma información, pero contenidas en una oración más extensa, por ejemplo para la pregunta \"¿Qué equipo ganó la copa Libertadores en 1991?, este modelo responde \"Colo colo ganó la copa Libertadores en 1991\", mientras que el agente anterior solamente respondía \"Colo Colo\""
      ],
      "metadata": {
        "id": "orUQ55amT74h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3.4 Análisis (0.25 puntos)**\n",
        "\n",
        "¿Qué diferencias tiene este enfoque con la solución *Router* vista en clases? Nombre al menos una ventaja y desventaja."
      ],
      "metadata": {
        "id": "Qb8bdAmYvgwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este enfoque es más recomendable que la solución Router cuando el usuario requiere responder preguntas basadas en un tema en específico (por ejemplo, documentación empresarial, artículos científicos, etc.) ya que en este caso se necesita un agente capaz de manejar información más específica y contextualizada.Sin embargo, también tiene una desventaja con respecto a Router a la hora de tratar con tareas de ámbitos diferentes, ya que en este caso la solución Router es mejor debido a su capacidad para manejar preguntas de naturaleza diversa."
      ],
      "metadata": {
        "id": "YAUlJxqoLK5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
        "\n",
        "- Pregunta 1: \"Hola! mi nombre es Sebastián\"\n",
        "  - Respuesta esperada: \"Hola Sebastián! ...\"\n",
        "- Pregunta 2: \"Cual es mi nombre?\"\n",
        "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
        "  - **Respuesta esperada: \"Tu nombre es Sebastián\"**\n",
        "\n",
        "Para solucionar esto, se les solicita agregar un componente de **memoria** a la solución entregada en el punto 2.3.\n",
        "\n",
        "**Nota: El Bonus es válido <u>sólo para la sección 2 de Large Language Models.</u>**"
      ],
      "metadata": {
        "id": "4JWVSuWiZ8Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6Y7tIPJLPfB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.5 Despliegue (0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a través de `gradio`, una librería especializada en el levantamiento rápido de demos basadas en ML.\n",
        "\n",
        "Primero instalamos la librería:"
      ],
      "metadata": {
        "id": "vFc3jBT5g0kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet gradio"
      ],
      "metadata": {
        "id": "T8TsvnCPbkIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5e781b-02d9-4214-ba6c-ae5f88bdc300"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego sólo deben ejecutar el siguiente código e interactuar con la interfaz a través del notebook o del link generado:"
      ],
      "metadata": {
        "id": "HJBztEUovKsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def agent_response(message, history):\n",
        "  '''\n",
        "  Función para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
        "  '''\n",
        "  # get chatbot response\n",
        "  response = agent_executor.invoke({\"input\": message})[\"output\"] # rellenar con la respuesta de su chat\n",
        "\n",
        "  # assert\n",
        "  assert type(response) == str, \"output de route_question debe ser string\"\n",
        "\n",
        "  # \"streaming\" response\n",
        "  for i in range(len(response)):\n",
        "    time.sleep(0.015)\n",
        "    yield response[: i+1]\n",
        "\n",
        "gr.ChatInterface(\n",
        "    agent_response,\n",
        "    type=\"messages\",\n",
        "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
        "    description=\"Hola! Soy un chatbot muy útil :)\", # también la descripción\n",
        "    theme=\"soft\",\n",
        "    ).launch(\n",
        "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
        "        debug = False,\n",
        "        )"
      ],
      "metadata": {
        "id": "Z3KedQSvg1-n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "fbf588e3-6caf-4602-94c6-f37cc1548054"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://250ecad1d8bb704850.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://250ecad1d8bb704850.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}